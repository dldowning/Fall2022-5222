{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Vi-s_C2OPcPQlg_pkSuo3Hx0HrIU9H58",
      "authorship_tag": "ABX9TyOcLXJsRcsiAQ6KVT7IBRJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dldowning/Fall2022-5222/blob/main/5222_Tweet_Analysis_Revision_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "id": "V9w4zRkSyFPA"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQKlDpd0xGyD",
        "outputId": "5b925293-455a-4826-ff4e-9f670277d33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3DS.tsv', '4chan.tsv', '2007scape.tsv', 'ACTrade.tsv', 'amiugly.tsv', 'BabyBumps.tsv', 'baseball.tsv', 'canada.tsv', 'CasualConversation.tsv', 'DarknetMarkets.tsv', 'darksouls.tsv', 'elderscrollsonline.tsv', 'Eve.tsv', 'Fallout.tsv', 'fantasyfootball.tsv', 'GameDeals.tsv', 'gamegrumps.tsv', 'halo.tsv', 'Homebrewing.tsv', 'IAmA.tsv', 'india.tsv', 'jailbreak.tsv', 'Jokes.tsv', 'KerbalSpaceProgram.tsv', 'Keto.tsv', 'leagueoflegends.tsv', 'Libertarian.tsv', 'magicTCG.tsv', 'MakeupAddiction.tsv', 'Naruto.tsv', 'nba.tsv', 'occulus.tsv', 'OkCupid.tsv', 'Parenting.tsv', 'pathofexile.tsv', 'raisedbynarcissists.tsv', 'Random_Acts_Of_Amazon.tsv', 'science.tsv', 'Seattle.tsv', 'TalesFromRetail.tsv', 'talesfromtechsupport.tsv', 'ultrahardcore.tsv', 'videos.tsv', 'Warthunder.tsv', 'histfreq2000.tsv', 'histadj2000.tsv']\n"
          ]
        }
      ],
      "source": [
        "#read file names into list - will later us to iterate gathering data \n",
        "my_file = open(\"/content/drive/MyDrive/5290/5290.Data/subreddit_files.txt\", \"r\")\n",
        "data = my_file.read()\n",
        "\n",
        "data_into_list = data.split(\"\\n\")\n",
        "print(data_into_list)\n",
        "my_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use file names to create dataframe names \n",
        "\n",
        "subreddit_dataframes = []            # List to hold subreddit dataframes \n",
        "\n",
        "for i in range(0,len(data_into_list)):   # For range in length of the # of subreddits we will use (44)    \n",
        "  x = data_into_list[i]                  # at index i of data_into_list assign the str value to x\n",
        "  dataframe_name = 'df_'+ x[:-4]          # with the assigned x value, append 'df_' to the front of te string and remove the last 4 characters \".tsv\". Leaves \"df_4chan\"\n",
        "\n",
        "  foo1 = dataframe_name\n",
        "  exec(foo1 + \" = subreddit_dataframes.append(pd.read_csv(\\\"/content/drive/MyDrive/5290/5290.Data/subreddits/\" + x +\"\\\",sep = '\\t', header=None)) \")    # Convert the string stored in dataframe_name to a variable name to hold the respective dataframe \n",
        "                                                                                                                                          # https://stackoverflow.com/questions/11553721/using-a-string-variable-as-a-variable-name\n",
        "  subreddit_dataframes[i].columns = ['Word', 'Sentiment Score', 'drop']            # Create clumn names in each respective dataframe \n",
        "  subreddit_dataframes[i] = subreddit_dataframes[i].drop('drop', axis=1)                    # Drop unwanted column"
      ],
      "metadata": {
        "id": "Yas76vnNxyVy"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Function To Create Train and Test Dataframes"
      ],
      "metadata": {
        "id": "FfBd7WY06XL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow about 16min for runtime\n",
        "\n",
        "def feature_extraction(data_location, label_location):\n",
        "  df = pd.read_csv(data_location, header=None)\n",
        "  df.columns = ['TWEET']\n",
        "\n",
        "  df[\"Tweet Tokens\"] = np.nan\n",
        "  df[\"Count: Words in + Lexicon\"] = np.nan\n",
        "  df[\"Count: Words in - Lexicon\"] = np.nan\n",
        "  df[\"Contain The word NO? \"] = np.nan\n",
        "  df[\"Count: Nouns\"] = np.nan\n",
        "  df[\"Ratio: Unique Words-Total Words\"] = np.nan\n",
        "  df[\"Ratio: Stop Words-Total Words\"] = np.nan\n",
        "  df[\"Count: Adjectives in Tweet\"] = np.nan\n",
        "  df[\"Log: Tweet word count\"] = np.nan\n",
        "  df[\"Log: Length of Longest Word in Tweet\"] = np.nan\n",
        "  df[\"Log: Count of Words with 5+ Characters\"] = np.nan\n",
        "\n",
        "  # ADD LABELS COLUMN TO DF \n",
        "  labels = pd.read_csv(label_location, sep=\"\\n\", header=None)\n",
        "  df = pd.concat([df,labels], axis = 1)\n",
        "  df.rename(columns = {0:'Labels'}, inplace = True)\n",
        "\n",
        "  # DROP NEUTRAL LABELS FROM DF\n",
        "  df.drop(df.loc[df['Labels']==1].index, inplace=True)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # CHANGE ALL 2 LABEL VALUES TO 1 \n",
        "  for i in range(0, len(df.index)):\n",
        "    if df['Labels'].values[i] == 2:\n",
        "      df.at[i,'Labels'] = 1\n",
        "\n",
        "  # CLEAN TWEETS\n",
        "  pattern_a = r'[^A-Za-z0-9]+'\n",
        "  pattern_b = r'\\b\\w{1,1}\\b'\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].lower()\n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].replace('@user', '')\n",
        "    df['TWEET'].values[i] = re.sub(pattern_a, ' ', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(pattern_b, '', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(emoji_pattern, '', df['TWEET'].values[i])\n",
        "\n",
        "  #TOKENIZE TWEETS\n",
        "  df['Tweet Tokens'] = df['Tweet Tokens'].astype('object')\n",
        "  for i in range(0, len(df.index)):\n",
        "    \n",
        "    tokens = df['TWEET'].values[i].split()\n",
        "    df.at[i, 'Tweet Tokens'] = tokens\n",
        "\n",
        "  #Create Positive and Negative Lexicons\n",
        "  pos_lexicon = []\n",
        "  neg_lexicon = []\n",
        "\n",
        "  for i in range(0, len(subreddit_dataframes)):               \n",
        "    for j in range(0, len(subreddit_dataframes[i].index)):    \n",
        "\n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] >= 0:         \n",
        "        pos_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "      \n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] < 0:         \n",
        "        neg_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "\n",
        "\n",
        "  pos_lexicon = [*set(pos_lexicon)]   # Remove duplicate values from + lexicon\n",
        "  neg_lexicon = [*set(neg_lexicon)]   # Remove duplicate values from - lexicon\n",
        "\n",
        "\n",
        "  #Handle duplicate words in postitive and negative lexicon\n",
        "  same_wrds = set(pos_lexicon).intersection(neg_lexicon)      #get set of all words that appear in both psoitive and Negative Lexicon\n",
        "                                                              #https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches\n",
        "\n",
        "  word_vals_dict = dict.fromkeys(same_wrds, 0)                # Create a dictionary to hold of all words found in positive and negative lexicons     \n",
        "  sentiment_vals2sum = []\n",
        "\n",
        "  for k in range(0, len(same_wrds)):    # In the set of words identified in positive and negative lexicon\n",
        "  \n",
        "    i = same_wrds.pop()                 # i will return one word from the set, then the following with each iteration\n",
        "    same_wrds.add(i)                    # https://stackoverflow.com/questions/59825/how-to-retrieve-an-element-from-a-set-without-removing-it\n",
        "\n",
        "    sentiment_vals2sum = []             # Will store the Sentiment Scores collected across data frames \n",
        "\n",
        "    for j in range(0, len(subreddit_dataframes)):                    # in range of dataframes(44)\n",
        "      is_wrd_there = i in subreddit_dataframes[j]['Word'].unique()   # Return true or false. True if desired word 'i' is in the data frame being checked false if not (ls_df_names[0], ls_df_names[1],...)\n",
        "      if is_wrd_there is True:                              # If true... \n",
        "\n",
        "        mask1 = subreddit_dataframes[j]['Word'].values == i                  # Get the sentiment value of the word from its dataframe \n",
        "                                                                    # https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
        "                                                      \n",
        "        sentiment_vals2sum.append(subreddit_dataframes[j][mask1].iat[0,1])   # append sentiment value to list where they are stored eg. sentiment_vals2sum \n",
        "        num_avg = mean(sentiment_vals2sum)                          # Take the mean of the sentiment scores collected in the list above(these are all sentiment scores for one word collected across dataframes where the word was found 'True')\n",
        "        word_vals_dict[i] = num_avg  \n",
        "\n",
        "  # Remove words that now have a clear positive or negative classification\n",
        "  for w in word_vals_dict.items():        # .items() returns a tuple of (word, score). See Cell above for all words: scores in dict\n",
        "    if w[1] >= 0:                         # if w[1] (the score) is greater than 0...\n",
        "      neg_lexicon.remove(w[0])            # remove it from the negative lexicon\n",
        "    if w[1] < 0:                          # If w[1] (the score) is less than 0...\n",
        "      pos_lexicon.remove(w[0])            # remove the word from the positive lexicon\n",
        "\n",
        "  # COUNT POSITIVE AND NEGATIVE WORDS\n",
        "  neg_lex_set = set(neg_lexicon)\n",
        "  pos_lex_set = set(pos_lexicon)\n",
        "\n",
        "  for i in range(0, len(df.index)):\n",
        "    x = set(df['Tweet Tokens'][i])\n",
        "    df['Count: Words in + Lexicon'].values[i] = len(x.intersection(pos_lex_set))\n",
        "    df['Count: Words in - Lexicon'].values[i] = len(x.intersection(neg_lex_set))\n",
        "\n",
        "  # DOES TWEET CONTAIN NO\n",
        "  for i in range(0, len(df.index)):                       # In the range 0 to length of the tweets dataframe         # Tokenize and lowercase tweets \n",
        "    if 'no' in df['Tweet Tokens'][i]:                                    # If no is in tweet dataframe value is 1 if not value is zero\n",
        "      df['Contain The word NO? '].values[i] = 1\n",
        "    else: \n",
        "      df['Contain The word NO? '].values[i] = 0\n",
        "\n",
        "  # COUNT NOUNS IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    noun_definitions = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in noun_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Nouns'].values[i] = count    \n",
        "\n",
        "  # RATIO: UNIQUE TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    ratio = len(np.unique(x)) / len(tokens)\n",
        "    df['Ratio: Unique Words-Total Words'].values[i] = ratio    \n",
        "\n",
        "  # STOP WORDS TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    stop_wrds_count = [w for w in tokens if w in stop_words]\n",
        "    ratio = len(stop_wrds_count) / len(tokens)\n",
        "    df['Ratio: Stop Words-Total Words'].values[i] = ratio\n",
        "\n",
        "  #ADJECTIVES IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    adj_definitions = ['JJ', 'JJR', 'JJS ']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in adj_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Adjectives in Tweet'].values[i] = count\n",
        "\n",
        "  # LOG OF TWEET WORD COUNT \n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]       #tokenize tweets \n",
        "    log_val = math.log(len(tokens))\n",
        "    df['Log: Tweet word count'].values[i] = log_val\n",
        "\n",
        "\n",
        "  # LOG LENGTH OF LONGEST WORD IN TWEET\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]   #tokenize tweets \n",
        "    longest_wrd = max(tokens, key=len)\n",
        "    log_val =  math.log(len(longest_wrd))\n",
        "    df['Log: Length of Longest Word in Tweet'].values[i] = log_val\n",
        "\n",
        "  #LOG OF COUNT OF WORD WITH 5+ CHARACTERS\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]    #tokenize tweets\n",
        "    count = 0\n",
        "      \n",
        "    if any(len(i) >= 5 for i in tokens) is True:\n",
        "\n",
        "      for j in range(0, len(tokens)):\n",
        "        if len(tokens[j]) >= 5:\n",
        "          count = count +1\n",
        "\n",
        "      log_val = math.log(count)\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = log_val\n",
        "      \n",
        "    else:\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = 0\n",
        "\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "mUtstsOA3vN7"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_location = \"/content/drive/MyDrive/5290/5290.Data/train_text.csv\"\n",
        "train_label_location = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_labels.txt\"\n",
        "\n",
        "df_train = feature_extraction(train_file_location, train_label_location) #Create train dataframe\n",
        "\n",
        "test_file_location = \"/content/drive/MyDrive/5290/5290.Data/test_text.csv\"\n",
        "test_label_location =\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/test_labels.txt\"\n",
        "\n",
        "df_test = feature_extraction(test_file_location, test_label_location)   #Create test dataframe"
      ],
      "metadata": {
        "id": "8NEOBwZB_TeD"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "fK2qOCd_Q5BL",
        "outputId": "1dd65221-3971-473c-f696-e0300b76fbcc"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   TWEET  \\\n",
              "0       qt in the original draft of the 7th book remu...   \n",
              "1       alciato bee will invest 150 million in januar...   \n",
              "2       lit my mum kerry the louboutins  wonder how m...   \n",
              "3       soul train oct 27 halloween special ft  dot f...   \n",
              "4      so disappointed in wwe summerslam  want to see...   \n",
              "...                                                  ...   \n",
              "24937  michael from good times is the 2nd greatest mi...   \n",
              "24938   just think some misguided girl is in the vip ...   \n",
              "24939   so amazing to have the beautiful lady gaga at...   \n",
              "24940   september has arrived which means apple  new ...   \n",
              "24941  leeds   sheff wed giuseppe bellusci securing l...   \n",
              "\n",
              "                                            Tweet Tokens  \\\n",
              "0      [qt, in, the, original, draft, of, the, 7th, b...   \n",
              "1      [alciato, bee, will, invest, 150, million, in,...   \n",
              "2      [lit, my, mum, kerry, the, louboutins, wonder,...   \n",
              "3      [soul, train, oct, 27, halloween, special, ft,...   \n",
              "4      [so, disappointed, in, wwe, summerslam, want, ...   \n",
              "...                                                  ...   \n",
              "24937  [michael, from, good, times, is, the, 2nd, gre...   \n",
              "24938  [just, think, some, misguided, girl, is, in, t...   \n",
              "24939  [so, amazing, to, have, the, beautiful, lady, ...   \n",
              "24940  [september, has, arrived, which, means, apple,...   \n",
              "24941  [leeds, sheff, wed, giuseppe, bellusci, securi...   \n",
              "\n",
              "       Count: Words in + Lexicon  Count: Words in - Lexicon  \\\n",
              "0                            8.0                        1.0   \n",
              "1                           10.0                        4.0   \n",
              "2                            5.0                        5.0   \n",
              "3                           15.0                        6.0   \n",
              "4                            6.0                        5.0   \n",
              "...                          ...                        ...   \n",
              "24937                        8.0                        1.0   \n",
              "24938                        9.0                        8.0   \n",
              "24939                       10.0                        2.0   \n",
              "24940                        9.0                        8.0   \n",
              "24941                        3.0                        4.0   \n",
              "\n",
              "       Contain The word NO?   Count: Nouns  Ratio: Unique Words-Total Words  \\\n",
              "0                        0.0           7.0                         0.823529   \n",
              "1                        0.0           5.0                         0.950000   \n",
              "2                        0.0           7.0                         0.933333   \n",
              "3                        0.0          11.0                         1.000000   \n",
              "4                        0.0           5.0                         1.000000   \n",
              "...                      ...           ...                              ...   \n",
              "24937                    0.0           5.0                         0.785714   \n",
              "24938                    0.0           8.0                         1.000000   \n",
              "24939                    0.0           6.0                         0.944444   \n",
              "24940                    0.0           6.0                         1.000000   \n",
              "24941                    0.0           5.0                         1.000000   \n",
              "\n",
              "       Ratio: Stop Words-Total Words  Count: Adjectives in Tweet  \\\n",
              "0                           0.352941                         2.0   \n",
              "1                           0.350000                         1.0   \n",
              "2                           0.200000                         1.0   \n",
              "3                           0.086957                         4.0   \n",
              "4                           0.285714                         2.0   \n",
              "...                              ...                         ...   \n",
              "24937                       0.285714                         1.0   \n",
              "24938                       0.391304                         1.0   \n",
              "24939                       0.444444                         2.0   \n",
              "24940                       0.388889                         2.0   \n",
              "24941                       0.200000                         2.0   \n",
              "\n",
              "       Log: Tweet word count  Log: Length of Longest Word in Tweet  \\\n",
              "0                   2.833213                              3.135494   \n",
              "1                   2.995732                              1.945910   \n",
              "2                   2.708050                              2.302585   \n",
              "3                   3.135494                              2.197225   \n",
              "4                   2.639057                              2.484907   \n",
              "...                      ...                                   ...   \n",
              "24937               2.639057                              2.079442   \n",
              "24938               3.135494                              2.708050   \n",
              "24939               2.890372                              2.197225   \n",
              "24940               2.890372                              2.197225   \n",
              "24941               2.708050                              2.079442   \n",
              "\n",
              "       Log: Count of Words with 5+ Characters  Labels  \n",
              "0                                    2.079442       1  \n",
              "1                                    2.197225       1  \n",
              "2                                    1.945910       1  \n",
              "3                                    2.302585       1  \n",
              "4                                    1.098612       0  \n",
              "...                                       ...     ...  \n",
              "24937                                1.945910       1  \n",
              "24938                                1.945910       0  \n",
              "24939                                1.386294       1  \n",
              "24940                                2.302585       1  \n",
              "24941                                2.397895       1  \n",
              "\n",
              "[24942 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d110f43c-9e8f-4fef-b6be-9b5e03075117\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>Tweet Tokens</th>\n",
              "      <th>Count: Words in + Lexicon</th>\n",
              "      <th>Count: Words in - Lexicon</th>\n",
              "      <th>Contain The word NO?</th>\n",
              "      <th>Count: Nouns</th>\n",
              "      <th>Ratio: Unique Words-Total Words</th>\n",
              "      <th>Ratio: Stop Words-Total Words</th>\n",
              "      <th>Count: Adjectives in Tweet</th>\n",
              "      <th>Log: Tweet word count</th>\n",
              "      <th>Log: Length of Longest Word in Tweet</th>\n",
              "      <th>Log: Count of Words with 5+ Characters</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qt in the original draft of the 7th book remu...</td>\n",
              "      <td>[qt, in, the, original, draft, of, the, 7th, b...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.833213</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alciato bee will invest 150 million in januar...</td>\n",
              "      <td>[alciato, bee, will, invest, 150, million, in,...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lit my mum kerry the louboutins  wonder how m...</td>\n",
              "      <td>[lit, my, mum, kerry, the, louboutins, wonder,...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.708050</td>\n",
              "      <td>2.302585</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>soul train oct 27 halloween special ft  dot f...</td>\n",
              "      <td>[soul, train, oct, 27, halloween, special, ft,...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.302585</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>so disappointed in wwe summerslam  want to see...</td>\n",
              "      <td>[so, disappointed, in, wwe, summerslam, want, ...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.639057</td>\n",
              "      <td>2.484907</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24937</th>\n",
              "      <td>michael from good times is the 2nd greatest mi...</td>\n",
              "      <td>[michael, from, good, times, is, the, 2nd, gre...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.639057</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24938</th>\n",
              "      <td>just think some misguided girl is in the vip ...</td>\n",
              "      <td>[just, think, some, misguided, girl, is, in, t...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>2.708050</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24939</th>\n",
              "      <td>so amazing to have the beautiful lady gaga at...</td>\n",
              "      <td>[so, amazing, to, have, the, beautiful, lady, ...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24940</th>\n",
              "      <td>september has arrived which means apple  new ...</td>\n",
              "      <td>[september, has, arrived, which, means, apple,...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.302585</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24941</th>\n",
              "      <td>leeds   sheff wed giuseppe bellusci securing l...</td>\n",
              "      <td>[leeds, sheff, wed, giuseppe, bellusci, securi...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.708050</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24942 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d110f43c-9e8f-4fef-b6be-9b5e03075117')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d110f43c-9e8f-4fef-b6be-9b5e03075117 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d110f43c-9e8f-4fef-b6be-9b5e03075117');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "GWv96EweQ7eu",
        "outputId": "c8a90be9-ca56-4b31-8292-bd2d518eb39f"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  TWEET  \\\n",
              "0      think  may be finally in with the in crowd ma...   \n",
              "1      wow first hugo chavez and now fidel castro da...   \n",
              "2     twitter  thankyouobama shows heartfelt gratitu...   \n",
              "3      take away illegals and dead people and trump ...   \n",
              "4           onedirection harrystyles cute little dance    \n",
              "...                                                 ...   \n",
              "6342   for al the crying you do about how middle ame...   \n",
              "6343    not even catholic but pope francis is my dud...   \n",
              "6344   looks like flynn isn  too pleased with me he ...   \n",
              "6345  trying to have  conversation with my dad about...   \n",
              "6346   you are  stand up guy and  gentleman vice pre...   \n",
              "\n",
              "                                           Tweet Tokens  \\\n",
              "0     [think, may, be, finally, in, with, the, in, c...   \n",
              "1     [wow, first, hugo, chavez, and, now, fidel, ca...   \n",
              "2     [twitter, thankyouobama, shows, heartfelt, gra...   \n",
              "3     [take, away, illegals, and, dead, people, and,...   \n",
              "4      [onedirection, harrystyles, cute, little, dance]   \n",
              "...                                                 ...   \n",
              "6342  [for, al, the, crying, you, do, about, how, mi...   \n",
              "6343  [not, even, catholic, but, pope, francis, is, ...   \n",
              "6344  [looks, like, flynn, isn, too, pleased, with, ...   \n",
              "6345  [trying, to, have, conversation, with, my, dad...   \n",
              "6346  [you, are, stand, up, guy, and, gentleman, vic...   \n",
              "\n",
              "      Count: Words in + Lexicon  Count: Words in - Lexicon  \\\n",
              "0                           4.0                        3.0   \n",
              "1                           7.0                       10.0   \n",
              "2                           3.0                        0.0   \n",
              "3                           2.0                        8.0   \n",
              "4                           2.0                        1.0   \n",
              "...                         ...                        ...   \n",
              "6342                        4.0                       13.0   \n",
              "6343                       10.0                        7.0   \n",
              "6344                        5.0                        5.0   \n",
              "6345                        5.0                        8.0   \n",
              "6346                        2.0                        6.0   \n",
              "\n",
              "      Contain The word NO?   Count: Nouns  Ratio: Unique Words-Total Words  \\\n",
              "0                       0.0           3.0                         0.909091   \n",
              "1                       0.0          11.0                         0.954545   \n",
              "2                       0.0           4.0                         1.000000   \n",
              "3                       0.0           4.0                         0.916667   \n",
              "4                       0.0           3.0                         1.000000   \n",
              "...                     ...           ...                              ...   \n",
              "6342                    0.0           4.0                         1.000000   \n",
              "6343                    0.0           5.0                         0.909091   \n",
              "6344                    0.0           3.0                         0.750000   \n",
              "6345                    0.0           5.0                         1.000000   \n",
              "6346                    0.0           5.0                         1.000000   \n",
              "\n",
              "      Ratio: Stop Words-Total Words  Count: Adjectives in Tweet  \\\n",
              "0                          0.454545                         0.0   \n",
              "1                          0.272727                         2.0   \n",
              "2                          0.142857                         1.0   \n",
              "3                          0.250000                         2.0   \n",
              "4                          0.000000                         1.0   \n",
              "...                             ...                         ...   \n",
              "6342                       0.550000                         2.0   \n",
              "6343                       0.500000                         2.0   \n",
              "6344                       0.562500                         2.0   \n",
              "6345                       0.470588                         0.0   \n",
              "6346                       0.400000                         1.0   \n",
              "\n",
              "      Log: Tweet word count  Log: Length of Longest Word in Tweet  \\\n",
              "0                  2.397895                              2.890372   \n",
              "1                  3.091042                              1.945910   \n",
              "2                  1.945910                              2.564949   \n",
              "3                  2.484907                              2.079442   \n",
              "4                  1.609438                              2.484907   \n",
              "...                     ...                                   ...   \n",
              "6342               2.995732                              1.945910   \n",
              "6343               3.091042                              2.302585   \n",
              "6344               2.772589                              1.945910   \n",
              "6345               2.833213                              2.564949   \n",
              "6346               2.302585                              2.197225   \n",
              "\n",
              "      Log: Count of Words with 5+ Characters  Labels  \n",
              "0                                   1.609438       1  \n",
              "1                                   2.484907       0  \n",
              "2                                   1.791759       1  \n",
              "3                                   1.386294       0  \n",
              "4                                   1.386294       1  \n",
              "...                                      ...     ...  \n",
              "6342                                1.945910       0  \n",
              "6343                                1.098612       1  \n",
              "6344                                1.791759       0  \n",
              "6345                                2.079442       0  \n",
              "6346                                1.386294       1  \n",
              "\n",
              "[6347 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2103e36f-88a3-4a74-affa-aad3ead872e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>Tweet Tokens</th>\n",
              "      <th>Count: Words in + Lexicon</th>\n",
              "      <th>Count: Words in - Lexicon</th>\n",
              "      <th>Contain The word NO?</th>\n",
              "      <th>Count: Nouns</th>\n",
              "      <th>Ratio: Unique Words-Total Words</th>\n",
              "      <th>Ratio: Stop Words-Total Words</th>\n",
              "      <th>Count: Adjectives in Tweet</th>\n",
              "      <th>Log: Tweet word count</th>\n",
              "      <th>Log: Length of Longest Word in Tweet</th>\n",
              "      <th>Log: Count of Words with 5+ Characters</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>think  may be finally in with the in crowd ma...</td>\n",
              "      <td>[think, may, be, finally, in, with, the, in, c...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wow first hugo chavez and now fidel castro da...</td>\n",
              "      <td>[wow, first, hugo, chavez, and, now, fidel, ca...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.091042</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>2.484907</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter  thankyouobama shows heartfelt gratitu...</td>\n",
              "      <td>[twitter, thankyouobama, shows, heartfelt, gra...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>take away illegals and dead people and trump ...</td>\n",
              "      <td>[take, away, illegals, and, dead, people, and,...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.484907</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>onedirection harrystyles cute little dance</td>\n",
              "      <td>[onedirection, harrystyles, cute, little, dance]</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>2.484907</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6342</th>\n",
              "      <td>for al the crying you do about how middle ame...</td>\n",
              "      <td>[for, al, the, crying, you, do, about, how, mi...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6343</th>\n",
              "      <td>not even catholic but pope francis is my dud...</td>\n",
              "      <td>[not, even, catholic, but, pope, francis, is, ...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.091042</td>\n",
              "      <td>2.302585</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6344</th>\n",
              "      <td>looks like flynn isn  too pleased with me he ...</td>\n",
              "      <td>[looks, like, flynn, isn, too, pleased, with, ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.772589</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6345</th>\n",
              "      <td>trying to have  conversation with my dad about...</td>\n",
              "      <td>[trying, to, have, conversation, with, my, dad...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.833213</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6346</th>\n",
              "      <td>you are  stand up guy and  gentleman vice pre...</td>\n",
              "      <td>[you, are, stand, up, guy, and, gentleman, vic...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.302585</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6347 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2103e36f-88a3-4a74-affa-aad3ead872e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2103e36f-88a3-4a74-affa-aad3ead872e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2103e36f-88a3-4a74-affa-aad3ead872e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train = df_train.drop(['Labels', 'TWEET', 'Tweet Tokens'],axis=1)\n",
        "Y_train = df_train['Labels']\n",
        "X_test = df_test.drop(['Labels','TWEET', 'Tweet Tokens'], axis=1)\n",
        "Y_test = df_test['Labels']\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_train = Y_train.values\n",
        "Y_test = Y_test.values"
      ],
      "metadata": {
        "id": "yCUWvEDGRNGa"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr = LogisticRegression(max_iter=1500)\n",
        "logisticRegr.fit(X_train, Y_train)\n",
        "predictions = logisticRegr.predict(X_test)\n",
        "score = logisticRegr.score(X_test, Y_test)\n",
        "print('Sklearn Logistic regression score: ', round(score *100, 2), '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA53DfeJRqpM",
        "outputId": "639fb615-5684-4d27-bd6b-9c4d77beea1d"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Logistic regression score:  61.48 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(Y_test, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djz9FxCnS_FM",
        "outputId": "710686e0-141b-4061-decf-c03fdc3c6a31"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1715 2257]\n",
            " [ 188 2187]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = cm[0][0] / (cm[0][0] + cm[0][1])\n",
        "recall = cm[0][0] / (cm[0][0] + cm[1][0])\n",
        "\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('F1: ', F1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui5HFFn1TSBz",
        "outputId": "dda125d9-0772-4f75-fc50-0e9bfc44a42c"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1:  0.5838297872340427\n"
          ]
        }
      ]
    }
  ]
}