{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dldowning/Fall2022-5222/blob/main/Downing_Roberts_5222_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "2Fg7eZRAlOgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 579,
      "metadata": {
        "id": "y0gm-p1OwcOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f86c01-0205-4c99-d742-5e772523c264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import nltk\n",
        "from google.colab import files\n",
        "import matplotlib as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import requests\n",
        "import string\n",
        "import random\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "import csv\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating dataframe"
      ],
      "metadata": {
        "id": "ki0KdvZFk91C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1C8ARH_yok3uOvirD_oKvgEmAR22SuC9R\"\n",
        "response = requests.get(URL)\n",
        "open(\"train_text_labels.csv\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpuC3U1RnsOJ",
        "outputId": "01524858-e289-437c-f12a-e089e95a4638"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5123208"
            ]
          },
          "metadata": {},
          "execution_count": 580
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1z0URnDJ8ck38mQ4CvHi5TUkly8e46glP\"\n",
        "response = requests.get(URL)\n",
        "open(\"test_text.txt\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv3I3RB99McR",
        "outputId": "fe8b87c7-21e6-4046-94be-3d8bdd8dde19"
      },
      "execution_count": 581,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1156877"
            ]
          },
          "metadata": {},
          "execution_count": 581
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1xWQ2Lpf866Be4OR8J-cJHuY1S25dWppf\"\n",
        "response = requests.get(URL)\n",
        "open(\"test_labels.txt\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCzr8I-pCtIh",
        "outputId": "3a1497b5-fdaa-4c8b-98b9-9373d6691a12"
      },
      "execution_count": 582,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36850"
            ]
          },
          "metadata": {},
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"/content/train_text_labels.csv\", header=None)\n",
        "df0.columns = ['Twitter', 'Label']\n",
        "len(df0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpaK7zlWlYbh",
        "outputId": "5a4aa72c-f504-48cc-85d1-8af36849d9ba"
      },
      "execution_count": 583,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45615"
            ]
          },
          "metadata": {},
          "execution_count": 583
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft = pd.read_csv(\"/content/test_text.txt\", sep=\"\\n\", header=None, quoting=csv.QUOTE_NONE)\n",
        "dft.columns = ['Twitter']\n",
        "len(dft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrWP7cBN67Gj",
        "outputId": "9349a18d-7bf3-47a0-fb75-87b27ea0c3bf"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12284"
            ]
          },
          "metadata": {},
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftl = pd.read_csv(\"/content/test_labels.txt\", sep=\"\\n\", header=None)\n",
        "dftl.columns = ['Label']\n",
        "len(dftl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAyC71rtA_xv",
        "outputId": "71fbdfce-58a9-40ff-a9a7-23fd1dfc0f0b"
      },
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12284"
            ]
          },
          "metadata": {},
          "execution_count": 585
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft['Label']=dftl['Label']\n",
        "dft.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4v2zs-HKFrQL",
        "outputId": "26f70690-d7be-4b66-e48e-254932e045e8"
      },
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label\n",
              "0  @user @user what do these '1/2 naked pics' hav...      1\n",
              "1  OH: “I had a blue penis while I was this” [pla...      1\n",
              "2  @user @user That's coming, but I think the vic...      1\n",
              "3  I think I may be finally in with the in crowd ...      2\n",
              "4  @user Wow,first Hugo Chavez and now Fidel Cast...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d5c86dc-c696-4c86-8b2d-494109492e17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user That's coming, but I think the vic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I think I may be finally in with the in crowd ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d5c86dc-c696-4c86-8b2d-494109492e17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d5c86dc-c696-4c86-8b2d-494109492e17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d5c86dc-c696-4c86-8b2d-494109492e17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 586
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0['Label'].value_counts()\n",
        "#0\tnegative\n",
        "#1\tneutral\n",
        "#2\tpositive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peakGoADUHke",
        "outputId": "f88d7f90-b8ab-416c-aa6b-11dfdb884ebd"
      },
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    20673\n",
              "2    17849\n",
              "0     7093\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 587
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the neutrals\n",
        "df = df0[df0['Label'] != 1]\n",
        "df.loc[df.Label == 2, 'Label'] = 1\n",
        "df=df.reset_index(drop=True)\n",
        "len(df)"
      ],
      "metadata": {
        "id": "47HFm_YlozWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0301a28-603f-4cee-c4a8-b296b7b6e407"
      },
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24942"
            ]
          },
          "metadata": {},
          "execution_count": 588
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft = dft[dft['Label'] != 1]\n",
        "dft=dft.reset_index(drop=True)\n",
        "dft.loc[dft.Label == 2, 'Label'] = 1\n",
        "len(df)\n",
        "len(dft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6dIwcfpF97G",
        "outputId": "4d020ee6-31c7-4014-e700-eb6e2077258c"
      },
      "execution_count": 589,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6347"
            ]
          },
          "metadata": {},
          "execution_count": 589
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tweetcleanandtoke(dataframe,colname,newcolname):\n",
        "  stop = stopwords.words('english')\n",
        "  pattern_a = r'[^A-Za-z0-9]+' #non-alphanumeric\n",
        "  pattern_b = r'\\b\\w{1,1}\\b' #repeated words\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):                       \n",
        "    dataframe[colname].values[i] = dataframe[colname].values[i].lower()\n",
        "    dataframe[colname].values[i] = dataframe[colname].values[i].replace('@user', '')\n",
        "    dataframe[colname].values[i] = re.sub(emoji_pattern, '', dataframe[colname].values[i])\n",
        "    dataframe[colname].values[i] = re.sub(pattern_a, ' ', dataframe[colname].values[i])\n",
        "    dataframe[colname].values[i] = re.sub(pattern_b, '', dataframe[colname].values[i])\n",
        "    \n",
        "\n",
        "  dataframe[colname] = dataframe[colname].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "  rowname = dataframe[colname].name\n",
        "  dataframe[newcolname]=0\n",
        "  dataframe[newcolname] = dataframe.apply(lambda row: nltk.word_tokenize(row[rowname]), axis=1)\n",
        "\n",
        "  return dataframe\n",
        "  "
      ],
      "metadata": {
        "id": "rRU76z3L7Z_y"
      },
      "execution_count": 590,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=tweetcleanandtoke(df,'Twitter','Twitter_tokens')\n",
        "dft=tweetcleanandtoke(df,'Twitter','Twitter_tokens')"
      ],
      "metadata": {
        "id": "uIgjtTsp9kUf"
      },
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Token_len']=df['Twitter_tokens'].apply(len)\n",
        "dft['Token_len']=dft['Twitter_tokens'].apply(len)\n",
        "\n"
      ],
      "metadata": {
        "id": "aoASGVI0tzhU"
      },
      "execution_count": 592,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the tokens for some EDA, also verifying I have no length 0\n",
        "list_of_lengths=[]\n",
        "less_than_9_len=[]\n",
        "for i in range (0, len(df)):\n",
        "  try:\n",
        "    list_of_lengths.append(len(df['Twitter_tokens'][i]));\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    if len(df['Twitter_tokens'][i]) < 9:\n",
        "      less_than_9_len.append(str(i));\n",
        "  except:\n",
        "    pass\n",
        "print(\"These stats are for the training set\")\n",
        "print(\"The min length is: \" + str(min(list_of_lengths)))\n",
        "print(\"The max length is: \" + str(max(list_of_lengths)))\n",
        "print(\"The mean length is: \" + str(mean(list_of_lengths)))\n",
        "print(\"The number of tweets with less than 9 tokens is: \" + str(len(less_than_9_len)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1ZY4K-nhkIQ",
        "outputId": "b2bcc1a5-5edf-48ff-ef80-95ba3a617e00"
      },
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These stats are for the training set\n",
            "The min length is: 1\n",
            "The max length is: 26\n",
            "The mean length is: 11.502004650789832\n",
            "The number of tweets with less than 9 tokens is: 4506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_lengths=[]\n",
        "less_than_9_len=[]\n",
        "for i in range (0, len(dft)):\n",
        "  try:\n",
        "    list_of_lengths.append(len(dft['Twitter_tokens'][i]));\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    if len(dft['Twitter_tokens'][i]) < 9:\n",
        "      less_than_9_len.append(str(i));\n",
        "  except:\n",
        "    pass\n",
        "print(\"These stats are for the testing set\")\n",
        "print(\"The min test length is: \" + str(min(list_of_lengths)))\n",
        "print(\"The max test length is: \" + str(max(list_of_lengths)))\n",
        "print(\"The mean test length is: \" + str(mean(list_of_lengths)))\n",
        "print(\"The number of test tweets with less than 9 tokens is: \" + str(len(less_than_9_len)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHZq8kCiGd8k",
        "outputId": "36a1616d-8b9a-4d3c-db48-f3a41f77d0cc"
      },
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These stats are for the testing set\n",
            "The min test length is: 1\n",
            "The max test length is: 26\n",
            "The mean test length is: 11.502004650789832\n",
            "The number of test tweets with less than 9 tokens is: 4506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading and extracting TSVs"
      ],
      "metadata": {
        "id": "b7aHvxGWv6n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_freq.zip\n",
        "!echo \"N\"| unzip /content/socialsent_hist_freq.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgfBvVXawvI6",
        "outputId": "9d964da4-de00-44a9-a9f4-072afb7987f1"
      },
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 20:34:09--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_freq.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 521987 (510K) [application/zip]\n",
            "Saving to: ‘socialsent_hist_freq.zip.4’\n",
            "\n",
            "socialsent_hist_fre 100%[===================>] 509.75K   289KB/s    in 1.8s    \n",
            "\n",
            "2022-11-12 20:34:11 (289 KB/s) - ‘socialsent_hist_freq.zip.4’ saved [521987/521987]\n",
            "\n",
            "Archive:  /content/socialsent_hist_freq.zip\n",
            "replace frequent_words/1850.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_adj.zip\n",
        "!echo \"N\"| unzip /content/socialsent_hist_adj.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAN6g11dv_zh",
        "outputId": "48c72a23-23ec-400a-ab28-ab87d1e10efb"
      },
      "execution_count": 596,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 20:34:12--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_adj.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 201855 (197K) [application/zip]\n",
            "Saving to: ‘socialsent_hist_adj.zip.4’\n",
            "\n",
            "socialsent_hist_adj 100%[===================>] 197.12K   207KB/s    in 1.0s    \n",
            "\n",
            "2022-11-12 20:34:13 (207 KB/s) - ‘socialsent_hist_adj.zip.4’ saved [201855/201855]\n",
            "\n",
            "Archive:  /content/socialsent_hist_adj.zip\n",
            "replace adjectives/1850.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2000adj = pd.read_csv(\"/content/adjectives/2000.tsv\", sep=\"\\t\", header=None)\n",
        "df_2000adj.columns = ['Word', 'Sentiment', 'Std']\n",
        "df_2000freq = pd.read_csv(\"/content/frequent_words/2000.tsv\", sep=\"\\t\", header=None)\n",
        "df_2000freq.columns = ['Word', 'Sentiment', 'Std']"
      ],
      "metadata": {
        "id": "EDpyKT1qwTT0"
      },
      "execution_count": 597,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_subreddits.zip\n",
        "!echo \"N\"| unzip /content/socialsent_subreddits.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqMTZ8gYRgHI",
        "outputId": "1698d641-f758-44d2-efc5-4fa6692bd59d"
      },
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 20:34:13--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_subreddits.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15659374 (15M) [application/zip]\n",
            "Saving to: ‘socialsent_subreddits.zip.4’\n",
            "\n",
            "socialsent_subreddi 100%[===================>]  14.93M  2.74MB/s    in 5.7s    \n",
            "\n",
            "2022-11-12 20:34:20 (2.61 MB/s) - ‘socialsent_subreddits.zip.4’ saved [15659374/15659374]\n",
            "\n",
            "Archive:  /content/socialsent_subreddits.zip\n",
            "replace subreddits/.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_files = ['3DS.tsv', \n",
        "'4chan.tsv',\n",
        "'2007scape.tsv',\n",
        "'ACTrade.tsv',\n",
        "'amiugly.tsv',\n",
        "'BabyBumps.tsv',\n",
        "'baseball.tsv',\n",
        "'canada.tsv',\n",
        "'CasualConversation.tsv',\n",
        "'DarkNetMarkets.tsv',\n",
        "'darksouls.tsv',\n",
        "'elderscrollsonline.tsv',\n",
        "'Eve.tsv',\n",
        "'Fallout.tsv',\n",
        "'fantasyfootball.tsv',\n",
        "'GameDeals.tsv',\n",
        "'gamegrumps.tsv',\n",
        "'halo.tsv',\n",
        "'Homebrewing.tsv',\n",
        "'IAmA.tsv',\n",
        "'india.tsv',\n",
        "'jailbreak.tsv',\n",
        "'Jokes.tsv',\n",
        "'KerbalSpaceProgram.tsv',\n",
        "'keto.tsv',\n",
        "'leagueoflegends.tsv',\n",
        "'Libertarian.tsv',\n",
        "'magicTCG.tsv',\n",
        "'MakeupAddiction.tsv',\n",
        "'Naruto.tsv',\n",
        "'nba.tsv',\n",
        "'oculus.tsv',\n",
        "'OkCupid.tsv',\n",
        "'Parenting.tsv',\n",
        "'pathofexile.tsv',\n",
        "'raisedbynarcissists.tsv',\n",
        "'Random_Acts_Of_Amazon.tsv',\n",
        "'science.tsv',\n",
        "'Seattle.tsv',\n",
        "'TalesFromRetail.tsv',\n",
        "'talesfromtechsupport.tsv',\n",
        "'ultrahardcore.tsv',\n",
        "'videos.tsv',\n",
        "'Warthunder.tsv',\n",
        "'whowouldwin.tsv',\n",
        "'xboxone.tsv',\n",
        "'yugioh.tsv',\n",
        "]"
      ],
      "metadata": {
        "id": "MlpvD2rmurcT"
      },
      "execution_count": 599,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dicts=[]\n",
        "for i in range(0,len(list_files)):\n",
        "    dfname='df_'+str(list_files[i])\n",
        "    dfname=dfname.replace('.tsv','')\n",
        "    path=\"/content/subreddits/\" + list_files[i]\n",
        "    dataframe = pd.read_csv(path, sep=\"\\t\", header=None)\n",
        "    dataframe.columns = ['Word', 'Sentiment', 'Std']\n",
        "    dataframe=dataframe.drop(columns=['Std'])\n",
        "    list_dicts.append(dict(dataframe.values))"
      ],
      "metadata": {
        "id": "h9Txu7LuMK_9"
      },
      "execution_count": 600,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine dictionaries\n",
        "def dict_merger(dict1, dict2):\n",
        "    new_dict = {**dict1, **dict2}\n",
        "    return new_dict"
      ],
      "metadata": {
        "id": "PfBXyR8eHAjj"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2000adj=df_2000adj.drop(columns='Std')\n",
        "feature1=dict(df_2000adj.values)\n",
        "df_2000freq=df_2000freq.drop(columns='Std')\n",
        "feature2=dict(df_2000freq.values)"
      ],
      "metadata": {
        "id": "VDw8BKZox-gH"
      },
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature3 = {}\n",
        "for i in range(0, 8):\n",
        "  feature3=dict_merger(feature3,list_dicts[i])\n",
        "\n",
        "feature4 = {}\n",
        "for i in range(8, 16):\n",
        "  feature4=dict_merger(feature4,list_dicts[i])\n",
        "\n",
        "feature5 = {}\n",
        "for i in range(16, 23):\n",
        "  feature5=dict_merger(feature5,list_dicts[i])\n",
        "\n",
        "feature6 = {}\n",
        "for i in range(23, 29):\n",
        "  feature6=dict_merger(feature6,list_dicts[i])\n",
        "\n",
        "feature7 = {}\n",
        "for i in range(29, 34):\n",
        "  feature7=dict_merger(feature7,list_dicts[i])\n",
        "\n",
        "feature8 = {}\n",
        "for i in range(34, 41):\n",
        "  feature8=dict_merger(feature8,list_dicts[i])\n",
        "\n",
        "feature9 = {}\n",
        "for i in range(41, 47):\n",
        "  feature9=dict_merger(feature9,list_dicts[i])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cb9HByXsIn9Q"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting features"
      ],
      "metadata": {
        "id": "qh_n5XtflKiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#one thing that boosted my scores was instead of taking one word per feature, I summed 9 words per feature\n",
        "#I took words at random and oversampled shorter tweets. boosted the F1 score by letting randomization try to hit a good token\n",
        "def lookups(row):\n",
        "  lookup_index=row.name\n",
        "  #print(\"This is the lookup_index: \" + str(lookup_index))\n",
        "  range_len=(df['Token_len'][lookup_index])\n",
        "  #print(\"This is the range_len: \" + str(range_len))\n",
        "  score=[]\n",
        "  for i in range(0, 9):\n",
        "    #print(\"Starting the for loop at: \" + str(i))\n",
        "    token=random.randint(0, range_len) \n",
        "    token -= 1\n",
        "    #print(\"The token is: \" + str(token))\n",
        "    word_tok=df.iloc[lookup_index, 2][token]\n",
        "    #print(\"The word_tok is: \" + str(word_tok))\n",
        "    try:\n",
        "      score.append(current_dict[word_tok])\n",
        "    except:\n",
        "      pass\n",
        "  try:\n",
        "      sum_score=sum(score)\n",
        "  except:\n",
        "      sum_score=0\n",
        "  return sum_score\n",
        "\n",
        "def lookupst(row):\n",
        "  lookup_index=row.name\n",
        "  #print(\"This is the lookup_index: \" + str(lookup_index))\n",
        "  range_len=(dft['Token_len'][lookup_index])\n",
        "  #print(\"This is the range_len: \" + str(range_len))\n",
        "  score=[]\n",
        "  for i in range(0, 9):\n",
        "    #print(\"Starting the for loop at: \" + str(i))\n",
        "    token=random.randint(0, range_len) \n",
        "    token -= 1\n",
        "    #print(\"The token is: \" + str(token))\n",
        "    word_tok=dft.iloc[lookup_index, 2][token]\n",
        "    #print(\"The word_tok is: \" + str(word_tok))\n",
        "    try:\n",
        "      score.append(current_dict[word_tok])\n",
        "    except:\n",
        "      pass\n",
        "  try:\n",
        "      sum_score=sum(score)\n",
        "  except:\n",
        "      sum_score=0\n",
        "  return sum_score\n",
        "\n",
        "def wordlengther(row):\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    longest_word=1\n",
        "    for word in token_list:\n",
        "        if longest_word<len(word):\n",
        "          longest_word=len(word)\n",
        "    log_long=np.log10(longest_word)\n",
        "    return log_long\n",
        "\n",
        "def wordfiver(row):\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    five_counts=1\n",
        "    for word in token_list:\n",
        "        if len(word)>=5:\n",
        "          five_counts+=1\n",
        "    log_five=np.log10(five_counts)\n",
        "    return log_five\n",
        "\n",
        "def wordlengthert(row):\n",
        "    index=row.name\n",
        "    token_list=dft['Twitter_tokens'][index]\n",
        "    longest_word=1\n",
        "    for word in token_list:\n",
        "        if longest_word<len(word):\n",
        "          longest_word=len(word)\n",
        "    log_long=np.log10(longest_word)\n",
        "    return log_long\n",
        "\n",
        "def wordfivert(row):\n",
        "    index=row.name\n",
        "    token_list=dft['Twitter_tokens'][index]\n",
        "    five_counts=1\n",
        "    for word in token_list:\n",
        "        if len(word)>=5:\n",
        "          five_counts+=1\n",
        "    log_five=np.log10(five_counts)\n",
        "    return log_five\n",
        "\n",
        "def mostpos(row):  #need the negative version too, mostneg\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    max_value=0\n",
        "    for word in token_list:\n",
        "      try: pos_value=feature3[word]   #replace with super dictionary\n",
        "      except: pos_value=0\n",
        "      if max_value<pos_value:\n",
        "        max_value=pos_value\n",
        "    return max_value"
      ],
      "metadata": {
        "id": "4qSZDlp0N_9R"
      },
      "execution_count": 668,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature24']=0\n",
        "df['feature24']=df.apply(mostpos,axis=1)"
      ],
      "metadata": {
        "id": "Rk7jxparlsMV"
      },
      "execution_count": 666,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature1']=0\n",
        "df['feature2']=0\n",
        "df['feature3']=0\n",
        "df['feature4']=0\n",
        "df['feature5']=0\n",
        "df['feature6']=0\n",
        "df['feature7']=0\n",
        "df['feature8']=0\n",
        "df['feature9']=0\n",
        "df['feature10']=0\n",
        "df['feature11']=0\n",
        "df['feature12']=0\n"
      ],
      "metadata": {
        "id": "1ZGXMsI8Iu_q"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list=['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9']\n",
        "for i in range(0, len(features_list)):\n",
        "  current_dict=list_dicts[i]\n",
        "  df[features_list[i]]=df.apply(lookups, axis=1)\n",
        "  dft[features_list[i]]=dft.apply(lookupst, axis=1)"
      ],
      "metadata": {
        "id": "-zF7OHmETgXd"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature10']=df['Token_len'].apply(np.log10)\n",
        "dft['feature10']=dft['Token_len'].apply(np.log10)\n",
        "df['feature11']=df.apply(wordlengther, axis=1)\n",
        "df['feature12']=df.apply(wordfiver, axis=1)\n",
        "dft['feature11']=dft.apply(wordlengthert, axis=1)\n",
        "dft['feature12']=dft.apply(wordfivert, axis=1)"
      ],
      "metadata": {
        "id": "j0nu5rs9y5gW"
      },
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature11']=df.apply(wordlengther, axis=1)\n",
        "df['feature12']=df.apply(wordfiver, axis=1)\n",
        "dft['feature11']=dft.apply(wordlengthert, axis=1)\n",
        "dft['feature12']=dft.apply(wordfivert, axis=1)"
      ],
      "metadata": {
        "id": "foYumH0w0CZ5"
      },
      "execution_count": 608,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward Selection of Features"
      ],
      "metadata": {
        "id": "IvcZXeOtTU6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfc=pd.concat([df, dft])\n",
        "Xc=dfc.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "yc=dfc['Label']"
      ],
      "metadata": {
        "id": "3QS-ndW6mk2e"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_feature_maker(x,y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, shuffle=True, random_state=42)\n",
        "  sel = SelectFromModel(RandomForestClassifier(n_estimators = 50))\n",
        "  sel.fit(X_train, y_train)\n",
        "  print(\"The best features to use are: \")\n",
        "  feature_index = sel.get_support(indices=True)\n",
        "  x_new=x.iloc[:,feature_index]\n",
        "  print(x_new.head())\n",
        "  return x_new"
      ],
      "metadata": {
        "id": "_tNVVetTkQtn"
      },
      "execution_count": 610,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuorTbGZT5kQ"
      },
      "execution_count": 610,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xc_selected=best_feature_maker(Xc,yc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hsYY-W1mGnP",
        "outputId": "72d56546-d5ae-4f2e-f989-16e5bee65284"
      },
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best features to use are: \n",
            "   feature1  feature2  feature3  feature4  feature6  feature8  feature9\n",
            "0      0.92      0.35      1.32      0.00     -1.90     -0.58      4.81\n",
            "1      1.68     -0.60     -0.38      1.23      0.05     -2.45      2.24\n",
            "2      2.94      1.10      0.25      0.25     -1.16     -1.69      0.03\n",
            "3      1.26     -1.43      4.93      0.46      1.06     -1.11      2.16\n",
            "4      5.10      4.59     -1.19     -0.52      2.53      2.16      3.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LogReg"
      ],
      "metadata": {
        "id": "JMgubEwbkzGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogRegression:\n",
        "    def __init__(self, feature_number, lr, epochs):      \n",
        "        self.intercept = 0\n",
        "        self.weight = np.zeros(feature_number)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "        z = np.dot(X, self.weight) + self.intercept\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def loss(self, s, y):\n",
        "        return (-y * np.log(s) - (1 - y) * np.log(1 - s)).mean()\n",
        "    \n",
        "    def gradient_descent(self, X, s, y):\n",
        "        return np.dot(X.T, (s - y)) / y.shape[0]\n",
        "    \n",
        "    def gradient_descent_intercept(self, s, y):\n",
        "        return np.mean(s - y)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        losses = []\n",
        "        for i in range(self.epochs):\n",
        "            sigma = self.sigmoid(X)\n",
        "\n",
        "            dW = self.gradient_descent(X , sigma, y)\n",
        "            dintercept = self.gradient_descent_intercept(sigma, y)\n",
        "\n",
        "            self.weight -= self.lr * dW\n",
        "            self.intercept -= self.lr * dintercept\n",
        "\n",
        "            loss = self.loss(sigma, y)\n",
        "            if len(losses) % 1000 == 0:\n",
        "                print(\"The iteration is \" + str(i) + \" and the loss is \" +  str(loss))\n",
        "            losses.append(loss)\n",
        "            if i > 1000:\n",
        "              if losses[-1] > losses[-100] - .0001:     #the difference should be an argument\n",
        "                print(\"The weight is \")\n",
        "                print(self.weight)\n",
        "                print(\"The intercept is \")\n",
        "                print(self.intercept)\n",
        "                break\n",
        "        return losses\n",
        "    \n",
        "    def predict(self, train):\n",
        "        x_new = train\n",
        "        result = self.sigmoid(x_new)\n",
        "        y_pred = np.zeros(result.shape[0])\n",
        "        for i in range(len(y_pred)):\n",
        "            if result[i] >= 0.5: \n",
        "                y_pred[i] = 1\n",
        "            else:\n",
        "                y_pred[i] = 0\n",
        "                continue\n",
        "                \n",
        "        return y_pred\n",
        "      \n",
        "    def metrics(self, pred, test):\n",
        "        y_pred=pred\n",
        "        y_test=test\n",
        "        tp=(sum((y_pred == 1) & (y_test==1)))\n",
        "        fp=(sum((y_pred == 1) & (y_test==0)))\n",
        "        fn=(sum((y_pred == 0) & (y_test==1)))\n",
        "        tn=(sum((y_pred == 0) & (y_test==0)))\n",
        "        confusion_matrix=[[tn, fp], [fn, tp]]\n",
        "        print(\"The confusion matrix is: \")\n",
        "        print(confusion_matrix[0])\n",
        "        print(confusion_matrix[1])\n",
        "        print('The accuracy for the Twitter sentiment is {}'.format(sum(y_pred == y_test) / y_test.shape[0]))\n",
        "        print('The precision for the Twitter sentiment is {}'.format((tp/(tp+fp))))\n",
        "        print('The recall for the Twitter sentiment is {}'.format((tp/(tp+fn))))\n",
        "        print('The F1 score for the Twitter sentiment is {}'.format((2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fn))+(tp/(tp+fp))))))\n",
        "        return confusion_matrix"
      ],
      "metadata": {
        "id": "XSwfy98wRmUv"
      },
      "execution_count": 612,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w_Coim96PYuk",
        "outputId": "871d17fe-aed5-4618-fccb-f7e554ec0261"
      },
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label  \\\n",
              "0  qt original draft 7th book remus lupin survive...      1   \n",
              "1  alciato bee invest 150 million january another...      1   \n",
              "2  lit mum kerry louboutins wonder many willam ow...      1   \n",
              "3  soul train oct 27 halloween special ft dot fin...      1   \n",
              "4  disappointed wwe summerslam want see john cena...      0   \n",
              "\n",
              "                                      Twitter_tokens  Token_len  feature1  \\\n",
              "0  [qt, original, draft, 7th, book, remus, lupin,...         11      0.92   \n",
              "1  [alciato, bee, invest, 150, million, january, ...         13      1.68   \n",
              "2  [lit, mum, kerry, louboutins, wonder, many, wi...         12      2.94   \n",
              "3  [soul, train, oct, 27, halloween, special, ft,...         21      1.26   \n",
              "4  [disappointed, wwe, summerslam, want, see, joh...         10      5.10   \n",
              "\n",
              "   feature2  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
              "0      0.35      1.32      0.00      1.12     -1.90      1.72     -0.58   \n",
              "1     -0.60     -0.38      1.23      0.90      0.05      1.18     -2.45   \n",
              "2      1.10      0.25      0.25      0.00     -1.16      0.88     -1.69   \n",
              "3     -1.43      4.93      0.46      1.28      1.06     -1.28     -1.11   \n",
              "4      4.59     -1.19     -0.52     -1.46      2.53     -3.58      2.16   \n",
              "\n",
              "   feature9  feature10  feature11  feature12  \n",
              "0      4.81   1.041393   1.361728   0.954243  \n",
              "1      2.24   1.113943   0.845098   1.000000  \n",
              "2      0.03   1.079181   1.000000   0.903090  \n",
              "3      2.16   1.322219   0.954243   1.041393  \n",
              "4      3.12   1.000000   1.079181   0.602060  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dcc1ab5-5d9d-447b-ae5e-634c9212d2cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "      <th>Twitter_tokens</th>\n",
              "      <th>Token_len</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qt original draft 7th book remus lupin survive...</td>\n",
              "      <td>1</td>\n",
              "      <td>[qt, original, draft, 7th, book, remus, lupin,...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.12</td>\n",
              "      <td>-1.90</td>\n",
              "      <td>1.72</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>4.81</td>\n",
              "      <td>1.041393</td>\n",
              "      <td>1.361728</td>\n",
              "      <td>0.954243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alciato bee invest 150 million january another...</td>\n",
              "      <td>1</td>\n",
              "      <td>[alciato, bee, invest, 150, million, january, ...</td>\n",
              "      <td>13</td>\n",
              "      <td>1.68</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.18</td>\n",
              "      <td>-2.45</td>\n",
              "      <td>2.24</td>\n",
              "      <td>1.113943</td>\n",
              "      <td>0.845098</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lit mum kerry louboutins wonder many willam ow...</td>\n",
              "      <td>1</td>\n",
              "      <td>[lit, mum, kerry, louboutins, wonder, many, wi...</td>\n",
              "      <td>12</td>\n",
              "      <td>2.94</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.16</td>\n",
              "      <td>0.88</td>\n",
              "      <td>-1.69</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.079181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.903090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>soul train oct 27 halloween special ft dot fin...</td>\n",
              "      <td>1</td>\n",
              "      <td>[soul, train, oct, 27, halloween, special, ft,...</td>\n",
              "      <td>21</td>\n",
              "      <td>1.26</td>\n",
              "      <td>-1.43</td>\n",
              "      <td>4.93</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.28</td>\n",
              "      <td>1.06</td>\n",
              "      <td>-1.28</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1.322219</td>\n",
              "      <td>0.954243</td>\n",
              "      <td>1.041393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disappointed wwe summerslam want see john cena...</td>\n",
              "      <td>0</td>\n",
              "      <td>[disappointed, wwe, summerslam, want, see, joh...</td>\n",
              "      <td>10</td>\n",
              "      <td>5.10</td>\n",
              "      <td>4.59</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>2.53</td>\n",
              "      <td>-3.58</td>\n",
              "      <td>2.16</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.079181</td>\n",
              "      <td>0.602060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dcc1ab5-5d9d-447b-ae5e-634c9212d2cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2dcc1ab5-5d9d-447b-ae5e-634c9212d2cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2dcc1ab5-5d9d-447b-ae5e-634c9212d2cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hmf3dyfPIbSd",
        "outputId": "c1b727c5-e2f5-4391-9feb-712c706fda7f"
      },
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label  \\\n",
              "0  qt original draft 7th book remus lupin survive...      1   \n",
              "1  alciato bee invest 150 million january another...      1   \n",
              "2  lit mum kerry louboutins wonder many willam ow...      1   \n",
              "3  soul train oct 27 halloween special ft dot fin...      1   \n",
              "4  disappointed wwe summerslam want see john cena...      0   \n",
              "\n",
              "                                      Twitter_tokens  Token_len  feature1  \\\n",
              "0  [qt, original, draft, 7th, book, remus, lupin,...         11      0.92   \n",
              "1  [alciato, bee, invest, 150, million, january, ...         13      1.68   \n",
              "2  [lit, mum, kerry, louboutins, wonder, many, wi...         12      2.94   \n",
              "3  [soul, train, oct, 27, halloween, special, ft,...         21      1.26   \n",
              "4  [disappointed, wwe, summerslam, want, see, joh...         10      5.10   \n",
              "\n",
              "   feature2  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
              "0      0.35      1.32      0.00      1.12     -1.90      1.72     -0.58   \n",
              "1     -0.60     -0.38      1.23      0.90      0.05      1.18     -2.45   \n",
              "2      1.10      0.25      0.25      0.00     -1.16      0.88     -1.69   \n",
              "3     -1.43      4.93      0.46      1.28      1.06     -1.28     -1.11   \n",
              "4      4.59     -1.19     -0.52     -1.46      2.53     -3.58      2.16   \n",
              "\n",
              "   feature9  feature10  feature11  feature12  \n",
              "0      4.81   1.041393   1.361728   0.954243  \n",
              "1      2.24   1.113943   0.845098   1.000000  \n",
              "2      0.03   1.079181   1.000000   0.903090  \n",
              "3      2.16   1.322219   0.954243   1.041393  \n",
              "4      3.12   1.000000   1.079181   0.602060  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3f49eaf-b7f9-4ac4-a05f-64c52871a768\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "      <th>Twitter_tokens</th>\n",
              "      <th>Token_len</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qt original draft 7th book remus lupin survive...</td>\n",
              "      <td>1</td>\n",
              "      <td>[qt, original, draft, 7th, book, remus, lupin,...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.12</td>\n",
              "      <td>-1.90</td>\n",
              "      <td>1.72</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>4.81</td>\n",
              "      <td>1.041393</td>\n",
              "      <td>1.361728</td>\n",
              "      <td>0.954243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alciato bee invest 150 million january another...</td>\n",
              "      <td>1</td>\n",
              "      <td>[alciato, bee, invest, 150, million, january, ...</td>\n",
              "      <td>13</td>\n",
              "      <td>1.68</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.18</td>\n",
              "      <td>-2.45</td>\n",
              "      <td>2.24</td>\n",
              "      <td>1.113943</td>\n",
              "      <td>0.845098</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lit mum kerry louboutins wonder many willam ow...</td>\n",
              "      <td>1</td>\n",
              "      <td>[lit, mum, kerry, louboutins, wonder, many, wi...</td>\n",
              "      <td>12</td>\n",
              "      <td>2.94</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.16</td>\n",
              "      <td>0.88</td>\n",
              "      <td>-1.69</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.079181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.903090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>soul train oct 27 halloween special ft dot fin...</td>\n",
              "      <td>1</td>\n",
              "      <td>[soul, train, oct, 27, halloween, special, ft,...</td>\n",
              "      <td>21</td>\n",
              "      <td>1.26</td>\n",
              "      <td>-1.43</td>\n",
              "      <td>4.93</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.28</td>\n",
              "      <td>1.06</td>\n",
              "      <td>-1.28</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1.322219</td>\n",
              "      <td>0.954243</td>\n",
              "      <td>1.041393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disappointed wwe summerslam want see john cena...</td>\n",
              "      <td>0</td>\n",
              "      <td>[disappointed, wwe, summerslam, want, see, joh...</td>\n",
              "      <td>10</td>\n",
              "      <td>5.10</td>\n",
              "      <td>4.59</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>2.53</td>\n",
              "      <td>-3.58</td>\n",
              "      <td>2.16</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.079181</td>\n",
              "      <td>0.602060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3f49eaf-b7f9-4ac4-a05f-64c52871a768')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3f49eaf-b7f9-4ac4-a05f-64c52871a768 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3f49eaf-b7f9-4ac4-a05f-64c52871a768');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 614
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfc=pd.concat([df, dft])\n",
        "Xc=dfc.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "yc=dfc['Label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "Xc, yc, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DM6t2DQNaT4C"
      },
      "execution_count": 615,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experimented with different splits, best performance was to concatenate the train and test sets\n",
        "#and then randomly resample them to create new train and test sets\n",
        "#this gave better variance and improved the score\n",
        "\"\"\"\n",
        "X_train=df.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "X_test=dft.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "y_train=df['Label']\n",
        "y_test=dft['Label']\n",
        "X=X_train\n",
        "y=y_train\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Fj-fW-zITEqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1f724977-7afa-4005-9792-2117f359b344"
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX_train=df.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\\nX_test=dft.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\\ny_train=df['Label']\\ny_test=dft['Label']\\nX=X_train\\ny=y_train\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 616
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "#very minor boost in performance since our features are already of similar scale, but did give a boost"
      ],
      "metadata": {
        "id": "hagr9i64S0Rc"
      },
      "execution_count": 617,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "\n",
        "LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "\n",
        "losses = LogRegSent.fit(X_train_norm, y_train)"
      ],
      "metadata": {
        "id": "4nst7aSnSMh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e19c71-3944-40fe-e159-b78642ac2db6"
      },
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5490925418234074\n",
            "The iteration is 2000 and the loss is 0.5390548701292588\n",
            "The iteration is 3000 and the loss is 0.5337922353077562\n",
            "The iteration is 4000 and the loss is 0.5304582207898911\n",
            "The iteration is 5000 and the loss is 0.528179928205877\n",
            "The iteration is 6000 and the loss is 0.5265571315911195\n",
            "The iteration is 7000 and the loss is 0.5253710953581804\n",
            "The weight is \n",
            "[ 4.90539694  1.52863335  1.47137829  0.8446475  -0.18676662  2.7935135\n",
            "  0.3948279   3.31243839  3.34492439 -0.99615211  0.20200091 -0.64656646]\n",
            "The intercept is \n",
            "-8.188005256966234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "plt.plot(losses)\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "AdozPFsDSOTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ba43cc43-81aa-4102-c6cc-fe5b1a7a33c4"
      },
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 619
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LogRegSent.predict(X_test_norm)"
      ],
      "metadata": {
        "id": "DMlfHTH1HD4S"
      },
      "execution_count": 620,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = LogRegSent.metrics(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSddLO7DtkZ8",
        "outputId": "e0335437-2f4b-4995-a0ea-f8570c77b81d"
      },
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix is: \n",
            "[525, 2304]\n",
            "[258, 6890]\n",
            "The accuracy for the Twitter sentiment is 0.7432093815776285\n",
            "The precision for the Twitter sentiment is 0.7494017837720253\n",
            "The recall for the Twitter sentiment is 0.963905987688864\n",
            "The F1 score for the Twitter sentiment is 0.8432260433239507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test 1 Additional Feature"
      ],
      "metadata": {
        "id": "75Bn-oE-r35D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_add_feature(x,y,feat,target):\n",
        "  x_1=x\n",
        "  x_1.insert(1, feat.name, feat)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.2, random_state=42)\n",
        "  X_train_norm, X_test_norm = mms.fit_transform(X_train), mms.transform(X_test)\n",
        "  feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "  LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "  losses = LogRegSent.fit(X_train_norm, y_train)\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "  plt.plot(losses)\n",
        "  plt.show\n",
        "  y_pred = LogRegSent.predict(X_test_norm)\n",
        "  cm = LogRegSent.metrics(y_pred, y_test)\n",
        "  f1=(2*cm[1][1]/(cm[1][1]+cm[0][1]))*(cm[1][1]/(cm[1][1]+cm[1][0]))/((cm[1][1]/(cm[1][1]+cm[1][0]))+(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "  print(\"The F1 with \" + str(feat.name) + \" is: \" + str(f1) + \" but the target was: \" +str(target))\n",
        "  diff=target-f1\n",
        "  print(\"The difference in F1 score with \" + str(feat.name) + \" is: \" + str(diff))\n",
        "  return diff\n",
        "\n"
      ],
      "metadata": {
        "id": "uy359nLBr7j0"
      },
      "execution_count": 622,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  features_selected = Xc_selected.columns\n",
        "  all_features=Xc.columns\n",
        "  removed_features_names=[]\n",
        "  removed_features=[]\n",
        "  for i in range(0,len(all_features)):\n",
        "    good=0\n",
        "    for j in range(0,len(features_selected)):\n",
        "      if all_features[i] == features_selected[j]:\n",
        "        good-=1\n",
        "    if good==0:\n",
        "      removed_features_names.append(Xc.columns[i])\n",
        "\n",
        "  for k in range(0,len(removed_features_names)):\n",
        "    removed_features.append(Xc[removed_features_names[k]])\n",
        "    print(\"Adding \" + str(removed_features_names[k]) + \" to the removed features list\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1MVe_-sdpBw",
        "outputId": "afed8a83-ca22-48a1-d380-2c13231a0860"
      },
      "execution_count": 623,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding feature5 to the removed features list\n",
            "Adding feature7 to the removed features list\n",
            "Adding feature10 to the removed features list\n",
            "Adding feature11 to the removed features list\n",
            "Adding feature12 to the removed features list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_diff_add=[]\n",
        "f1_selected = 0.8089763431350873\n",
        "for i in range(0,len(removed_features)):\n",
        "  new=removed_features[i]\n",
        "  difference=try_add_feature(Xc_selected,yc,new,f1_selected)\n",
        "  f1_diff_add.append(difference)\n",
        "  print(\"---------------\")\n",
        "for i in range(0,len(removed_features)):\n",
        "  print(\"To remove \" + str(removed_features[i].name) + \" there was a loss of \" + str(f1_diff_add[i]) + \" in F1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CUfsYfJc_-RJ",
        "outputId": "55bce5b9-863a-49fe-f353-8e4d8e005ede"
      },
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5542946537131913\n",
            "The iteration is 2000 and the loss is 0.5415098859948735\n",
            "The iteration is 3000 and the loss is 0.5350831036105181\n",
            "The iteration is 4000 and the loss is 0.5312348315069836\n",
            "The iteration is 5000 and the loss is 0.528725949876204\n",
            "The iteration is 6000 and the loss is 0.5270152294215463\n",
            "The iteration is 7000 and the loss is 0.5258170695202251\n",
            "The weight is \n",
            "[ 4.92802923 -0.31013254  1.66912248  1.51999013  1.01007324  2.79159811\n",
            "  3.30597073  3.3891635 ]\n",
            "The intercept is \n",
            "-9.275533542987649\n",
            "The confusion matrix is: \n",
            "[515, 2314]\n",
            "[269, 6879]\n",
            "The accuracy for the Twitter sentiment is 0.741104540443019\n",
            "The precision for the Twitter sentiment is 0.7482867399108017\n",
            "The recall for the Twitter sentiment is 0.9623670956911025\n",
            "The F1 score for the Twitter sentiment is 0.8419313383513861\n",
            "The F1 with feature5 is: 0.8419313383513861 but the target was: 0.8089763431350873\n",
            "The difference in F1 score with feature5 is: -0.032954995216298855\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5542782480675631\n",
            "The iteration is 2000 and the loss is 0.5414745940424048\n",
            "The iteration is 3000 and the loss is 0.5350247965885233\n",
            "The iteration is 4000 and the loss is 0.5311513111809489\n",
            "The iteration is 5000 and the loss is 0.5286175545542462\n",
            "The iteration is 6000 and the loss is 0.5268837838185411\n",
            "The iteration is 7000 and the loss is 0.5256650720661077\n",
            "The weight is \n",
            "[ 4.91258953  0.45612388 -0.33013194  1.65047512  1.49065336  0.97603395\n",
            "  2.76506982  3.28914374  3.34988358]\n",
            "The intercept is \n",
            "-9.388393527070706\n",
            "The confusion matrix is: \n",
            "[516, 2313]\n",
            "[266, 6882]\n",
            "The accuracy for the Twitter sentiment is 0.7415054625638969\n",
            "The precision for the Twitter sentiment is 0.7484502446982055\n",
            "The recall for the Twitter sentiment is 0.9627867935086738\n",
            "The F1 score for the Twitter sentiment is 0.842195435354586\n",
            "The F1 with feature7 is: 0.842195435354586 but the target was: 0.8089763431350873\n",
            "The difference in F1 score with feature7 is: -0.0332190922194987\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5499930857684872\n",
            "The iteration is 2000 and the loss is 0.5388592748701322\n",
            "The iteration is 3000 and the loss is 0.5335611436103302\n",
            "The iteration is 4000 and the loss is 0.5303226062057539\n",
            "The iteration is 5000 and the loss is 0.5281310531993336\n",
            "The iteration is 6000 and the loss is 0.5265771115997874\n",
            "The weight is \n",
            "[ 4.88283329 -1.57509846  0.44237532 -0.17713604  1.55258261  1.46050094\n",
            "  0.87295026  2.82443809  3.27696225  3.44623882]\n",
            "The intercept is \n",
            "-8.205620925606103\n",
            "The confusion matrix is: \n",
            "[528, 2301]\n",
            "[270, 6878]\n",
            "The accuracy for the Twitter sentiment is 0.742307306805653\n",
            "The precision for the Twitter sentiment is 0.7493190979409522\n",
            "The recall for the Twitter sentiment is 0.9622271964185787\n",
            "The F1 score for the Twitter sentiment is 0.8425307772401545\n",
            "The F1 with feature10 is: 0.8425307772401545 but the target was: 0.8089763431350873\n",
            "The difference in F1 score with feature10 is: -0.0335544341050672\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5498070971768793\n",
            "The iteration is 2000 and the loss is 0.5389951919745027\n",
            "The iteration is 3000 and the loss is 0.5337702895085622\n",
            "The iteration is 4000 and the loss is 0.5305167252584401\n",
            "The iteration is 5000 and the loss is 0.5282861552481046\n",
            "The iteration is 6000 and the loss is 0.526689110674494\n",
            "The iteration is 7000 and the loss is 0.5255173163779396\n",
            "The weight is \n",
            "[ 4.90795306  0.02015801 -1.55952554  0.43425553 -0.1734847   1.54875495\n",
            "  1.4578643   0.88007972  2.82127366  3.27315212  3.43991847]\n",
            "The intercept is \n",
            "-8.236611185166941\n",
            "The confusion matrix is: \n",
            "[528, 2301]\n",
            "[270, 6878]\n",
            "The accuracy for the Twitter sentiment is 0.742307306805653\n",
            "The precision for the Twitter sentiment is 0.7493190979409522\n",
            "The recall for the Twitter sentiment is 0.9622271964185787\n",
            "The F1 score for the Twitter sentiment is 0.8425307772401545\n",
            "The F1 with feature11 is: 0.8425307772401545 but the target was: 0.8089763431350873\n",
            "The difference in F1 score with feature11 is: -0.0335544341050672\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5490925418234075\n",
            "The iteration is 2000 and the loss is 0.5390548701292589\n",
            "The iteration is 3000 and the loss is 0.5337922353077562\n",
            "The iteration is 4000 and the loss is 0.5304582207898911\n",
            "The iteration is 5000 and the loss is 0.528179928205877\n",
            "The iteration is 6000 and the loss is 0.5265571315911195\n",
            "The iteration is 7000 and the loss is 0.5253710953581804\n",
            "The weight is \n",
            "[ 4.90539694 -0.64656646  0.20200091 -0.99615211  0.3948279  -0.18676662\n",
            "  1.52863335  1.47137829  0.8446475   2.7935135   3.31243839  3.34492439]\n",
            "The intercept is \n",
            "-8.188005256966237\n",
            "The confusion matrix is: \n",
            "[525, 2304]\n",
            "[258, 6890]\n",
            "The accuracy for the Twitter sentiment is 0.7432093815776285\n",
            "The precision for the Twitter sentiment is 0.7494017837720253\n",
            "The recall for the Twitter sentiment is 0.963905987688864\n",
            "The F1 score for the Twitter sentiment is 0.8432260433239507\n",
            "The F1 with feature12 is: 0.8432260433239507 but the target was: 0.8089763431350873\n",
            "The difference in F1 score with feature12 is: -0.03424970018886342\n",
            "To remove feature5 there was a loss of -0.032954995216298855 in F1\n",
            "To remove feature7 there was a loss of -0.0332190922194987 in F1\n",
            "To remove feature10 there was a loss of -0.0335544341050672 in F1\n",
            "To remove feature11 there was a loss of -0.0335544341050672 in F1\n",
            "To remove feature12 there was a loss of -0.03424970018886342 in F1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(removed_features)):\n",
        "  print(\"To remove \" + str(removed_features[i].name) + \" there was a loss of \" + str(f1_diff_add[i]) + \" in F1\")"
      ],
      "metadata": {
        "id": "rsK5cb3dC-6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b79021-cfaf-4055-c3eb-c079a9aee784"
      },
      "execution_count": 625,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To remove feature5 there was a loss of -0.032954995216298855 in F1\n",
            "To remove feature7 there was a loss of -0.0332190922194987 in F1\n",
            "To remove feature10 there was a loss of -0.0335544341050672 in F1\n",
            "To remove feature11 there was a loss of -0.0335544341050672 in F1\n",
            "To remove feature12 there was a loss of -0.03424970018886342 in F1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try 1 Remove Feature"
      ],
      "metadata": {
        "id": "-5A_vwhaWKCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_remove_feature(x,y,feat,target):\n",
        "  x_1=x\n",
        "  x_1=x_1.drop(columns=feat)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.2, random_state=42)\n",
        "  X_train_norm, X_test_norm = mms.fit_transform(X_train), mms.transform(X_test)\n",
        "  feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "  LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "  losses = LogRegSent.fit(X_train_norm, y_train)\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "  plt.plot(losses)\n",
        "  plt.show\n",
        "  y_pred = LogRegSent.predict(X_test_norm)\n",
        "  cm = LogRegSent.metrics(y_pred, y_test)\n",
        "  f1=(2*cm[1][1]/(cm[1][1]+cm[0][1]))*(cm[1][1]/(cm[1][1]+cm[1][0]))/((cm[1][1]/(cm[1][1]+cm[1][0]))+(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "  print(\"The F1 with \" + str(feat) + \" is: \" + str(f1) + \" but the target was: \" +str(target))\n",
        "  diff=target-f1\n",
        "  print(\"The difference in F1 score without \" + str(feat) + \" is: \" + str(diff))\n",
        "  return diff\n",
        "\n"
      ],
      "metadata": {
        "id": "b8_3fAeyWJm8"
      },
      "execution_count": 670,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features=Xc.columns\n",
        "f1_diff_rem=[]\n",
        "f1_selected = 0.8089763431350873\n",
        "for i in range(0,len(all_features)):\n",
        "  new=all_features[i]\n",
        "  difference=try_remove_feature(Xc_selected,yc,new,f1_selected)\n",
        "  f1_diff_rem.append(difference)\n",
        "  print(\"---------------\")\n",
        "for i in range(0,len(all_features)):\n",
        "  print(\"To remove \" + str(all_features[i].name) + \" there was a loss of \" + str(f1_diff_rem[i]) + \" in F1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24OBixYSW3O2",
        "outputId": "a85bbeee-3f9f-4083-c919-3a4c05c267d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5534896262934913\n",
            "The iteration is 2000 and the loss is 0.5458199971336917\n",
            "The iteration is 3000 and the loss is 0.5422420631910059\n",
            "The iteration is 4000 and the loss is 0.5401038599691866\n",
            "The iteration is 5000 and the loss is 0.5386882771074364\n",
            "The weight is \n",
            "[-0.71535579  0.17361531 -0.95664711  0.65020286  0.1303353   1.68789103\n",
            "  1.68502729  1.27769542  3.01769152  3.43443343  3.74741856]\n",
            "The intercept is \n",
            "-5.8843111287774335\n",
            "The confusion matrix is: \n",
            "[417, 2412]\n",
            "[198, 6950]\n",
            "The accuracy for the Twitter sentiment is 0.7383983161270923\n",
            "The precision for the Twitter sentiment is 0.7423627430036317\n",
            "The recall for the Twitter sentiment is 0.972299944040291\n",
            "The F1 score for the Twitter sentiment is 0.8419139915202907\n",
            "The F1 with feature1 is: 0.8419139915202907 but the target was: 0.8089763431350873\n",
            "The difference in F1 score without feature1 is: -0.03293764838520341\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5501888253319414\n",
            "The iteration is 2000 and the loss is 0.5402093472113476\n",
            "The iteration is 3000 and the loss is 0.5350671566867828\n",
            "The iteration is 4000 and the loss is 0.531843936229779\n",
            "The iteration is 5000 and the loss is 0.529658405047101\n",
            "The iteration is 6000 and the loss is 0.5281119233503161\n",
            "The weight is \n",
            "[ 4.95603387 -0.69217795  0.18366411 -1.0139047   0.48276549 -0.17759229\n",
            "  1.67351493  0.91351518  2.86423567  3.50310404  3.51067121]\n",
            "The intercept is \n",
            "-7.757692667628102\n",
            "The confusion matrix is: \n",
            "[517, 2312]\n",
            "[262, 6886]\n",
            "The accuracy for the Twitter sentiment is 0.7420066152149944\n",
            "The precision for the Twitter sentiment is 0.7486410089149815\n",
            "The recall for the Twitter sentiment is 0.9633463905987689\n",
            "The F1 score for the Twitter sentiment is 0.8425302826379543\n",
            "The F1 with feature2 is: 0.8425302826379543 but the target was: 0.8089763431350873\n",
            "The difference in F1 score without feature2 is: -0.033553939502867\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizations"
      ],
      "metadata": {
        "id": "4abZieyLZrX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "some visualization of how much the F1 difference is for each feature\n",
        "order the features from best to worst with a label of each feature\n",
        "that way we can try to describe why the best measured better\n",
        "and why the worst measured worse\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qZ_zO2MWZuYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify our LogReg against sklearn"
      ],
      "metadata": {
        "id": "KjL4vj0yvd5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calling sklearn to compare. checks out my math above is correct!\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "confusion_matrix_twitter = confusion_matrix(y_test, y_pred)\n",
        "print(\"The confusion matrix for Twitter sentinment:\")\n",
        "print(confusion_matrix_twitter)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_twitter)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNWDZ8A8Sbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "print(\"The confusion matrix for Twitter sentiment:\")\n",
        "print(confusion_matrix_twitter)\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dy9yad9Bs3Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "E_I7rz3jSeDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "POPn5VzdWvnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I implemented it from scratch above, just using this as a benchmark to test my code. \n",
        "#My code's metrics are really really close so I consider that a win\n",
        "from sklearn import metrics  \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#X=np.concatenate((X_train_norm, X_test_norm))\n",
        "#y=np.concatenate((y_train, y_test))\n",
        "#y.loc[y.Label == 2, 'Label'] = 1\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
        "Xc, yc, test_size=0.33, random_state=42)\n",
        "#X_train2, X_test2, y_train2, y_test2 = X_train_norm, X_test_norm, y_train, y_test\n",
        "goodmodel = LogisticRegression()\n",
        "goodmodel.fit(X_train2, y_train2)\n",
        "y_pred2 = pd.Series(goodmodel.predict(X_test2))\n",
        "confusion_matrix_twitter2 = confusion_matrix(y_test2, y_pred2)\n",
        "print(\"The confusion matrix for Twitter sentiment:\")\n",
        "print(confusion_matrix_twitter2)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_twitter2)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"Precision:\", metrics.precision_score(y_test2, y_pred2))\n",
        "print(\"Recall:\", metrics.recall_score(y_test2, y_pred2))\n",
        "print(\"F1:\"), metrics.f1_score(y_test2, y_pred2)"
      ],
      "metadata": {
        "id": "glUnTXt8om5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test2"
      ],
      "metadata": {
        "id": "YMFkOfozo6in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2"
      ],
      "metadata": {
        "id": "QOZLX2oio7Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Complete\")"
      ],
      "metadata": {
        "id": "xR1--HPQpTwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow about 16min for runtime\n",
        "#Extract all features and put them in on data frame\n",
        "\n",
        "def feature_extraction(data_location, label_location):\n",
        "  df = pd.read_csv(data_location, header=None)\n",
        "  df.columns = ['TWEET']\n",
        "\n",
        "  df[\"Tweet Tokens\"] = np.nan\n",
        "  df[\"Count: Words in + Lexicon\"] = np.nan\n",
        "  df[\"Count: Words in - Lexicon\"] = np.nan\n",
        "  df[\"Contain The word NO? \"] = np.nan\n",
        "  df[\"Count: Nouns\"] = np.nan\n",
        "  df[\"Ratio: Unique Words-Total Words\"] = np.nan\n",
        "  df[\"Ratio: Stop Words-Total Words\"] = np.nan\n",
        "  df[\"Count: Adjectives in Tweet\"] = np.nan\n",
        "  df[\"Log: Tweet word count\"] = np.nan\n",
        "  df[\"Log: Length of Longest Word in Tweet\"] = np.nan\n",
        "  df[\"Log: Count of Words with 5+ Characters\"] = np.nan\n",
        "\n",
        "  # ADD LABELS COLUMN TO DF \n",
        "  labels = pd.read_csv(label_location, sep=\"\\n\", header=None)\n",
        "  df = pd.concat([df,labels], axis = 1)\n",
        "  df.rename(columns = {0:'Labels'}, inplace = True)\n",
        "\n",
        "  # DROP NEUTRAL LABELS FROM DF\n",
        "  df.drop(df.loc[df['Labels']==1].index, inplace=True)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # CHANGE ALL 2 LABEL VALUES TO 1 \n",
        "  for i in range(0, len(df.index)):\n",
        "    if df['Labels'].values[i] == 2:\n",
        "      df.at[i,'Labels'] = 1\n",
        "\n",
        "  # CLEAN TWEETS\n",
        "  pattern_a = r'[^A-Za-z0-9]+'\n",
        "  pattern_b = r'\\b\\w{1,1}\\b'\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].lower()\n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].replace('@user', '')\n",
        "    df['TWEET'].values[i] = re.sub(pattern_a, ' ', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(pattern_b, '', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(emoji_pattern, '', df['TWEET'].values[i])\n",
        "\n",
        "  #TOKENIZE TWEETS\n",
        "  df['Tweet Tokens'] = df['Tweet Tokens'].astype('object')\n",
        "  for i in range(0, len(df.index)):\n",
        "    \n",
        "    tokens = df['TWEET'].values[i].split()\n",
        "    df.at[i, 'Tweet Tokens'] = tokens\n",
        "\n",
        "  #Create Positive and Negative Lexicons\n",
        "  pos_lexicon = []\n",
        "  neg_lexicon = []\n",
        "\n",
        "  for i in range(0, len(subreddit_dataframes)):               \n",
        "    for j in range(0, len(subreddit_dataframes[i].index)):    \n",
        "\n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] >= 0:         \n",
        "        pos_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "      \n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] < 0:         \n",
        "        neg_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "\n",
        "\n",
        "  pos_lexicon = [*set(pos_lexicon)]   # Remove duplicate values from + lexicon\n",
        "  neg_lexicon = [*set(neg_lexicon)]   # Remove duplicate values from - lexicon\n",
        "\n",
        "\n",
        "  #Handle duplicate words in postitive and negative lexicon\n",
        "  same_wrds = set(pos_lexicon).intersection(neg_lexicon)      #get set of all words that appear in both psoitive and Negative Lexicon\n",
        "                                                              #https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches\n",
        "\n",
        "  word_vals_dict = dict.fromkeys(same_wrds, 0)                # Create a dictionary to hold of all words found in positive and negative lexicons     \n",
        "  sentiment_vals2sum = []\n",
        "\n",
        "  for k in range(0, len(same_wrds)):    # In the set of words identified in positive and negative lexicon\n",
        "  \n",
        "    i = same_wrds.pop()                 # i will return one word from the set, then the following with each iteration\n",
        "    same_wrds.add(i)                    # https://stackoverflow.com/questions/59825/how-to-retrieve-an-element-from-a-set-without-removing-it\n",
        "\n",
        "    sentiment_vals2sum = []             # Will store the Sentiment Scores collected across data frames \n",
        "\n",
        "    for j in range(0, len(subreddit_dataframes)):                    # in range of dataframes(44)\n",
        "      is_wrd_there = i in subreddit_dataframes[j]['Word'].unique()   # Return true or false. True if desired word 'i' is in the data frame being checked false if not (ls_df_names[0], ls_df_names[1],...)\n",
        "      if is_wrd_there is True:                              # If true... \n",
        "\n",
        "        mask1 = subreddit_dataframes[j]['Word'].values == i                  # Get the sentiment value of the word from its dataframe \n",
        "                                                                    # https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
        "                                                      \n",
        "        sentiment_vals2sum.append(subreddit_dataframes[j][mask1].iat[0,1])   # append sentiment value to list where they are stored eg. sentiment_vals2sum \n",
        "        num_avg = mean(sentiment_vals2sum)                          # Take the mean of the sentiment scores collected in the list above(these are all sentiment scores for one word collected across dataframes where the word was found 'True')\n",
        "        word_vals_dict[i] = num_avg  \n",
        "\n",
        "  # Remove words that now have a clear positive or negative classification\n",
        "  for w in word_vals_dict.items():        # .items() returns a tuple of (word, score). See Cell above for all words: scores in dict\n",
        "    if w[1] >= 0:                         # if w[1] (the score) is greater than 0...\n",
        "      neg_lexicon.remove(w[0])            # remove it from the negative lexicon\n",
        "    if w[1] < 0:                          # If w[1] (the score) is less than 0...\n",
        "      pos_lexicon.remove(w[0])            # remove the word from the positive lexicon\n",
        "\n",
        "  # COUNT POSITIVE AND NEGATIVE WORDS\n",
        "  neg_lex_set = set(neg_lexicon)\n",
        "  pos_lex_set = set(pos_lexicon)\n",
        "\n",
        "  for i in range(0, len(df.index)):\n",
        "    x = set(df['Tweet Tokens'][i])\n",
        "    df['Count: Words in + Lexicon'].values[i] = len(x.intersection(pos_lex_set))\n",
        "    df['Count: Words in - Lexicon'].values[i] = len(x.intersection(neg_lex_set))\n",
        "\n",
        "  # DOES TWEET CONTAIN NO\n",
        "  for i in range(0, len(df.index)):                       # In the range 0 to length of the tweets dataframe         # Tokenize and lowercase tweets \n",
        "    if 'no' in df['Tweet Tokens'][i]:                                    # If no is in tweet dataframe value is 1 if not value is zero\n",
        "      df['Contain The word NO? '].values[i] = 1\n",
        "    else: \n",
        "      df['Contain The word NO? '].values[i] = 0\n",
        "\n",
        "  # COUNT NOUNS IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    noun_definitions = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in noun_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Nouns'].values[i] = count    \n",
        "\n",
        "  # RATIO: UNIQUE TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    ratio = len(np.unique(x)) / len(tokens)\n",
        "    df['Ratio: Unique Words-Total Words'].values[i] = ratio    \n",
        "\n",
        "  # STOP WORDS TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    stop_wrds_count = [w for w in tokens if w in stop_words]\n",
        "    ratio = len(stop_wrds_count) / len(tokens)\n",
        "    df['Ratio: Stop Words-Total Words'].values[i] = ratio\n",
        "\n",
        "  #ADJECTIVES IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    adj_definitions = ['JJ', 'JJR', 'JJS ']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in adj_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Adjectives in Tweet'].values[i] = count\n",
        "\n",
        "  # LOG OF TWEET WORD COUNT \n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]       #tokenize tweets \n",
        "    log_val = math.log(len(tokens))\n",
        "    df['Log: Tweet word count'].values[i] = log_val\n",
        "\n",
        "\n",
        "  # LOG LENGTH OF LONGEST WORD IN TWEET\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]   #tokenize tweets \n",
        "    longest_wrd = max(tokens, key=len)\n",
        "    log_val =  math.log(len(longest_wrd))\n",
        "    df['Log: Length of Longest Word in Tweet'].values[i] = log_val\n",
        "\n",
        "  #LOG OF COUNT OF WORD WITH 5+ CHARACTERS\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]    #tokenize tweets\n",
        "    count = 0\n",
        "      \n",
        "    if any(len(i) >= 5 for i in tokens) is True:\n",
        "\n",
        "      for j in range(0, len(tokens)):\n",
        "        if len(tokens[j]) >= 5:\n",
        "          count = count +1\n",
        "\n",
        "      log_val = math.log(count)\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = log_val\n",
        "      \n",
        "    else:\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = 0\n",
        "\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "92GOZSc0Nmps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How to run: \n",
        "# dataframe = feature_extraction(data_location, label_location)"
      ],
      "metadata": {
        "id": "p45NGKHsMeWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}