{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dldowning/Fall2022-5222/blob/main/All_Features_Downing_Roberts_5222_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "2Fg7eZRAlOgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0gm-p1OwcOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0538b7-a92b-4f10-ba5a-d3dccdb3ef27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=50e7d39fe89825500741de3538f274167dff5f630e23967b2e58d1b417f7a5ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e3/f2/1de1c2e3ed742e1df73e0f15d58864e50c7e64f607b548d6cf\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "%pip install emoji\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import nltk\n",
        "from google.colab import files\n",
        "import matplotlib as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import requests\n",
        "import string\n",
        "import random\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "import csv\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import emoji\n",
        "import plotly.graph_objects as go\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating dataframe"
      ],
      "metadata": {
        "id": "ki0KdvZFk91C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1ubIaCqJnOzG-m_ns7VmdV87Ecs349BbG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMr-smqMOwym",
        "outputId": "588c39db-0878-43ad-fb08-3487a89cf5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ubIaCqJnOzG-m_ns7VmdV87Ecs349BbG\n",
            "To: /content/tweets_extracted.csv\n",
            "\r  0% 0.00/18.3M [00:00<?, ?B/s]\r 66% 12.1M/18.3M [00:00<00:00, 118MB/s]\r100% 18.3M/18.3M [00:00<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1C8ARH_yok3uOvirD_oKvgEmAR22SuC9R\"\n",
        "response = requests.get(URL)\n",
        "open(\"train_text_labels.csv\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpuC3U1RnsOJ",
        "outputId": "5de4f662-9374-43db-f2cc-ca76a472bb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5123208"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1z0URnDJ8ck38mQ4CvHi5TUkly8e46glP\"\n",
        "response = requests.get(URL)\n",
        "open(\"test_text.txt\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv3I3RB99McR",
        "outputId": "35207752-4cc3-4f34-d18d-3113f0e8207b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1156877"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1xWQ2Lpf866Be4OR8J-cJHuY1S25dWppf\"\n",
        "response = requests.get(URL)\n",
        "open(\"test_labels.txt\", \"wb\").write(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCzr8I-pCtIh",
        "outputId": "a594ec19-f429-43eb-a638-e196d0cb151b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36850"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"/content/train_text_labels.csv\", header=None)\n",
        "df0.columns = ['Twitter', 'Label']\n",
        "len(df0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpaK7zlWlYbh",
        "outputId": "05ca8cb4-ae60-4ea1-bf7c-dc86a7fbcdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45615"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft = pd.read_csv(\"/content/test_text.txt\", sep=\"\\n\", header=None, quoting=csv.QUOTE_NONE)\n",
        "dft.columns = ['Twitter']\n",
        "len(dft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrWP7cBN67Gj",
        "outputId": "d747ea4e-bbfa-476e-fe8d-805e0eae2de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12284"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftl = pd.read_csv(\"/content/test_labels.txt\", sep=\"\\n\", header=None)\n",
        "dftl.columns = ['Label']\n",
        "len(dftl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAyC71rtA_xv",
        "outputId": "3210863f-e037-4bd3-c4bd-875e4ec1ef39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12284"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft['Label']=dftl['Label']\n",
        "dft.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4v2zs-HKFrQL",
        "outputId": "1ff4e617-81a9-4565-c02c-7a66c420f0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label\n",
              "0  @user @user what do these '1/2 naked pics' hav...      1\n",
              "1  OH: “I had a blue penis while I was this” [pla...      1\n",
              "2  @user @user That's coming, but I think the vic...      1\n",
              "3  I think I may be finally in with the in crowd ...      2\n",
              "4  @user Wow,first Hugo Chavez and now Fidel Cast...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f787b5c6-d1e8-4211-b457-f39dfb5acafc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user That's coming, but I think the vic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I think I may be finally in with the in crowd ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f787b5c6-d1e8-4211-b457-f39dfb5acafc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f787b5c6-d1e8-4211-b457-f39dfb5acafc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f787b5c6-d1e8-4211-b457-f39dfb5acafc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0['Label'].value_counts()\n",
        "#0\tnegative\n",
        "#1\tneutral\n",
        "#2\tpositive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peakGoADUHke",
        "outputId": "e2a3769a-0b4a-4540-d66c-6d3025838ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    20673\n",
              "2    17849\n",
              "0     7093\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the neutrals\n",
        "df = df0[df0['Label'] != 1]\n",
        "df.loc[df.Label == 2, 'Label'] = 1\n",
        "df=df.reset_index(drop=True)\n",
        "len(df)"
      ],
      "metadata": {
        "id": "47HFm_YlozWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d283ff1-50b4-4560-c1a0-8df91113a5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24942"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft = dft[dft['Label'] != 1]\n",
        "dft=dft.reset_index(drop=True)\n",
        "dft.loc[dft.Label == 2, 'Label'] = 1\n",
        "len(df)\n",
        "len(dft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6dIwcfpF97G",
        "outputId": "c0ca0d38-4f23-4cfe-ad49-d3614352daa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6347"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_original_Tweets = df[['Twitter']].copy()\n",
        "dft_original_Tweets = dft[['Twitter']].copy()"
      ],
      "metadata": {
        "id": "Aan79blBBlii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tweetcleanandtoke(dataframe,colname,newcolname):\n",
        "  stop = stopwords.words('english')\n",
        "  pattern_a = r'[^A-Za-z0-9]+' #non-alphanumeric\n",
        "  pattern_b = r'\\b\\w{1,1}\\b' #repeated words\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):                       \n",
        "    dataframe[colname].values[i] = dataframe[colname].values[i].lower()\n",
        "    dataframe[colname].values[i] = dataframe[colname].values[i].replace('@user', '')\n",
        "    dataframe[colname].values[i] = re.sub(emoji_pattern, '', dataframe[colname].values[i])\n",
        "    dataframe[colname].values[i] = re.sub(pattern_a, ' ', dataframe[colname].values[i])\n",
        "    dataframe[colname].values[i] = re.sub(pattern_b, '', dataframe[colname].values[i])\n",
        "    \n",
        "\n",
        "  dataframe[colname] = dataframe[colname].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "  rowname = dataframe[colname].name\n",
        "  dataframe[newcolname]=0\n",
        "  dataframe[newcolname] = dataframe.apply(lambda row: nltk.word_tokenize(row[rowname]), axis=1)\n",
        "\n",
        "  return dataframe\n",
        "  "
      ],
      "metadata": {
        "id": "rRU76z3L7Z_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=tweetcleanandtoke(df,'Twitter','Twitter_tokens')\n",
        "dft=tweetcleanandtoke(dft,'Twitter','Twitter_tokens')"
      ],
      "metadata": {
        "id": "uIgjtTsp9kUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Token_len']=df['Twitter_tokens'].apply(len)\n",
        "dft['Token_len']=dft['Twitter_tokens'].apply(len)\n",
        "\n"
      ],
      "metadata": {
        "id": "aoASGVI0tzhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the tokens for some EDA, also verifying I have no length 0\n",
        "list_of_lengths=[]\n",
        "less_than_9_len=[]\n",
        "for i in range (0, len(df)):\n",
        "  try:\n",
        "    list_of_lengths.append(len(df['Twitter_tokens'][i]));\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    if len(df['Twitter_tokens'][i]) < 9:\n",
        "      less_than_9_len.append(str(i));\n",
        "  except:\n",
        "    pass\n",
        "print(\"These stats are for the training set\")\n",
        "print(\"The min length is: \" + str(min(list_of_lengths)))\n",
        "print(\"The max length is: \" + str(max(list_of_lengths)))\n",
        "print(\"The mean length is: \" + str(mean(list_of_lengths)))\n",
        "print(\"The number of tweets with less than 9 tokens is: \" + str(len(less_than_9_len)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1ZY4K-nhkIQ",
        "outputId": "ddd7ec28-6bba-48ea-fa83-2c49ca1633f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These stats are for the training set\n",
            "The min length is: 1\n",
            "The max length is: 26\n",
            "The mean length is: 11.502004650789832\n",
            "The number of tweets with less than 9 tokens is: 4506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_lengths=[]\n",
        "less_than_9_len=[]\n",
        "for i in range (0, len(dft)):\n",
        "  try:\n",
        "    list_of_lengths.append(len(dft['Twitter_tokens'][i]));\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    if len(dft['Twitter_tokens'][i]) < 9:\n",
        "      less_than_9_len.append(str(i));\n",
        "  except:\n",
        "    pass\n",
        "print(\"These stats are for the testing set\")\n",
        "print(\"The min test length is: \" + str(min(list_of_lengths)))\n",
        "print(\"The max test length is: \" + str(max(list_of_lengths)))\n",
        "print(\"The mean test length is: \" + str(mean(list_of_lengths)))\n",
        "print(\"The number of test tweets with less than 9 tokens is: \" + str(len(less_than_9_len)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHZq8kCiGd8k",
        "outputId": "02495c5a-bb16-4c26-899f-6f84cd302bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These stats are for the testing set\n",
            "The min test length is: 1\n",
            "The max test length is: 20\n",
            "The mean test length is: 9.237277453915235\n",
            "The number of test tweets with less than 9 tokens is: 2587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading and extracting TSVs"
      ],
      "metadata": {
        "id": "b7aHvxGWv6n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_freq.zip\n",
        "!echo \"N\"| unzip /content/socialsent_hist_freq.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgfBvVXawvI6",
        "outputId": "6b18ad97-b4ee-4d87-8fd2-339565750687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-26 20:50:08--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_freq.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 521987 (510K) [application/zip]\n",
            "Saving to: ‘socialsent_hist_freq.zip’\n",
            "\n",
            "socialsent_hist_fre 100%[===================>] 509.75K   873KB/s    in 0.6s    \n",
            "\n",
            "2022-11-26 20:50:09 (873 KB/s) - ‘socialsent_hist_freq.zip’ saved [521987/521987]\n",
            "\n",
            "Archive:  /content/socialsent_hist_freq.zip\n",
            "   creating: frequent_words/\n",
            "  inflating: frequent_words/1850.tsv  \n",
            "  inflating: frequent_words/1860.tsv  \n",
            "  inflating: frequent_words/1870.tsv  \n",
            "  inflating: frequent_words/1880.tsv  \n",
            "  inflating: frequent_words/1890.tsv  \n",
            "  inflating: frequent_words/1900.tsv  \n",
            "  inflating: frequent_words/1910.tsv  \n",
            "  inflating: frequent_words/1920.tsv  \n",
            "  inflating: frequent_words/1930.tsv  \n",
            "  inflating: frequent_words/1940.tsv  \n",
            "  inflating: frequent_words/1950.tsv  \n",
            "  inflating: frequent_words/1960.tsv  \n",
            "  inflating: frequent_words/1970.tsv  \n",
            "  inflating: frequent_words/1980.tsv  \n",
            "  inflating: frequent_words/1990.tsv  \n",
            "  inflating: frequent_words/2000.tsv  \n",
            "  inflating: frequent_words/README.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/frequent_words/\n",
            "  inflating: __MACOSX/frequent_words/._README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_adj.zip\n",
        "!echo \"N\"| unzip /content/socialsent_hist_adj.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAN6g11dv_zh",
        "outputId": "7b2c3bed-2096-4a6a-a55d-aa0e8e251aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-26 20:50:09--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_hist_adj.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 201855 (197K) [application/zip]\n",
            "Saving to: ‘socialsent_hist_adj.zip’\n",
            "\n",
            "socialsent_hist_adj 100%[===================>] 197.12K   677KB/s    in 0.3s    \n",
            "\n",
            "2022-11-26 20:50:09 (677 KB/s) - ‘socialsent_hist_adj.zip’ saved [201855/201855]\n",
            "\n",
            "Archive:  /content/socialsent_hist_adj.zip\n",
            "   creating: adjectives/\n",
            "  inflating: adjectives/1850.tsv     \n",
            "  inflating: adjectives/1860.tsv     \n",
            "  inflating: adjectives/1870.tsv     \n",
            "  inflating: adjectives/1880.tsv     \n",
            "  inflating: adjectives/1890.tsv     \n",
            "  inflating: adjectives/1900.tsv     \n",
            "  inflating: adjectives/1910.tsv     \n",
            "  inflating: adjectives/1920.tsv     \n",
            "  inflating: adjectives/1930.tsv     \n",
            "  inflating: adjectives/1940.tsv     \n",
            "  inflating: adjectives/1950.tsv     \n",
            "  inflating: adjectives/1960.tsv     \n",
            "  inflating: adjectives/1970.tsv     \n",
            "  inflating: adjectives/1980.tsv     \n",
            "  inflating: adjectives/1990.tsv     \n",
            "  inflating: adjectives/2000.tsv     \n",
            "  inflating: adjectives/README.txt   \n",
            "   creating: __MACOSX/adjectives/\n",
            "  inflating: __MACOSX/adjectives/._README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2000adj = pd.read_csv(\"/content/adjectives/2000.tsv\", sep=\"\\t\", header=None)\n",
        "df_2000adj.columns = ['Word', 'Sentiment', 'Std']\n",
        "df_2000freq = pd.read_csv(\"/content/frequent_words/2000.tsv\", sep=\"\\t\", header=None)\n",
        "df_2000freq.columns = ['Word', 'Sentiment', 'Std']"
      ],
      "metadata": {
        "id": "EDpyKT1qwTT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/projects/socialsent/files/socialsent_subreddits.zip\n",
        "!echo \"N\"| unzip /content/socialsent_subreddits.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqMTZ8gYRgHI",
        "outputId": "eea26534-0519-43e2-c255-9d745a685edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-26 20:50:10--  https://nlp.stanford.edu/projects/socialsent/files/socialsent_subreddits.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15659374 (15M) [application/zip]\n",
            "Saving to: ‘socialsent_subreddits.zip’\n",
            "\n",
            "socialsent_subreddi 100%[===================>]  14.93M  6.76MB/s    in 2.2s    \n",
            "\n",
            "2022-11-26 20:50:12 (6.76 MB/s) - ‘socialsent_subreddits.zip’ saved [15659374/15659374]\n",
            "\n",
            "Archive:  /content/socialsent_subreddits.zip\n",
            "   creating: subreddits/\n",
            "  inflating: subreddits/.zip         \n",
            "  inflating: subreddits/2007scape.tsv  \n",
            "  inflating: subreddits/3DS.tsv      \n",
            "  inflating: subreddits/4chan.tsv    \n",
            "  inflating: subreddits/ACTrade.tsv  \n",
            "  inflating: subreddits/AdviceAnimals.tsv  \n",
            "  inflating: subreddits/amiugly.tsv  \n",
            "  inflating: subreddits/Anarcho_Capitalism.tsv  \n",
            "  inflating: subreddits/Android.tsv  \n",
            "  inflating: subreddits/anime.tsv    \n",
            "  inflating: subreddits/apple.tsv    \n",
            "  inflating: subreddits/archeage.tsv  \n",
            "  inflating: subreddits/AskMen.tsv   \n",
            "  inflating: subreddits/askscience.tsv  \n",
            "  inflating: subreddits/AskWomen.tsv  \n",
            "  inflating: subreddits/asoiaf.tsv   \n",
            "  inflating: subreddits/atheism.tsv  \n",
            "  inflating: subreddits/australia.tsv  \n",
            "  inflating: subreddits/aww.tsv      \n",
            "  inflating: subreddits/BabyBumps.tsv  \n",
            "  inflating: subreddits/baseball.tsv  \n",
            "  inflating: subreddits/battlefield_4.tsv  \n",
            "  inflating: subreddits/bestof.tsv   \n",
            "  inflating: subreddits/bicycling.tsv  \n",
            "  inflating: subreddits/BigBrother.tsv  \n",
            "  inflating: subreddits/Bitcoin.tsv  \n",
            "  inflating: subreddits/boardgames.tsv  \n",
            "  inflating: subreddits/bodybuilding.tsv  \n",
            "  inflating: subreddits/books.tsv    \n",
            "  inflating: subreddits/bravefrontier.tsv  \n",
            "  inflating: subreddits/britishproblems.tsv  \n",
            "  inflating: subreddits/buildapc.tsv  \n",
            "  inflating: subreddits/canada.tsv   \n",
            "  inflating: subreddits/cars.tsv     \n",
            "  inflating: subreddits/CasualConversation.tsv  \n",
            "  inflating: subreddits/casualiama.tsv  \n",
            "  inflating: subreddits/CasualPokemonTrades.tsv  \n",
            "  inflating: subreddits/CFB.tsv      \n",
            "  inflating: subreddits/changemyview.tsv  \n",
            "  inflating: subreddits/childfree.tsv  \n",
            "  inflating: subreddits/Christianity.tsv  \n",
            "  inflating: subreddits/cigars.tsv   \n",
            "  inflating: subreddits/circlejerk.tsv  \n",
            "  inflating: subreddits/civ.tsv      \n",
            "  inflating: subreddits/Civcraft.tsv  \n",
            "  inflating: subreddits/ClashOfClans.tsv  \n",
            "  inflating: subreddits/ClubTeen.tsv  \n",
            "  inflating: subreddits/CoDCompetitive.tsv  \n",
            "  inflating: subreddits/CollegeBasketball.tsv  \n",
            "  inflating: subreddits/comicbooks.tsv  \n",
            "  inflating: subreddits/conspiracy.tsv  \n",
            "  inflating: subreddits/Cricket.tsv  \n",
            "  inflating: subreddits/cringe.tsv   \n",
            "  inflating: subreddits/cringepics.tsv  \n",
            "  inflating: subreddits/csgobetting.tsv  \n",
            "  inflating: subreddits/DarkNetMarkets.tsv  \n",
            "  inflating: subreddits/darksouls.tsv  \n",
            "  inflating: subreddits/DarkSouls2.tsv  \n",
            "  inflating: subreddits/dataisbeautiful.tsv  \n",
            "  inflating: subreddits/dayz.tsv     \n",
            "  inflating: subreddits/DebateReligion.tsv  \n",
            "  inflating: subreddits/DestinyTheGame.tsv  \n",
            "  inflating: subreddits/Diablo.tsv   \n",
            "  inflating: subreddits/DIY.tsv      \n",
            "  inflating: subreddits/DnD.tsv      \n",
            "  inflating: subreddits/dogecoin.tsv  \n",
            "  inflating: subreddits/dogemarket.tsv  \n",
            "  inflating: subreddits/DotA2.tsv    \n",
            "  inflating: subreddits/dragonage.tsv  \n",
            "  inflating: subreddits/Drugs.tsv    \n",
            "  inflating: subreddits/elderscrollsonline.tsv  \n",
            "  inflating: subreddits/electronic_cigarette.tsv  \n",
            "  inflating: subreddits/europe.tsv   \n",
            "  inflating: subreddits/Eve.tsv      \n",
            "  inflating: subreddits/exmormon.tsv  \n",
            "  inflating: subreddits/explainlikeimfive.tsv  \n",
            "  inflating: subreddits/Fallout.tsv  \n",
            "  inflating: subreddits/fantasyfootball.tsv  \n",
            "  inflating: subreddits/fatlogic.tsv  \n",
            "  inflating: subreddits/fatpeoplehate.tsv  \n",
            "  inflating: subreddits/fatpeoplestories.tsv  \n",
            "  inflating: subreddits/ffxiv.tsv    \n",
            "  inflating: subreddits/FIFA.tsv     \n",
            "  inflating: subreddits/Fitness.tsv  \n",
            "  inflating: subreddits/food.tsv     \n",
            "  inflating: subreddits/formula1.tsv  \n",
            "  inflating: subreddits/friendsafari.tsv  \n",
            "  inflating: subreddits/Frozen.tsv   \n",
            "  inflating: subreddits/Frugal.tsv   \n",
            "  inflating: subreddits/funny.tsv    \n",
            "  inflating: subreddits/Futurology.tsv  \n",
            "  inflating: subreddits/GameDeals.tsv  \n",
            "  inflating: subreddits/gamegrumps.tsv  \n",
            "  inflating: subreddits/gameofthrones.tsv  \n",
            "  inflating: subreddits/Games.tsv    \n",
            "  inflating: subreddits/gaming.tsv   \n",
            "  inflating: subreddits/gaybros.tsv  \n",
            "  inflating: subreddits/gifs.tsv     \n",
            "  inflating: subreddits/GlobalOffensive.tsv  \n",
            "  inflating: subreddits/GlobalOffensiveTrade.tsv  \n",
            "  inflating: subreddits/gonewild.tsv  \n",
            "  inflating: subreddits/GrandTheftAutoV.tsv  \n",
            "  inflating: subreddits/Guildwars2.tsv  \n",
            "  inflating: subreddits/Guitar.tsv   \n",
            "  inflating: subreddits/Gunners.tsv  \n",
            "  inflating: subreddits/guns.tsv     \n",
            "  inflating: subreddits/halo.tsv     \n",
            "  inflating: subreddits/hearthstone.tsv  \n",
            "  inflating: subreddits/hiphopheads.tsv  \n",
            "  inflating: subreddits/hockey.tsv   \n",
            "  inflating: subreddits/Homebrewing.tsv  \n",
            "  inflating: subreddits/IAmA.tsv     \n",
            "  inflating: subreddits/ImGoingToHellForThis.tsv  \n",
            "  inflating: subreddits/india.tsv    \n",
            "  inflating: subreddits/ireland.tsv  \n",
            "  inflating: subreddits/jailbreak.tsv  \n",
            "  inflating: subreddits/Jokes.tsv    \n",
            "  inflating: subreddits/JusticePorn.tsv  \n",
            "  inflating: subreddits/Justrolledintotheshop.tsv  \n",
            "  inflating: subreddits/KerbalSpaceProgram.tsv  \n",
            "  inflating: subreddits/keto.tsv     \n",
            "  inflating: subreddits/KotakuInAction.tsv  \n",
            "  inflating: subreddits/leagueoflegends.tsv  \n",
            "  inflating: subreddits/legaladvice.tsv  \n",
            "  inflating: subreddits/lewronggeneration.tsv  \n",
            "  inflating: subreddits/Libertarian.tsv  \n",
            "  inflating: subreddits/LifeProTips.tsv  \n",
            "  inflating: subreddits/LiverpoolFC.tsv  \n",
            "  inflating: subreddits/longboarding.tsv  \n",
            "  inflating: subreddits/loseit.tsv   \n",
            "  inflating: subreddits/magicTCG.tsv  \n",
            "  inflating: subreddits/MakeupAddiction.tsv  \n",
            "  inflating: subreddits/malefashionadvice.tsv  \n",
            "  inflating: subreddits/MapPorn.tsv  \n",
            "  inflating: subreddits/MechanicalKeyboards.tsv  \n",
            "  inflating: subreddits/MensRights.tsv  \n",
            "  inflating: subreddits/mildlyinteresting.tsv  \n",
            "  inflating: subreddits/mindcrack.tsv  \n",
            "  inflating: subreddits/Minecraft.tsv  \n",
            "  inflating: subreddits/MLPLounge.tsv  \n",
            "  inflating: subreddits/MLS.tsv      \n",
            "  inflating: subreddits/MMA.tsv      \n",
            "  inflating: subreddits/motorcycles.tsv  \n",
            "  inflating: subreddits/movies.tsv   \n",
            "  inflating: subreddits/Music.tsv    \n",
            "  inflating: subreddits/mylittlepony.tsv  \n",
            "  inflating: subreddits/Naruto.tsv   \n",
            "  inflating: subreddits/NASCAR.tsv   \n",
            "  inflating: subreddits/nba.tsv      \n",
            "  inflating: subreddits/news.tsv     \n",
            "  inflating: subreddits/newzealand.tsv  \n",
            "  inflating: subreddits/nfl.tsv      \n",
            "  inflating: subreddits/NoFap.tsv    \n",
            "  inflating: subreddits/nosleep.tsv  \n",
            "  inflating: subreddits/nottheonion.tsv  \n",
            "  inflating: subreddits/oculus.tsv   \n",
            "  inflating: subreddits/offmychest.tsv  \n",
            "  inflating: subreddits/OkCupid.tsv  \n",
            "  inflating: subreddits/opiates.tsv  \n",
            "  inflating: subreddits/Parenting.tsv  \n",
            "  inflating: subreddits/pathofexile.tsv  \n",
            "  inflating: subreddits/pcgaming.tsv  \n",
            "  inflating: subreddits/pcmasterrace.tsv  \n",
            "  inflating: subreddits/PercyJacksonRP.tsv  \n",
            "  inflating: subreddits/personalfinance.tsv  \n",
            "  inflating: subreddits/photography.tsv  \n",
            "  inflating: subreddits/photoshopbattles.tsv  \n",
            "  inflating: subreddits/pics.tsv     \n",
            "  inflating: subreddits/Planetside.tsv  \n",
            "  inflating: subreddits/pokemon.tsv  \n",
            "  inflating: subreddits/Pokemongiveaway.tsv  \n",
            "  inflating: subreddits/PokemonPlaza.tsv  \n",
            "  inflating: subreddits/pokemontrades.tsv  \n",
            "  inflating: subreddits/polandball.tsv  \n",
            "  inflating: subreddits/politics.tsv  \n",
            "  inflating: subreddits/Portland.tsv  \n",
            "  inflating: subreddits/PotterPlayRP.tsv  \n",
            "  inflating: subreddits/programming.tsv  \n",
            "  inflating: subreddits/PS4.tsv      \n",
            "  inflating: subreddits/raisedbynarcissists.tsv  \n",
            "  inflating: subreddits/Random_Acts_Of_Amazon.tsv  \n",
            "  inflating: subreddits/RandomActsOfGaming.tsv  \n",
            "  inflating: subreddits/randomsuperpowers.tsv  \n",
            "  inflating: subreddits/Rateme.tsv   \n",
            "  inflating: subreddits/reactiongifs.tsv  \n",
            "  inflating: subreddits/README.txt   \n",
            "   creating: __MACOSX/subreddits/\n",
            "  inflating: __MACOSX/subreddits/._README.txt  \n",
            "  inflating: subreddits/reddevils.tsv  \n",
            "  inflating: subreddits/relationship_advice.tsv  \n",
            "  inflating: subreddits/relationships.tsv  \n",
            "  inflating: subreddits/roosterteeth.tsv  \n",
            "  inflating: subreddits/runescape.tsv  \n",
            "  inflating: subreddits/rupaulsdragrace.tsv  \n",
            "  inflating: subreddits/science.tsv  \n",
            "  inflating: subreddits/Seattle.tsv  \n",
            "  inflating: subreddits/sex.tsv      \n",
            "  inflating: subreddits/SFGiants.tsv  \n",
            "  inflating: subreddits/ShinyPokemon.tsv  \n",
            "  inflating: subreddits/Showerthoughts.tsv  \n",
            "  inflating: subreddits/SkincareAddiction.tsv  \n",
            "  inflating: subreddits/skyrim.tsv   \n",
            "  inflating: subreddits/smashbros.tsv  \n",
            "  inflating: subreddits/Smite.tsv    \n",
            "  inflating: subreddits/Sneakers.tsv  \n",
            "  inflating: subreddits/soccer.tsv   \n",
            "  inflating: subreddits/sports.tsv   \n",
            "  inflating: subreddits/SquaredCircle.tsv  \n",
            "  inflating: subreddits/starcitizen.tsv  \n",
            "  inflating: subreddits/starcraft.tsv  \n",
            "  inflating: subreddits/StarWars.tsv  \n",
            "  inflating: subreddits/Steam.tsv    \n",
            "  inflating: subreddits/SteamGameSwap.tsv  \n",
            "  inflating: subreddits/SubredditDrama.tsv  \n",
            "  inflating: subreddits/summonerschool.tsv  \n",
            "  inflating: subreddits/SVExchange.tsv  \n",
            "  inflating: subreddits/sysadmin.tsv  \n",
            "  inflating: subreddits/TalesFromRetail.tsv  \n",
            "  inflating: subreddits/talesfromtechsupport.tsv  \n",
            "  inflating: subreddits/technology.tsv  \n",
            "  inflating: subreddits/techsupport.tsv  \n",
            "  inflating: subreddits/teenagers.tsv  \n",
            "  inflating: subreddits/television.tsv  \n",
            "  inflating: subreddits/tf2.tsv      \n",
            "  inflating: subreddits/thatHappened.tsv  \n",
            "  inflating: subreddits/TheLastAirbender.tsv  \n",
            "  inflating: subreddits/TheRedPill.tsv  \n",
            "  inflating: subreddits/thewalkingdead.tsv  \n",
            "  inflating: subreddits/tifu.tsv     \n",
            "  inflating: subreddits/tipofmytongue.tsv  \n",
            "  inflating: subreddits/titanfall.tsv  \n",
            "  inflating: subreddits/todayilearned.tsv  \n",
            "  inflating: subreddits/toronto.tsv  \n",
            "  inflating: subreddits/trees.tsv    \n",
            "  inflating: subreddits/TrollXChromosomes.tsv  \n",
            "  inflating: subreddits/TumblrInAction.tsv  \n",
            "  inflating: subreddits/twitchplayspokemon.tsv  \n",
            "  inflating: subreddits/TwoXChromosomes.tsv  \n",
            "  inflating: subreddits/ultrahardcore.tsv  \n",
            "  inflating: subreddits/unitedkingdom.tsv  \n",
            "  inflating: subreddits/videos.tsv   \n",
            "  inflating: subreddits/Warthunder.tsv  \n",
            "  inflating: subreddits/whowouldwin.tsv  \n",
            "  inflating: subreddits/wiiu.tsv     \n",
            "  inflating: subreddits/WildStar.tsv  \n",
            "  inflating: subreddits/windowsphone.tsv  \n",
            "  inflating: subreddits/woahdude.tsv  \n",
            "  inflating: subreddits/worldnews.tsv  \n",
            "  inflating: subreddits/WorldofTanks.tsv  \n",
            "  inflating: subreddits/wow.tsv      \n",
            "  inflating: subreddits/WritingPrompts.tsv  \n",
            "  inflating: subreddits/WTF.tsv      \n",
            "  inflating: subreddits/xboxone.tsv  \n",
            "  inflating: subreddits/yugioh.tsv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_files = ['3DS.tsv', \n",
        "'4chan.tsv',\n",
        "'2007scape.tsv',\n",
        "'ACTrade.tsv',\n",
        "'amiugly.tsv',\n",
        "'BabyBumps.tsv',\n",
        "'baseball.tsv',\n",
        "'canada.tsv',\n",
        "'CasualConversation.tsv',\n",
        "'DarkNetMarkets.tsv',\n",
        "'darksouls.tsv',\n",
        "'elderscrollsonline.tsv',\n",
        "'Eve.tsv',\n",
        "'Fallout.tsv',\n",
        "'fantasyfootball.tsv',\n",
        "'GameDeals.tsv',\n",
        "'gamegrumps.tsv',\n",
        "'halo.tsv',\n",
        "'Homebrewing.tsv',\n",
        "'IAmA.tsv',\n",
        "'india.tsv',\n",
        "'jailbreak.tsv',\n",
        "'Jokes.tsv',\n",
        "'KerbalSpaceProgram.tsv',\n",
        "'keto.tsv',\n",
        "'leagueoflegends.tsv',\n",
        "'Libertarian.tsv',\n",
        "'magicTCG.tsv',\n",
        "'MakeupAddiction.tsv',\n",
        "'Naruto.tsv',\n",
        "'nba.tsv',\n",
        "'oculus.tsv',\n",
        "'OkCupid.tsv',\n",
        "'Parenting.tsv',\n",
        "'pathofexile.tsv',\n",
        "'raisedbynarcissists.tsv',\n",
        "'Random_Acts_Of_Amazon.tsv',\n",
        "'science.tsv',\n",
        "'Seattle.tsv',\n",
        "'TalesFromRetail.tsv',\n",
        "'talesfromtechsupport.tsv',\n",
        "'ultrahardcore.tsv',\n",
        "'videos.tsv',\n",
        "'Warthunder.tsv',\n",
        "'whowouldwin.tsv',\n",
        "'xboxone.tsv',\n",
        "'yugioh.tsv',\n",
        "]"
      ],
      "metadata": {
        "id": "MlpvD2rmurcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dicts=[]\n",
        "for i in range(0,len(list_files)):\n",
        "    dfname='df_'+str(list_files[i])\n",
        "    dfname=dfname.replace('.tsv','')\n",
        "    path=\"/content/subreddits/\" + list_files[i]\n",
        "    dataframe = pd.read_csv(path, sep=\"\\t\", header=None)\n",
        "    dataframe.columns = ['Word', 'Sentiment', 'Std']\n",
        "    dataframe=dataframe.drop(columns=['Std'])\n",
        "    list_dicts.append(dict(dataframe.values))"
      ],
      "metadata": {
        "id": "h9Txu7LuMK_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine dictionaries\n",
        "def dict_merger(dict1, dict2):\n",
        "    new_dict = {**dict1, **dict2}\n",
        "    return new_dict"
      ],
      "metadata": {
        "id": "PfBXyR8eHAjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2000adj=df_2000adj.drop(columns='Std')\n",
        "feature1=dict(df_2000adj.values)\n",
        "df_2000freq=df_2000freq.drop(columns='Std')\n",
        "feature2=dict(df_2000freq.values)"
      ],
      "metadata": {
        "id": "VDw8BKZox-gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature3 = {}\n",
        "for i in range(0, 8):\n",
        "  feature3=dict_merger(feature3,list_dicts[i])\n",
        "\n",
        "feature4 = {}\n",
        "for i in range(8, 16):\n",
        "  feature4=dict_merger(feature4,list_dicts[i])\n",
        "\n",
        "feature5 = {}\n",
        "for i in range(16, 23):\n",
        "  feature5=dict_merger(feature5,list_dicts[i])\n",
        "\n",
        "feature6 = {}\n",
        "for i in range(23, 29):\n",
        "  feature6=dict_merger(feature6,list_dicts[i])\n",
        "\n",
        "feature7 = {}\n",
        "for i in range(29, 34):\n",
        "  feature7=dict_merger(feature7,list_dicts[i])\n",
        "\n",
        "feature8 = {}\n",
        "for i in range(34, 41):\n",
        "  feature8=dict_merger(feature8,list_dicts[i])\n",
        "\n",
        "feature9 = {}\n",
        "for i in range(41, 47):\n",
        "  feature9=dict_merger(feature9,list_dicts[i])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cb9HByXsIn9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting features"
      ],
      "metadata": {
        "id": "qh_n5XtflKiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#one thing that boosted my scores was instead of taking one word per feature, I summed 9 words per feature\n",
        "#I took words at random and oversampled shorter tweets. boosted the F1 score by letting randomization try to hit a good token\n",
        "def lookups(row):\n",
        "  lookup_index=row.name\n",
        "  #print(\"This is the lookup_index: \" + str(lookup_index))\n",
        "  range_len=(df['Token_len'][lookup_index])\n",
        "  #print(\"This is the range_len: \" + str(range_len))\n",
        "  score=[]\n",
        "  for i in range(0, 9):\n",
        "    #print(\"Starting the for loop at: \" + str(i))\n",
        "    token=random.randint(0, range_len) \n",
        "    token -= 1\n",
        "    #print(\"The token is: \" + str(token))\n",
        "    word_tok=df.iloc[lookup_index, 2][token]\n",
        "    #print(\"The word_tok is: \" + str(word_tok))\n",
        "    try:\n",
        "      score.append(current_dict[word_tok])\n",
        "    except:\n",
        "      pass\n",
        "  try:\n",
        "      sum_score=sum(score)\n",
        "  except:\n",
        "      sum_score=0\n",
        "  return sum_score\n",
        "\n",
        "def lookupst(row):\n",
        "  lookup_index=row.name\n",
        "  #print(\"This is the lookup_index: \" + str(lookup_index))\n",
        "  range_len=(dft['Token_len'][lookup_index])\n",
        "  #print(\"This is the range_len: \" + str(range_len))\n",
        "  score=[]\n",
        "  for i in range(0, 9):\n",
        "    #print(\"Starting the for loop at: \" + str(i))\n",
        "    token=random.randint(0, range_len) \n",
        "    token -= 1\n",
        "    #print(\"The token is: \" + str(token))\n",
        "    word_tok=dft.iloc[lookup_index, 2][token]\n",
        "    #print(\"The word_tok is: \" + str(word_tok))\n",
        "    try:\n",
        "      score.append(current_dict[word_tok])\n",
        "    except:\n",
        "      pass\n",
        "  try:\n",
        "      sum_score=sum(score)\n",
        "  except:\n",
        "      sum_score=0\n",
        "  return sum_score\n",
        "\n",
        "def wordlengther(row):\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    longest_word=1\n",
        "    for word in token_list:\n",
        "        if longest_word<len(word):\n",
        "          longest_word=len(word)\n",
        "    log_long=np.log10(longest_word)\n",
        "    return log_long\n",
        "\n",
        "def wordfiver(row):\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    five_counts=1\n",
        "    for word in token_list:\n",
        "        if len(word)>=5:\n",
        "          five_counts+=1\n",
        "    log_five=np.log10(five_counts)\n",
        "    return log_five\n",
        "\n",
        "def wordlengthert(row):\n",
        "    index=row.name\n",
        "    token_list=dft['Twitter_tokens'][index]\n",
        "    longest_word=1\n",
        "    for word in token_list:\n",
        "        if longest_word<len(word):\n",
        "          longest_word=len(word)\n",
        "    log_long=np.log10(longest_word)\n",
        "    return log_long\n",
        "\n",
        "def wordfivert(row):\n",
        "    index=row.name\n",
        "    token_list=dft['Twitter_tokens'][index]\n",
        "    five_counts=1\n",
        "    for word in token_list:\n",
        "        if len(word)>=5:\n",
        "          five_counts+=1\n",
        "    log_five=np.log10(five_counts)\n",
        "    return log_five\n",
        "\n",
        "def mostpos(row):  #need the negative version too, mostneg\n",
        "    index=row.name\n",
        "    token_list=df['Twitter_tokens'][index]\n",
        "    max_value=0\n",
        "    for word in token_list:\n",
        "      try: pos_value=feature3[word]   #replace with super dictionary\n",
        "      except: pos_value=0\n",
        "      if max_value<pos_value:\n",
        "        max_value=pos_value\n",
        "    return max_value"
      ],
      "metadata": {
        "id": "4qSZDlp0N_9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection(lst1, lst2):\n",
        "    return list(set(lst1) & set(lst2))"
      ],
      "metadata": {
        "id": "BXNxohZHMo-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature24']=0\n",
        "df['feature24']=df.apply(mostpos,axis=1)"
      ],
      "metadata": {
        "id": "Rk7jxparlsMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature1']=0\n",
        "df['feature2']=0\n",
        "df['feature3']=0\n",
        "df['feature4']=0\n",
        "df['feature5']=0\n",
        "df['feature6']=0\n",
        "df['feature7']=0\n",
        "df['feature8']=0\n",
        "df['feature9']=0\n",
        "df['feature10']=0\n",
        "df['feature11']=0\n",
        "df['feature12']=0\n"
      ],
      "metadata": {
        "id": "1ZGXMsI8Iu_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list=['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9']\n",
        "for i in range(0, len(features_list)):\n",
        "  current_dict=list_dicts[i]\n",
        "  df[features_list[i]]=df.apply(lookups, axis=1)\n",
        "  dft[features_list[i]]=dft.apply(lookupst, axis=1)"
      ],
      "metadata": {
        "id": "-zF7OHmETgXd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "61155dc2-ac30-407d-9a43-953f7d176c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f837d10a6dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcurrent_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mdft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookupst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-ca9ff02f68cc>\u001b[0m in \u001b[0;36mlookups\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(\"The token is: \" + str(token))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mword_tok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(\"The word_tok is: \" + str(word_tok))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \"\"\"\n\u001b[1;32m   3564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3565\u001b[0;31m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3566\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3399\u001b[0m             \u001b[0;31m# this is a cached value, mark it so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3400\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3401\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_set_as_cached\u001b[0;34m(self, item, cacher)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcacher\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \"\"\"\n\u001b[1;32m   1196\u001b[0m         \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0m_cacher\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweakref\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature10']=df['Token_len'].apply(np.log10)\n",
        "dft['feature10']=dft['Token_len'].apply(np.log10)\n",
        "df['feature11']=df.apply(wordlengther, axis=1)\n",
        "df['feature12']=df.apply(wordfiver, axis=1)\n",
        "dft['feature11']=dft.apply(wordlengthert, axis=1)\n",
        "dft['feature12']=dft.apply(wordfivert, axis=1)"
      ],
      "metadata": {
        "id": "j0nu5rs9y5gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature11']=df.apply(wordlengther, axis=1)\n",
        "df['feature12']=df.apply(wordfiver, axis=1)\n",
        "dft['feature11']=dft.apply(wordlengthert, axis=1)\n",
        "dft['feature12']=dft.apply(wordfivert, axis=1)"
      ],
      "metadata": {
        "id": "foYumH0w0CZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "HzK3S5OACivL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft"
      ],
      "metadata": {
        "id": "Izz5rSqECkbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_original_Tweets.columns = ['Original Tweet']\n",
        "df['Original Tweet'] = df_original_Tweets['Original Tweet']\n",
        "\n",
        "first_column = df.pop('Original Tweet')\n",
        "# insert column using insert(position,column_name,first_column) function\n",
        "df.insert(0, 'Original Tweet', first_column)"
      ],
      "metadata": {
        "id": "6Eure_atCoVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_original_Tweets.columns = ['Original Tweet']\n",
        "dft['Original Tweet'] = dft_original_Tweets['Original Tweet']\n",
        "\n",
        "first_column = dft.pop('Original Tweet')\n",
        "# insert column using insert(position,column_name,first_column) function\n",
        "dft.insert(0, 'Original Tweet', first_column)"
      ],
      "metadata": {
        "id": "nMS3zf_RDNbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "GsEodv-cFUiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft"
      ],
      "metadata": {
        "id": "sT1Pcj0dFZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction13_23(dataframe):  #pass in df or dft \n",
        "\n",
        "  dataframe[\"Feature 13\"] = np.nan # Count: Words in + Lexicon\n",
        "  dataframe[\"Feature 14\"] = np.nan # Count: Words in - Lexicon\n",
        "  dataframe[\"Feature 15\"] = np.nan # Count: Nouns in Tweet\n",
        "  dataframe[\"Feature 16\"] = np.nan # Count: Adjectives\n",
        "  dataframe[\"Feature 17\"] = np.nan # Ratio: Unique words - total words\n",
        "  dataframe[\"Feature 18\"] = np.nan # Ratio: Stop Words - Total Words\n",
        "  dataframe[\"Feature 19\"] = np.nan # Ratio Nouns to total words\n",
        "  dataframe[\"Feature 20\"] = np.nan # Ratio of proper nouns to total words\n",
        "  dataframe[\"Feature 21\"] = np.nan # Ratio Capital letters to lowercase letters\n",
        "  dataframe[\"Feature 22\"] = np.nan # Ratio of punctuation characters to Total Characters\n",
        "  dataframe[\"Feature 23\"] = np.nan # Does Tweet conatin the word 'No'\n",
        "  dataframe[\"Feature 24\"] = np.nan # Mean Length of all words in tweet \n",
        "  dataframe[\"Feature 25\"] = np.nan # Log of Mean Length of all words in tweet \n",
        "  dataframe[\"Feature 26\"] = np.nan # Highest word score of all words in tweet \n",
        "  dataframe[\"Feature 27\"] = np.nan # Lowest word score of all words in tweet\n",
        "  dataframe[\"Feature 28\"] = np.nan # Emoji count  \n",
        "\n",
        "\n",
        "\n",
        "  #CREATE POSITIVE AND NEGATIVE LEXICONS\n",
        "  pos_lexicon = []\n",
        "  neg_lexicon = []\n",
        "\n",
        "  for i in range(0, len(list_dicts)):               \n",
        "    for j in range(0, len(list_dicts[i])):    \n",
        "\n",
        "      if list(list_dicts[i].values())[j] >= 0:         \n",
        "        pos_lexicon.append(list(list_dicts[i].keys())[j])        \n",
        "          \n",
        "      if list(list_dicts[i].values())[j] < 0:         \n",
        "        neg_lexicon.append(list(list_dicts[i].keys())[j]) \n",
        "\n",
        "  pos_lexicon = [*set(pos_lexicon)]   # Remove duplicate values from + lexicon\n",
        "  neg_lexicon = [*set(neg_lexicon)]   # Remove duplicate values from - lexicon\n",
        "\n",
        "  wrds_in_PosNeg = intersection(pos_lexicon, neg_lexicon)\n",
        "  wrds_in_PosNeg.pop(0)\n",
        "\n",
        "\n",
        "  #Look for duplicates across dictionaries \n",
        "  duplicate_dict = {}\n",
        "\n",
        "  for i in range(0, len(wrds_in_PosNeg)):\n",
        "    sent_scores_2sum = []\n",
        "\n",
        "    for j in range(0, len(list_dicts)):\n",
        "      subreddit_wrd_list = list(list_dicts[j].keys())\n",
        "\n",
        "      if wrds_in_PosNeg[i] in subreddit_wrd_list:\n",
        "        sent_scores_2sum.append(list_dicts[j].get(wrds_in_PosNeg[i]))\n",
        "        num_avg = mean(sent_scores_2sum)\n",
        "    \n",
        "    duplicate_dict[wrds_in_PosNeg[i]] =  num_avg\n",
        "\n",
        "  # Remove words that now have a clear positive or negative classification\n",
        "  for w in duplicate_dict.items():        # .items() returns a tuple of (word, score). See Cell above for all words: scores in dict\n",
        "    if w[1] >= 0:                         # if w[1] (the score) is greater than 0...\n",
        "      neg_lexicon.remove(w[0])            # remove it from the negative lexicon\n",
        "    if w[1] < 0:                          # If w[1] (the score) is less than 0...\n",
        "      pos_lexicon.remove(w[0])            # remove the word from the positive lexicon\n",
        "\n",
        "\n",
        "  # COUNT POSITIVE AND NEGATIVE WORDS (13 & 14)\n",
        "  neg_lex_set = set(neg_lexicon)\n",
        "  pos_lex_set = set(pos_lexicon)\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    x = set(dataframe['Twitter_tokens'][i])\n",
        "    dataframe['Feature 13'].values[i] = len(x.intersection(pos_lex_set))\n",
        "    dataframe['Feature 14'].values[i] = len(x.intersection(neg_lex_set))\n",
        "\n",
        "\n",
        "  # COUNT NOUNS IN TWEET (15)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    tokens = dataframe['Twitter_tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    noun_definitions = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in noun_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    dataframe['Feature 15'].values[i] = count  \n",
        "\n",
        "\n",
        "  #COUNT ADJECTIVES IN TWEET (16)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    tokens = dataframe['Twitter_tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    adj_definitions = ['JJ', 'JJR', 'JJS ']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in adj_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    dataframe['Feature 16'].values[i] = count\n",
        "\n",
        "  # RATIO: UNIQUE TO TOTAL WORDS (17)\n",
        "  for i in range(0, len(dataframe.index)):                       \n",
        "    tokens = dataframe['Twitter_tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    ratio = len(np.unique(x)) / len(tokens)\n",
        "    dataframe['Feature 17'].values[i] = ratio\n",
        "\n",
        "\n",
        "  # STOP WORDS TO TOTAL WORDS (18)\n",
        "  for i in range(0, len(dataframe.index)):                       \n",
        "    tokens = dataframe['Twitter_tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    stop_wrds_count = [w for w in tokens if w in stop_words]\n",
        "    ratio = len(stop_wrds_count) / len(tokens)\n",
        "    dataframe['Feature 18'].values[i] = ratio\n",
        "\n",
        "\n",
        "  # RATIO OF NOUNS TO TOTAL WORDS (19)\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "      tokens = dataframe['Twitter_tokens'][i]\n",
        "      tokens = [w for w in tokens if not w in stop_words]\n",
        "      tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "      noun_definitions = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "      count = 0\n",
        "\n",
        "      for j in range(0, len(tagged)):\n",
        "        if tagged[j][1] in noun_definitions:\n",
        "          count += 1\n",
        "\n",
        "      ratio = count / len(dataframe['Twitter_tokens'][i])\n",
        "      dataframe['Feature 19'].values[i] = ratio\n",
        "\n",
        "     \n",
        "  # RATIO OF PROPER NOUNS TO TOTAL WORDS (20)\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "      tokens = dataframe['Twitter_tokens'][i]\n",
        "      tokens = [w for w in tokens if not w in stop_words]\n",
        "      tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "      noun_definitions = ['NNP', 'NNPS']\n",
        "      count = 0\n",
        "\n",
        "      for j in range(0, len(tagged)):\n",
        "        if tagged[j][1] in noun_definitions:\n",
        "          count += 1\n",
        "\n",
        "      ratio = count / len(dataframe['Twitter_tokens'][i])\n",
        "      dataframe['Feature 20'].values[i] = ratio\n",
        "\n",
        "  # RATIO OF CAPITAL LETTERS TO LOWERCASE LETERS(21)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    upper_count = len(re.findall(r'[A-Z]', dataframe['Original Tweet'].values[i]))\n",
        "    lower_count = len(re.findall(r'[a-z]', dataframe['Original Tweet'].values[i]))\n",
        "\n",
        "    if lower_count == 0:\n",
        "      dataframe['Feature 21'].values[i] = 0 \n",
        "    if lower_count!= 0: \n",
        "      ratio = upper_count / lower_count\n",
        "      dataframe['Feature 21'].values[i] = ratio\n",
        "\n",
        "\n",
        "  # RATIO PUNCTUATION CHARACTERS TO TOTAL CHARACTERS (22)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    count = 0\n",
        "\n",
        "    for j in dataframe['Original Tweet'][i]:\n",
        "      if j in string.punctuation:\n",
        "        count += 1\n",
        "\n",
        "    ratio = count / len(dataframe['Original Tweet'][i])\n",
        "    dataframe['Feature 22'].values[i] = ratio\n",
        "\n",
        "\n",
        "  # DOES TWEET CONTAIN NO (23)\n",
        "  for i in range(0, len(dataframe.index)):                       # In the range 0 to length of the tweets dataframe         # Tokenize and lowercase tweets \n",
        "    if 'no' in dataframe['Twitter_tokens'][i]:                                    # If no is in tweet dataframe value is 1 if not value is zero\n",
        "      dataframe['Feature 23'].values[i] = 1\n",
        "    else: \n",
        "      dataframe['Feature 23'].values[i] = 0\n",
        "\n",
        "  # MEAN LENGTH OF WORDS IN TWEET (24)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    average = sum(len(token) for token in dataframe['Twitter_tokens'][i]) / len(dataframe['Twitter_tokens'][i])\n",
        "\n",
        "    dataframe['Feature 24'].values[i] = average\n",
        "\n",
        "\n",
        "\n",
        "  # LOG MEAN LENGTH OF WORDS IN TWEET (25)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    average = sum(len(token) for token in dataframe['Twitter_tokens'][i]) / len(dataframe['Twitter_tokens'][i])\n",
        "\n",
        "    dataframe['Feature 25'].values[i] = math.log(average)\n",
        "\n",
        "\n",
        "  # HIGHEST SCORE VALUE OF TOKENS (26)\n",
        "  dataframe['Feature 26'] = dataframe['Feature 26'].astype('object')\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    found_values = []\n",
        "\n",
        "    for j in range(0 , len(dataframe['Twitter_tokens'][i])):\n",
        "      if dataframe['Twitter_tokens'][i][j] in super_dict:\n",
        "        found_values.append(super_dict.get(dataframe['Twitter_tokens'][i][j])) \n",
        "\n",
        "      if not found_values:\n",
        "        found_values.append(0) \n",
        "\n",
        "    dataframe['Feature 26'].values[i] = max(found_values)\n",
        "\n",
        "\n",
        "  # LOWEST SCORE VALUE OF TOKENS (27)\n",
        "  dataframe['Feature 27'] = dataframe['Feature 27'].astype('object')\n",
        "\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    found_values = []\n",
        "\n",
        "    for j in range(0 , len(dataframe['Twitter_tokens'][i])):\n",
        "      if dataframe['Twitter_tokens'][i][j] in super_dict:\n",
        "        found_values.append(super_dict.get(dataframe['Twitter_tokens'][i][j])) \n",
        "\n",
        "      if not found_values:\n",
        "        found_values.append(0) \n",
        "\n",
        "    dataframe['Feature 27'].values[i] = min(found_values)\n",
        "\n",
        "\n",
        "  # COUNT EMOJIS (28)\n",
        "  for i in range(0, len(dataframe.index)):\n",
        "    count = len(re.findall(r'[\\U0001f600-\\U0001f650]', dataframe['Original Tweet'][i]))\n",
        "\n",
        "    dataframe['Feature 28'].values[i] = count\n",
        "\n",
        "  return(dataframe)"
      ],
      "metadata": {
        "id": "t3AWr_KqH2D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combination of all subreddit dict values into one dict \n",
        "super_dict = {}\n",
        "for i in range(0, len(list_dicts)):\n",
        "  super_dict=dict_merger(super_dict,list_dicts[i])"
      ],
      "metadata": {
        "id": "TN1eTNYiNvt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated = feature_extraction13_23(df)\n",
        "dft_updated = feature_extraction13_23(dft)"
      ],
      "metadata": {
        "id": "kjVlqmfwMEVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_updated\n",
        "dft = dft_updated"
      ],
      "metadata": {
        "id": "L_dYyihBReQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#dfc=pd.concat([df, dft])\n",
        "dfc.to_csv('tweets_extracted.csv')"
      ],
      "metadata": {
        "id": "vqxrhdNsJRef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward Selection of Features"
      ],
      "metadata": {
        "id": "IvcZXeOtTU6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown 1ubIaCqJnOzG-m_ns7VmdV87Ecs349BbG\n",
        "#dfc=pd.read_csv('tweets_extracted.csv')\n",
        "#Xc=dfc.drop(columns=['Unnamed: 0', 'Twitter','Label','Twitter_tokens','Token_len','Original Tweet','feature24']) #whats wrong with feature24?\n",
        "#yc=dfc['Label']"
      ],
      "metadata": {
        "id": "KAeXsYHcmc7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306f23d5-e9e5-4308-9a3c-32f2846f4ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ubIaCqJnOzG-m_ns7VmdV87Ecs349BbG\n",
            "To: /content/tweets_extracted.csv\n",
            "100% 18.3M/18.3M [00:00<00:00, 132MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfc=pd.concat([df, dft])\n",
        "Xc=dfc.drop(columns=['Twitter','Label','Twitter_tokens','Token_len','Original Tweet','feature24']) #whats wrong with feature24?\n",
        "yc=dfc['Label']"
      ],
      "metadata": {
        "id": "3QS-ndW6mk2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_feature_maker(x,y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, shuffle=True, random_state=42)\n",
        "  sel = SelectFromModel(RandomForestClassifier(n_estimators = 50))\n",
        "  sel.fit(X_train, y_train)\n",
        "  print(\"The best features to use are: \")\n",
        "  feature_index = sel.get_support(indices=True)\n",
        "  x_new=x.iloc[:,feature_index]\n",
        "  print(x_new.head())\n",
        "  weights=sel.estimator_.feature_importances_\n",
        "  weights_percent = 100 * (weights/max(weights))\n",
        "  for i in range(0,len(weights)):\n",
        "    print(\"The feature \" + str(X_train.columns[i]) + \" has a relative importance percentage \" + str(weights_percent[i]))\n",
        "  return x_new\n",
        "\n",
        "  #https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
        "  #call coefficients for a third ranking"
      ],
      "metadata": {
        "id": "_tNVVetTkQtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xc_selected=best_feature_maker(Xc,yc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hsYY-W1mGnP",
        "outputId": "18ea83d7-2312-4bb0-ad55-ca6b2d2200a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best features to use are: \n",
            "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
            "0      1.42     -0.23     -0.43     -0.52      0.56     -0.31      2.26   \n",
            "1      5.64      2.17     -0.54      0.54      0.51      1.24      0.57   \n",
            "2      1.82     -2.73     -1.70     -0.09     -0.71      3.65      2.08   \n",
            "3      0.25      0.14      3.65      1.32     -2.67     -5.03      4.65   \n",
            "4      3.48      0.32     -3.09     -1.57     -1.32      2.60      0.46   \n",
            "\n",
            "   feature8  feature9  Feature 13  Feature 14  Feature 21  Feature 22  \\\n",
            "0      0.81      0.83         7.0         1.0    0.130952    0.033898   \n",
            "1      5.02      1.29         8.0         3.0    0.066667    0.034783   \n",
            "2     -0.08      0.11         5.0         4.0    0.238095    0.068627   \n",
            "3      1.78      1.38        14.0         5.0    1.611111    0.121429   \n",
            "4      0.74      4.52         3.0         5.0    0.033898    0.012658   \n",
            "\n",
            "   Feature 26  Feature 27  \n",
            "0        1.57       -0.44  \n",
            "1        1.52       -0.83  \n",
            "2        3.36       -3.12  \n",
            "3        2.65       -0.44  \n",
            "4        1.55       -1.65  \n",
            "The feature feature1 has a relative importance percentage 86.40163468408473\n",
            "The feature feature2 has a relative importance percentage 58.47034172861291\n",
            "The feature feature3 has a relative importance percentage 52.35136295591531\n",
            "The feature feature4 has a relative importance percentage 54.667298886312345\n",
            "The feature feature5 has a relative importance percentage 43.16589301930024\n",
            "The feature feature6 has a relative importance percentage 51.793820864920214\n",
            "The feature feature7 has a relative importance percentage 45.87124158175938\n",
            "The feature feature8 has a relative importance percentage 69.95017570784626\n",
            "The feature feature9 has a relative importance percentage 66.18688252818464\n",
            "The feature feature10 has a relative importance percentage 27.100568860890473\n",
            "The feature feature11 has a relative importance percentage 23.76248645309518\n",
            "The feature feature12 has a relative importance percentage 26.34323571407327\n",
            "The feature Feature 13 has a relative importance percentage 63.77158217368765\n",
            "The feature Feature 14 has a relative importance percentage 100.0\n",
            "The feature Feature 15 has a relative importance percentage 19.93415218412927\n",
            "The feature Feature 16 has a relative importance percentage 18.48951650067179\n",
            "The feature Feature 17 has a relative importance percentage 12.124680833676008\n",
            "The feature Feature 18 has a relative importance percentage 0.29558592654752436\n",
            "The feature Feature 19 has a relative importance percentage 33.31950900754798\n",
            "The feature Feature 20 has a relative importance percentage 1.7483491926022832\n",
            "The feature Feature 21 has a relative importance percentage 60.640364548123436\n",
            "The feature Feature 22 has a relative importance percentage 43.51677324033304\n",
            "The feature Feature 23 has a relative importance percentage 0.0\n",
            "The feature Feature 24 has a relative importance percentage 37.105133477101845\n",
            "The feature Feature 25 has a relative importance percentage 38.83102787782608\n",
            "The feature Feature 26 has a relative importance percentage 56.08875958164439\n",
            "The feature Feature 27 has a relative importance percentage 55.08022606346591\n",
            "The feature Feature 28 has a relative importance percentage 1.0450935757526747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LogReg"
      ],
      "metadata": {
        "id": "JMgubEwbkzGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogRegression:\n",
        "    def __init__(self, feature_number, lr, epochs):      \n",
        "        self.intercept = 0\n",
        "        self.weight = np.zeros(feature_number)\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "        z = np.dot(X, self.weight) + self.intercept\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def loss(self, s, y):\n",
        "        return (-y * np.log(s) - (1 - y) * np.log(1 - s)).mean()\n",
        "    \n",
        "    def gradient_descent(self, X, s, y):\n",
        "        return np.dot(X.T, (s - y)) / y.shape[0]\n",
        "    \n",
        "    def gradient_descent_intercept(self, s, y):\n",
        "        return np.mean(s - y)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        losses = []\n",
        "        for i in range(self.epochs):\n",
        "            sigma = self.sigmoid(X)\n",
        "\n",
        "            dW = self.gradient_descent(X , sigma, y)\n",
        "            dintercept = self.gradient_descent_intercept(sigma, y)\n",
        "\n",
        "            self.weight -= self.lr * dW\n",
        "            self.intercept -= self.lr * dintercept\n",
        "\n",
        "            loss = self.loss(sigma, y)\n",
        "            if len(losses) % 1000 == 0:\n",
        "                print(\"The iteration is \" + str(i) + \" and the loss is \" +  str(loss))\n",
        "            losses.append(loss)\n",
        "            if i > 1000:\n",
        "              if losses[-1] > losses[-100] - .0001:     #the difference should be an argument\n",
        "                print(\"The weight is \")\n",
        "                print(self.weight)\n",
        "                print(\"The intercept is \")\n",
        "                print(self.intercept)\n",
        "                break\n",
        "        return losses\n",
        "    \n",
        "    def predict(self, train):\n",
        "        x_new = train\n",
        "        result = self.sigmoid(x_new)\n",
        "        y_pred = np.zeros(result.shape[0])\n",
        "        for i in range(len(y_pred)):\n",
        "            if result[i] >= 0.5: \n",
        "                y_pred[i] = 1\n",
        "            else:\n",
        "                y_pred[i] = 0\n",
        "                continue\n",
        "                \n",
        "        return y_pred\n",
        "      \n",
        "    def metrics(self, pred, test):\n",
        "        y_pred=pred\n",
        "        y_test=test\n",
        "        tp=(sum((y_pred == 1) & (y_test==1)))\n",
        "        fp=(sum((y_pred == 1) & (y_test==0)))\n",
        "        fn=(sum((y_pred == 0) & (y_test==1)))\n",
        "        tn=(sum((y_pred == 0) & (y_test==0)))\n",
        "        confusion_matrix=[[tn, fp], [fn, tp]]\n",
        "        print(\"The confusion matrix is: \")\n",
        "        print(confusion_matrix[0])\n",
        "        print(confusion_matrix[1])\n",
        "        print('The accuracy for the Twitter sentiment is {}'.format(sum(y_pred == y_test) / y_test.shape[0]))\n",
        "        print('The precision for the Twitter sentiment is {}'.format((tp/(tp+fp))))\n",
        "        print('The recall for the Twitter sentiment is {}'.format((tp/(tp+fn))))\n",
        "        print('The F1 score for the Twitter sentiment is {}'.format((2*((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fn))+(tp/(tp+fp))))))\n",
        "        return confusion_matrix"
      ],
      "metadata": {
        "id": "XSwfy98wRmUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "w_Coim96PYuk",
        "outputId": "7025078d-7863-4f92-c126-0c09f1eb991c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label  \\\n",
              "0  qt original draft 7th book remus lupin survive...      1   \n",
              "1  alciato bee invest 150 million january another...      1   \n",
              "2  lit mum kerry louboutins wonder many willam ow...      1   \n",
              "3  soul train oct 27 halloween special ft dot fin...      1   \n",
              "4  disappointed wwe summerslam want see john cena...      0   \n",
              "\n",
              "                                      Twitter_tokens  Token_len  feature24  \\\n",
              "0  [qt, original, draft, 7th, book, remus, lupin,...         11       1.39   \n",
              "1  [alciato, bee, invest, 150, million, january, ...         13       3.63   \n",
              "2  [lit, mum, kerry, louboutins, wonder, many, wi...         12       0.73   \n",
              "3  [soul, train, oct, 27, halloween, special, ft,...         21       2.50   \n",
              "4  [disappointed, wwe, summerslam, want, see, joh...         10       1.75   \n",
              "\n",
              "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
              "0      3.28      4.10     -0.72      0.44         0         0         0   \n",
              "1      1.33     -0.26      0.68      0.17         0         0         0   \n",
              "2      0.73     -0.68     -1.67      0.27         0         0         0   \n",
              "3     -1.38      0.10      2.67      2.80         0         0         0   \n",
              "4      0.02      5.23     -5.12     -2.49         0         0         0   \n",
              "\n",
              "   feature8  feature9  feature10  feature11  feature12  \n",
              "0         0         0          0          0          0  \n",
              "1         0         0          0          0          0  \n",
              "2         0         0          0          0          0  \n",
              "3         0         0          0          0          0  \n",
              "4         0         0          0          0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bb3f0a3-2bf4-494b-9105-3997e41b1730\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "      <th>Twitter_tokens</th>\n",
              "      <th>Token_len</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qt original draft 7th book remus lupin survive...</td>\n",
              "      <td>1</td>\n",
              "      <td>[qt, original, draft, 7th, book, remus, lupin,...</td>\n",
              "      <td>11</td>\n",
              "      <td>1.39</td>\n",
              "      <td>3.28</td>\n",
              "      <td>4.10</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alciato bee invest 150 million january another...</td>\n",
              "      <td>1</td>\n",
              "      <td>[alciato, bee, invest, 150, million, january, ...</td>\n",
              "      <td>13</td>\n",
              "      <td>3.63</td>\n",
              "      <td>1.33</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lit mum kerry louboutins wonder many willam ow...</td>\n",
              "      <td>1</td>\n",
              "      <td>[lit, mum, kerry, louboutins, wonder, many, wi...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.73</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-1.67</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>soul train oct 27 halloween special ft dot fin...</td>\n",
              "      <td>1</td>\n",
              "      <td>[soul, train, oct, 27, halloween, special, ft,...</td>\n",
              "      <td>21</td>\n",
              "      <td>2.50</td>\n",
              "      <td>-1.38</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.67</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disappointed wwe summerslam want see john cena...</td>\n",
              "      <td>0</td>\n",
              "      <td>[disappointed, wwe, summerslam, want, see, joh...</td>\n",
              "      <td>10</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.23</td>\n",
              "      <td>-5.12</td>\n",
              "      <td>-2.49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb3f0a3-2bf4-494b-9105-3997e41b1730')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bb3f0a3-2bf4-494b-9105-3997e41b1730 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bb3f0a3-2bf4-494b-9105-3997e41b1730');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dft.head()"
      ],
      "metadata": {
        "id": "hmf3dyfPIbSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "cd552cc2-33f0-4de2-85ff-51bfe7d4f4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Twitter  Label  \\\n",
              "0  think may finally crowd mannequinchallenge gra...      1   \n",
              "1  wow first hugo chavez fidel castro danny glove...      0   \n",
              "2  twitter thankyouobama shows heartfelt gratitud...      1   \n",
              "3  take away illegals dead people trump wins popu...      0   \n",
              "4         onedirection harrystyles cute little dance      1   \n",
              "\n",
              "                                      Twitter_tokens  Token_len  feature1  \\\n",
              "0  [think, may, finally, crowd, mannequinchalleng...          6      2.17   \n",
              "1  [wow, first, hugo, chavez, fidel, castro, dann...         16      0.22   \n",
              "2  [twitter, thankyouobama, shows, heartfelt, gra...          6      0.24   \n",
              "3  [take, away, illegals, dead, people, trump, wi...          9     -0.39   \n",
              "4   [onedirection, harrystyles, cute, little, dance]          5      0.18   \n",
              "\n",
              "   feature2  feature3  feature4  \n",
              "0      6.82      3.96      4.46  \n",
              "1     -0.48      0.94      1.78  \n",
              "2      2.78     -0.68     -0.87  \n",
              "3     -3.03     -3.25      1.40  \n",
              "4      1.03      6.25      1.20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9ac298c-bb63-440a-ad07-c12959a38d50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter</th>\n",
              "      <th>Label</th>\n",
              "      <th>Twitter_tokens</th>\n",
              "      <th>Token_len</th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>think may finally crowd mannequinchallenge gra...</td>\n",
              "      <td>1</td>\n",
              "      <td>[think, may, finally, crowd, mannequinchalleng...</td>\n",
              "      <td>6</td>\n",
              "      <td>2.17</td>\n",
              "      <td>6.82</td>\n",
              "      <td>3.96</td>\n",
              "      <td>4.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wow first hugo chavez fidel castro danny glove...</td>\n",
              "      <td>0</td>\n",
              "      <td>[wow, first, hugo, chavez, fidel, castro, dann...</td>\n",
              "      <td>16</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter thankyouobama shows heartfelt gratitud...</td>\n",
              "      <td>1</td>\n",
              "      <td>[twitter, thankyouobama, shows, heartfelt, gra...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.78</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>take away illegals dead people trump wins popu...</td>\n",
              "      <td>0</td>\n",
              "      <td>[take, away, illegals, dead, people, trump, wi...</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-3.03</td>\n",
              "      <td>-3.25</td>\n",
              "      <td>1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>onedirection harrystyles cute little dance</td>\n",
              "      <td>1</td>\n",
              "      <td>[onedirection, harrystyles, cute, little, dance]</td>\n",
              "      <td>5</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1.03</td>\n",
              "      <td>6.25</td>\n",
              "      <td>1.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9ac298c-bb63-440a-ad07-c12959a38d50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9ac298c-bb63-440a-ad07-c12959a38d50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9ac298c-bb63-440a-ad07-c12959a38d50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#experimented with different splits, best performance was to concatenate the train and test sets\n",
        "#and then randomly resample them to create new train and test sets\n",
        "#this gave better variance and improved the score\n",
        "\"\"\"\n",
        "X_train=df.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "X_test=dft.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\n",
        "y_train=df['Label']\n",
        "y_test=dft['Label']\n",
        "X=X_train\n",
        "y=y_train\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Fj-fW-zITEqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "97000577-6914-4f05-89f8-d2bb8e4c5faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX_train=df.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\\nX_test=dft.drop(columns=['Twitter','Label','Twitter_tokens','Token_len'])\\ny_train=df['Label']\\ny_test=dft['Label']\\nX=X_train\\ny=y_train\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "Xc_selected, yc, test_size=0.2, random_state=42)\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "#very minor boost in performance since our features are already of similar scale, but did give a boost"
      ],
      "metadata": {
        "id": "hagr9i64S0Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "\n",
        "LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "\n",
        "losses = LogRegSent.fit(X_train_norm, y_train)"
      ],
      "metadata": {
        "id": "4nst7aSnSMh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510e17f0-1374-4d00-b2a6-3b6b93e9c38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5200311243215193\n",
            "The iteration is 2000 and the loss is 0.5147366437535069\n",
            "The iteration is 3000 and the loss is 0.5118344063779497\n",
            "The iteration is 4000 and the loss is 0.5097822238029467\n",
            "The iteration is 5000 and the loss is 0.5082863512480211\n",
            "The weight is \n",
            "[ 3.82739655  0.79955854 -0.07744657  1.41160887 -0.9209953   0.81062744\n",
            " -0.20679894  2.05837136  1.89220124  3.03677959 -4.67162514 -0.09132563\n",
            "  0.44075742  1.26288049  1.17038968]\n",
            "The intercept is \n",
            "-6.032237746989782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "plt.plot(losses)\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "AdozPFsDSOTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "80d57902-2c5b-4d09-8685-4cbf7306fb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LogRegSent.predict(X_test_norm)"
      ],
      "metadata": {
        "id": "DMlfHTH1HD4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = LogRegSent.metrics(y_pred, y_test)"
      ],
      "metadata": {
        "id": "LSddLO7DtkZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fe255b-017a-4c3f-9c4b-591700793363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix is: \n",
            "[1149, 1036]\n",
            "[519, 3554]\n",
            "The accuracy for the Twitter sentiment is 0.7515180568871844\n",
            "The precision for the Twitter sentiment is 0.7742919389978213\n",
            "The recall for the Twitter sentiment is 0.8725754971765284\n",
            "The F1 score for the Twitter sentiment is 0.8205009811843472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm-VvUPfuEip",
        "outputId": "e42945b9-cba2-49fb-f36d-7417d81ac1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1166, 1019], [509, 3564]]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "Xc, yc, test_size=0.2, random_state=42)\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "losses = LogRegSent.fit(X_train_norm, y_train)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "plt.plot(losses)\n",
        "plt.show\n",
        "y_pred = LogRegSent.predict(X_test_norm)\n",
        "cm = LogRegSent.metrics(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "4HVZs-Q5tyTj",
        "outputId": "6e667f16-ddca-45c7-a105-a05cc8240697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163337648981696\n",
            "The iteration is 2000 and the loss is 0.5119824758821128\n",
            "The iteration is 3000 and the loss is 0.5096605563872266\n",
            "The iteration is 4000 and the loss is 0.5080362587179873\n",
            "The iteration is 5000 and the loss is 0.5068466849292902\n",
            "The weight is \n",
            "[ 3.78482296  0.95961696  0.08913285  1.41022504 -0.64968299  0.87404907\n",
            " -0.21844328  2.20870057  1.70453716 -0.84113012  0.38050787 -0.88064503\n",
            "  3.22044406 -4.44841141  0.90426279 -0.17841712 -0.89822205  0.05269887\n",
            " -1.09436821  0.67946859 -0.06685071  0.29464851  0.         -0.07085495\n",
            " -0.46595887  1.18808346  1.16645053 -0.0338025 ]\n",
            "The intercept is \n",
            "-3.9837679860651014\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7776565568404975\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8234750462107209\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test 1 Additional Feature"
      ],
      "metadata": {
        "id": "75Bn-oE-r35D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_add_feature(x,y,feat,target):\n",
        "  x_1=x\n",
        "  x_1.insert(1, feat.name, feat)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.2, random_state=42)\n",
        "  mms = MinMaxScaler()\n",
        "  X_train_norm, X_test_norm = mms.fit_transform(X_train), mms.transform(X_test)\n",
        "  feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "  LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "  losses = LogRegSent.fit(X_train_norm, y_train)\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "  plt.plot(losses)\n",
        "  plt.show\n",
        "  y_pred = LogRegSent.predict(X_test_norm)\n",
        "  cm = LogRegSent.metrics(y_pred, y_test)\n",
        "  f1=(2*cm[1][1]/(cm[1][1]+cm[0][1]))*(cm[1][1]/(cm[1][1]+cm[1][0]))/((cm[1][1]/(cm[1][1]+cm[1][0]))+(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "  print(\"The F1 with \" + str(feat.name) + \" is: \" + str(f1) + \" but the target was: \" +str(target))\n",
        "  diff=target-f1\n",
        "  print(\"The difference in F1 score with \" + str(feat.name) + \" is: \" + str(diff))\n",
        "  return diff\n",
        "\n"
      ],
      "metadata": {
        "id": "uy359nLBr7j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  features_selected = Xc_selected.columns\n",
        "  all_features=Xc.columns\n",
        "  removed_features_names=[]\n",
        "  removed_features=[]\n",
        "  for i in range(0,len(all_features)):\n",
        "    good=0\n",
        "    for j in range(0,len(features_selected)):\n",
        "      if all_features[i] == features_selected[j]:\n",
        "        good-=1\n",
        "    if good==0:\n",
        "      removed_features_names.append(Xc.columns[i])\n",
        "\n",
        "  for k in range(0,len(removed_features_names)):\n",
        "    removed_features.append(Xc[removed_features_names[k]])\n",
        "    print(\"Adding \" + str(removed_features_names[k]) + \" to the removed features list\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1MVe_-sdpBw",
        "outputId": "9167cd12-de7c-46a0-8999-517e002976cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding feature10 to the removed features list\n",
            "Adding feature11 to the removed features list\n",
            "Adding feature12 to the removed features list\n",
            "Adding Feature 15 to the removed features list\n",
            "Adding Feature 16 to the removed features list\n",
            "Adding Feature 17 to the removed features list\n",
            "Adding Feature 18 to the removed features list\n",
            "Adding Feature 19 to the removed features list\n",
            "Adding Feature 20 to the removed features list\n",
            "Adding Feature 23 to the removed features list\n",
            "Adding Feature 24 to the removed features list\n",
            "Adding Feature 25 to the removed features list\n",
            "Adding Feature 28 to the removed features list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_diff_add=[]\n",
        "f1_selected = 0.8205009811843472 #this should be the F1 score of the Xc_selected features from SelectFromModel\n",
        "for i in range(0,len(removed_features)):\n",
        "  new=removed_features[i]\n",
        "  Xc_OG=Xc_selected\n",
        "  difference=try_add_feature(Xc_OG,yc,new,f1_selected)\n",
        "  f1_diff_add.append(difference)\n",
        "  print(\"---------------\")\n",
        "for i in range(0,len(removed_features)):\n",
        "  print(\"To remove \" + str(removed_features[i]) + \" there was a loss of \" + str(f1_diff_add[i]) + \" in F1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CUfsYfJc_-RJ",
        "outputId": "e7ddb61c-8ee5-409a-e367-149412fa935c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5196841967540914\n",
            "The iteration is 2000 and the loss is 0.5145978646120509\n",
            "The iteration is 3000 and the loss is 0.5118385447677866\n",
            "The iteration is 4000 and the loss is 0.509888629198091\n",
            "The iteration is 5000 and the loss is 0.5084590254924924\n",
            "The weight is \n",
            "[ 3.8223213  -0.75786424  0.82309067 -0.0750922   1.40115552 -0.87981623\n",
            "  0.80076578 -0.230857    2.04982421  1.87357789  3.45359581 -4.33846946\n",
            " -0.07914294  0.46647226  1.27038873  1.16765758]\n",
            "The intercept is \n",
            "-5.704076502193648\n",
            "The confusion matrix is: \n",
            "[1159, 1026]\n",
            "[515, 3558]\n",
            "The accuracy for the Twitter sentiment is 0.7537551933525087\n",
            "The precision for the Twitter sentiment is 0.7761780104712042\n",
            "The recall for the Twitter sentiment is 0.8735575742695801\n",
            "The F1 score for the Twitter sentiment is 0.8219937622733048\n",
            "The F1 with feature10 is: 0.8219937622733048 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with feature10 is: -0.0014927810889575621\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5194694458899329\n",
            "The iteration is 2000 and the loss is 0.514576244746091\n",
            "The iteration is 3000 and the loss is 0.5118908181947253\n",
            "The iteration is 4000 and the loss is 0.5099686769033143\n",
            "The iteration is 5000 and the loss is 0.5085443986595233\n",
            "The weight is \n",
            "[ 3.82991733 -0.4071495  -0.631022    0.82176122 -0.06922012  1.39216457\n",
            " -0.86244433  0.82128413 -0.23869557  2.04482861  1.86125851  3.36663902\n",
            " -4.38938815 -0.07312536  0.47260823  1.25514039  1.16852765]\n",
            "The intercept is \n",
            "-5.611284396571579\n",
            "The confusion matrix is: \n",
            "[1159, 1026]\n",
            "[507, 3566]\n",
            "The accuracy for the Twitter sentiment is 0.7550335570469798\n",
            "The precision for the Twitter sentiment is 0.7765679442508711\n",
            "The recall for the Twitter sentiment is 0.8755217284556838\n",
            "The F1 score for the Twitter sentiment is 0.8230813618003462\n",
            "The F1 with feature11 is: 0.8230813618003462 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with feature11 is: -0.0025803806159989673\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5186740503506613\n",
            "The iteration is 2000 and the loss is 0.5139333533679343\n",
            "The iteration is 3000 and the loss is 0.5113062272271282\n",
            "The iteration is 4000 and the loss is 0.509411279036311\n",
            "The iteration is 5000 and the loss is 0.5079981378585743\n",
            "The weight is \n",
            "[ 3.83985146 -1.05948986 -0.05194998  0.08680563  0.79233891 -0.06364326\n",
            "  1.34591772 -0.85626958  0.80139454 -0.27962459  2.09338397  1.75372477\n",
            "  3.41156826 -4.34061709 -0.07911667  0.3771169   1.22993801  1.14023598]\n",
            "The intercept is \n",
            "-5.444815264021072\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[514, 3559]\n",
            "The accuracy for the Twitter sentiment is 0.7550335570469798\n",
            "The precision for the Twitter sentiment is 0.7774137177806902\n",
            "The recall for the Twitter sentiment is 0.8738030935428431\n",
            "The F1 score for the Twitter sentiment is 0.8227950525950757\n",
            "The F1 with feature12 is: 0.8227950525950757 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with feature12 is: -0.00229407141072846\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5186707863248343\n",
            "The iteration is 2000 and the loss is 0.5139456363728896\n",
            "The iteration is 3000 and the loss is 0.5113107956694324\n",
            "The iteration is 4000 and the loss is 0.5094077766129109\n",
            "The iteration is 5000 and the loss is 0.5079869908205968\n",
            "The weight is \n",
            "[ 3.84735178 -0.10353643 -1.03800625 -0.0470582   0.11659175  0.795592\n",
            " -0.06146674  1.34644357 -0.85840456  0.80250618 -0.28523418  2.10074331\n",
            "  1.75372581  3.43208597 -4.32945437 -0.07908636  0.38101814  1.22849196\n",
            "  1.1400917 ]\n",
            "The intercept is \n",
            "-5.463324074256741\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[512, 3561]\n",
            "The accuracy for the Twitter sentiment is 0.7553531479705976\n",
            "The precision for the Twitter sentiment is 0.7775109170305677\n",
            "The recall for the Twitter sentiment is 0.874294132089369\n",
            "The F1 score for the Twitter sentiment is 0.8230671443430025\n",
            "The F1 with Feature 15 is: 0.8230671443430025 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 15 is: -0.0025661631586553213\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5185826705945769\n",
            "The iteration is 2000 and the loss is 0.5138899025580396\n",
            "The iteration is 3000 and the loss is 0.5112749426877095\n",
            "The iteration is 4000 and the loss is 0.5093865019873559\n",
            "The iteration is 5000 and the loss is 0.5079771827215407\n",
            "The weight is \n",
            "[ 3.84285131e+00  2.43311728e-01 -1.97605962e-02 -1.08551373e+00\n",
            " -4.55784595e-02  1.46582852e-03  8.13330800e-01 -8.03916154e-02\n",
            "  1.36653327e+00 -8.62062105e-01  7.99056451e-01 -2.79551552e-01\n",
            "  2.08992111e+00  1.76361662e+00  3.39874921e+00 -4.33570010e+00\n",
            " -8.32884660e-02  3.53098876e-01  1.22251134e+00  1.14269697e+00]\n",
            "The intercept is \n",
            "-5.415094920383976\n",
            "The confusion matrix is: \n",
            "[1163, 1022]\n",
            "[513, 3560]\n",
            "The accuracy for the Twitter sentiment is 0.7547139661233621\n",
            "The precision for the Twitter sentiment is 0.7769532955041467\n",
            "The recall for the Twitter sentiment is 0.874048612816106\n",
            "The F1 score for the Twitter sentiment is 0.8226458694396304\n",
            "The F1 with Feature 16 is: 0.8226458694396304 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 16 is: -0.0021448882552831394\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5171320805574434\n",
            "The iteration is 2000 and the loss is 0.5129746366158947\n",
            "The iteration is 3000 and the loss is 0.5107315601790019\n",
            "The iteration is 4000 and the loss is 0.5091229385419612\n",
            "The iteration is 5000 and the loss is 0.5079174666581198\n",
            "The weight is \n",
            "[ 3.76584485 -1.0833011   0.08707314 -0.18194917 -1.04789441  0.08407574\n",
            " -0.28263836  0.88588098 -0.02698666  1.36532341 -0.72887417  0.81225233\n",
            " -0.20711711  2.09509387  1.72010806  3.59110513 -4.17814798 -0.07421176\n",
            "  0.28260355  1.23651223  1.13923229]\n",
            "The intercept is \n",
            "-4.355968910071053\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[520, 3553]\n",
            "The accuracy for the Twitter sentiment is 0.7540747842761265\n",
            "The precision for the Twitter sentiment is 0.7771216097987752\n",
            "The recall for the Twitter sentiment is 0.8723299779032654\n",
            "The F1 score for the Twitter sentiment is 0.8219780219780219\n",
            "The F1 with Feature 17 is: 0.8219780219780219 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 17 is: -0.001477040793674722\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5171318952169977\n",
            "The iteration is 2000 and the loss is 0.512973776706933\n",
            "The iteration is 3000 and the loss is 0.5107300911927491\n",
            "The iteration is 4000 and the loss is 0.5091209217870248\n",
            "The iteration is 5000 and the loss is 0.5079149515721152\n",
            "The weight is \n",
            "[ 3.76649303  0.07527997 -1.08334732  0.08736547 -0.18174524 -1.04739078\n",
            "  0.08420952 -0.28296291  0.8863943  -0.02707386  1.36568666 -0.72897817\n",
            "  0.81225403 -0.20745102  2.09516839  1.72050918  3.59070289 -4.17848953\n",
            " -0.07424602  0.28280644  1.23667751  1.13912495]\n",
            "The intercept is \n",
            "-4.357100038513733\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[520, 3553]\n",
            "The accuracy for the Twitter sentiment is 0.7540747842761265\n",
            "The precision for the Twitter sentiment is 0.7771216097987752\n",
            "The recall for the Twitter sentiment is 0.8723299779032654\n",
            "The F1 score for the Twitter sentiment is 0.8219780219780219\n",
            "The F1 with Feature 18 is: 0.8219780219780219 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 18 is: -0.001477040793674722\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163713108414439\n",
            "The iteration is 2000 and the loss is 0.5120760152364388\n",
            "The iteration is 3000 and the loss is 0.5098103986817497\n",
            "The iteration is 4000 and the loss is 0.5082159940802923\n",
            "The iteration is 5000 and the loss is 0.5070432375968591\n",
            "The weight is \n",
            "[ 3.76842503 -1.12649724  0.05836342 -0.92208599 -0.17655947  0.96786677\n",
            " -1.1078544   0.11025678 -0.72519964  0.96449287  0.08540655  1.40958586\n",
            " -0.65417553  0.86327368 -0.21556197  2.20441704  1.7143757   3.29142349\n",
            " -4.40503241 -0.06689027  0.30665048  1.18867661  1.1630998 ]\n",
            "The intercept is \n",
            "-3.9921714236306096\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[514, 3559]\n",
            "The accuracy for the Twitter sentiment is 0.7548737615851709\n",
            "The precision for the Twitter sentiment is 0.7772439397248307\n",
            "The recall for the Twitter sentiment is 0.8738030935428431\n",
            "The F1 score for the Twitter sentiment is 0.8226999537679149\n",
            "The F1 with Feature 19 is: 0.8226999537679149 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 19 is: -0.0021989725835677154\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.516297378543645\n",
            "The iteration is 2000 and the loss is 0.5119581587419764\n",
            "The iteration is 3000 and the loss is 0.5096624735516548\n",
            "The iteration is 4000 and the loss is 0.5080473304640782\n",
            "The iteration is 5000 and the loss is 0.5068602193021096\n",
            "The weight is \n",
            "[ 3.78395715  0.68503245 -1.13723866  0.05649267 -0.91995628 -0.17506608\n",
            "  0.96458924 -1.10236248  0.11499152 -0.73012516  0.96931328  0.0844054\n",
            "  1.41738506 -0.65487014  0.86279408 -0.22102169  2.20757069  1.7133027\n",
            "  3.28618052 -4.40388946 -0.06758834  0.30600041  1.19365486  1.16525005]\n",
            "The intercept is \n",
            "-4.010985548676466\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[516, 3557]\n",
            "The accuracy for the Twitter sentiment is 0.7545541706615532\n",
            "The precision for the Twitter sentiment is 0.777146602578108\n",
            "The recall for the Twitter sentiment is 0.8733120549963173\n",
            "The F1 score for the Twitter sentiment is 0.8224277456647401\n",
            "The F1 with Feature 20 is: 0.8224277456647401 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 20 is: -0.0019267644803928619\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.516297378543645\n",
            "The iteration is 2000 and the loss is 0.5119581587419764\n",
            "The iteration is 3000 and the loss is 0.5096624735516548\n",
            "The iteration is 4000 and the loss is 0.5080473304640782\n",
            "The iteration is 5000 and the loss is 0.5068602193021096\n",
            "The weight is \n",
            "[ 3.78395715  0.          0.68503245 -1.13723866  0.05649267 -0.91995628\n",
            " -0.17506608  0.96458924 -1.10236248  0.11499152 -0.73012516  0.96931328\n",
            "  0.0844054   1.41738506 -0.65487014  0.86279408 -0.22102169  2.20757069\n",
            "  1.7133027   3.28618052 -4.40388946 -0.06758834  0.30600041  1.19365486\n",
            "  1.16525005]\n",
            "The intercept is \n",
            "-4.010985548676467\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[516, 3557]\n",
            "The accuracy for the Twitter sentiment is 0.7545541706615532\n",
            "The precision for the Twitter sentiment is 0.777146602578108\n",
            "The recall for the Twitter sentiment is 0.8733120549963173\n",
            "The F1 score for the Twitter sentiment is 0.8224277456647401\n",
            "The F1 with Feature 23 is: 0.8224277456647401 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 23 is: -0.0019267644803928619\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163026064917753\n",
            "The iteration is 2000 and the loss is 0.5119691299602518\n",
            "The iteration is 3000 and the loss is 0.5096641920196481\n",
            "The iteration is 4000 and the loss is 0.5080439074002698\n",
            "The iteration is 5000 and the loss is 0.5068543742542371\n",
            "The weight is \n",
            "[ 3.78480456 -0.29544986  0.          0.68343078 -1.12430927  0.05534441\n",
            " -0.91327481 -0.17562844  0.94735206 -1.03272072  0.20941981 -0.77011622\n",
            "  0.96511437  0.08623474  1.41405643 -0.65399245  0.86627806 -0.22124061\n",
            "  2.20797863  1.71032035  3.26291505 -4.41974744 -0.06653172  0.30344778\n",
            "  1.19077671  1.16626071]\n",
            "The intercept is \n",
            "-4.010638121469006\n",
            "The confusion matrix is: \n",
            "[1168, 1017]\n",
            "[514, 3559]\n",
            "The accuracy for the Twitter sentiment is 0.7553531479705976\n",
            "The precision for the Twitter sentiment is 0.7777534965034965\n",
            "The recall for the Twitter sentiment is 0.8738030935428431\n",
            "The F1 score for the Twitter sentiment is 0.8229853162215286\n",
            "The F1 with Feature 24 is: 0.8229853162215286 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 24 is: -0.0024843350371813733\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163340101158802\n",
            "The iteration is 2000 and the loss is 0.5119826742128999\n",
            "The iteration is 3000 and the loss is 0.5096607024933104\n",
            "The iteration is 4000 and the loss is 0.5080363389529559\n",
            "The iteration is 5000 and the loss is 0.5068466938846996\n",
            "The weight is \n",
            "[ 3.78526948 -0.46631567 -0.07116529  0.          0.67958241 -1.09467171\n",
            "  0.05272546 -0.89812695 -0.17856745  0.90448278 -0.88024835  0.38015263\n",
            " -0.84083245  0.95972919  0.08911563  1.41047171 -0.64989921  0.87396593\n",
            " -0.21848957  2.20887995  1.70449108  3.22045152 -4.44841924 -0.06693897\n",
            "  0.29484725  1.18808411  1.16632075]\n",
            "The intercept is \n",
            "-3.9843846104322767\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7559923298178332\n",
            "The precision for the Twitter sentiment is 0.7778262767350502\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8235701906412478\n",
            "The F1 with Feature 25 is: 0.8235701906412478 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 25 is: -0.00306920945690059\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163337648981696\n",
            "The iteration is 2000 and the loss is 0.5119824758821128\n",
            "The iteration is 3000 and the loss is 0.5096605563872266\n",
            "The iteration is 4000 and the loss is 0.5080362587179873\n",
            "The iteration is 5000 and the loss is 0.5068466849292902\n",
            "The weight is \n",
            "[ 3.78482296 -0.0338025  -0.46595887 -0.07085495  0.          0.67946859\n",
            " -1.09436821  0.05269887 -0.89822205 -0.17841712  0.90426279 -0.88064503\n",
            "  0.38050787 -0.84113012  0.95961696  0.08913285  1.41022504 -0.64968299\n",
            "  0.87404907 -0.21844328  2.20870057  1.70453716  3.22044406 -4.44841141\n",
            " -0.06685071  0.29464851  1.18808346  1.16645053]\n",
            "The intercept is \n",
            "-3.983767986065105\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7776565568404975\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8234750462107209\n",
            "The F1 with Feature 28 is: 0.8234750462107209 but the target was: 0.8205009811843472\n",
            "The difference in F1 score with Feature 28 is: -0.0029740650263736512\n",
            "---------------\n",
            "To remove 0        1.041393\n",
            "1        1.113943\n",
            "2        1.079181\n",
            "3        1.322219\n",
            "4        1.000000\n",
            "           ...   \n",
            "31284    0.954243\n",
            "31285    1.041393\n",
            "31286    0.845098\n",
            "31287    0.954243\n",
            "31288    0.778151\n",
            "Name: feature10, Length: 31289, dtype: float64 there was a loss of -0.0014927810889575621 in F1\n",
            "To remove 0        1.361728\n",
            "1        0.845098\n",
            "2        1.000000\n",
            "3        0.954243\n",
            "4        1.079181\n",
            "           ...   \n",
            "31284    0.845098\n",
            "31285    1.000000\n",
            "31286    0.845098\n",
            "31287    1.113943\n",
            "31288    0.954243\n",
            "Name: feature11, Length: 31289, dtype: float64 there was a loss of -0.0025803806159989673 in F1\n",
            "To remove 0        0.954243\n",
            "1        1.000000\n",
            "2        0.903090\n",
            "3        1.041393\n",
            "4        0.602060\n",
            "           ...   \n",
            "31284    0.845098\n",
            "31285    0.602060\n",
            "31286    0.845098\n",
            "31287    0.903090\n",
            "31288    0.698970\n",
            "Name: feature12, Length: 31289, dtype: float64 there was a loss of -0.00229407141072846 in F1\n",
            "To remove 0         7.0\n",
            "1         5.0\n",
            "2         7.0\n",
            "3        11.0\n",
            "4         5.0\n",
            "         ... \n",
            "31284     4.0\n",
            "31285     5.0\n",
            "31286     3.0\n",
            "31287     5.0\n",
            "31288     5.0\n",
            "Name: Feature 15, Length: 31289, dtype: float64 there was a loss of -0.0025661631586553213 in F1\n",
            "To remove 0        2.0\n",
            "1        1.0\n",
            "2        1.0\n",
            "3        4.0\n",
            "4        2.0\n",
            "        ... \n",
            "31284    2.0\n",
            "31285    2.0\n",
            "31286    2.0\n",
            "31287    0.0\n",
            "31288    1.0\n",
            "Name: Feature 16, Length: 31289, dtype: float64 there was a loss of -0.0021448882552831394 in F1\n",
            "To remove 0        1.000000\n",
            "1        1.000000\n",
            "2        0.916667\n",
            "3        1.000000\n",
            "4        1.000000\n",
            "           ...   \n",
            "31284    1.000000\n",
            "31285    1.000000\n",
            "31286    0.714286\n",
            "31287    1.000000\n",
            "31288    1.000000\n",
            "Name: Feature 17, Length: 31289, dtype: float64 there was a loss of -0.001477040793674722 in F1\n",
            "To remove 0        0.0\n",
            "1        0.0\n",
            "2        0.0\n",
            "3        0.0\n",
            "4        0.0\n",
            "        ... \n",
            "31284    0.0\n",
            "31285    0.0\n",
            "31286    0.0\n",
            "31287    0.0\n",
            "31288    0.0\n",
            "Name: Feature 18, Length: 31289, dtype: float64 there was a loss of -0.001477040793674722 in F1\n",
            "To remove 0        0.636364\n",
            "1        0.384615\n",
            "2        0.583333\n",
            "3        0.523810\n",
            "4        0.500000\n",
            "           ...   \n",
            "31284    0.444444\n",
            "31285    0.454545\n",
            "31286    0.428571\n",
            "31287    0.555556\n",
            "31288    0.833333\n",
            "Name: Feature 19, Length: 31289, dtype: float64 there was a loss of -0.0021989725835677154 in F1\n",
            "To remove 0        0.0\n",
            "1        0.0\n",
            "2        0.0\n",
            "3        0.0\n",
            "4        0.0\n",
            "        ... \n",
            "31284    0.0\n",
            "31285    0.0\n",
            "31286    0.0\n",
            "31287    0.0\n",
            "31288    0.0\n",
            "Name: Feature 20, Length: 31289, dtype: float64 there was a loss of -0.0019267644803928619 in F1\n",
            "To remove 0        0.0\n",
            "1        0.0\n",
            "2        0.0\n",
            "3        0.0\n",
            "4        0.0\n",
            "        ... \n",
            "31284    0.0\n",
            "31285    0.0\n",
            "31286    0.0\n",
            "31287    0.0\n",
            "31288    0.0\n",
            "Name: Feature 23, Length: 31289, dtype: float64 there was a loss of -0.0019267644803928619 in F1\n",
            "To remove 0        7.000000\n",
            "1        5.230769\n",
            "2        5.416667\n",
            "3        4.428571\n",
            "4        5.300000\n",
            "           ...   \n",
            "31284    5.000000\n",
            "31285    5.090909\n",
            "31286    5.714286\n",
            "31287    7.777778\n",
            "31288    5.833333\n",
            "Name: Feature 24, Length: 31289, dtype: float64 there was a loss of -0.0024843350371813733 in F1\n",
            "To remove 0        1.945910\n",
            "1        1.654558\n",
            "2        1.689481\n",
            "3        1.488077\n",
            "4        1.667707\n",
            "           ...   \n",
            "31284    1.609438\n",
            "31285    1.627456\n",
            "31286    1.742969\n",
            "31287    2.051271\n",
            "31288    1.763589\n",
            "Name: Feature 25, Length: 31289, dtype: float64 there was a loss of -0.00306920945690059 in F1\n",
            "To remove 0        0.0\n",
            "1        0.0\n",
            "2        0.0\n",
            "3        0.0\n",
            "4        0.0\n",
            "        ... \n",
            "31284    0.0\n",
            "31285    0.0\n",
            "31286    0.0\n",
            "31287    0.0\n",
            "31288    0.0\n",
            "Name: Feature 28, Length: 31289, dtype: float64 there was a loss of -0.0029740650263736512 in F1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(removed_features)):\n",
        "  print(\"To remove \" + str(removed_features[i].name) + \" there was a loss of \" + str(f1_diff_add[i]) + \" in F1\")"
      ],
      "metadata": {
        "id": "rsK5cb3dC-6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f253aaf1-c738-493d-b7cb-eb3c63f1c11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To remove feature10 there was a loss of -0.0014927810889575621 in F1\n",
            "To remove feature11 there was a loss of -0.0025803806159989673 in F1\n",
            "To remove feature12 there was a loss of -0.00229407141072846 in F1\n",
            "To remove Feature 15 there was a loss of -0.0025661631586553213 in F1\n",
            "To remove Feature 16 there was a loss of -0.0021448882552831394 in F1\n",
            "To remove Feature 17 there was a loss of -0.001477040793674722 in F1\n",
            "To remove Feature 18 there was a loss of -0.001477040793674722 in F1\n",
            "To remove Feature 19 there was a loss of -0.0021989725835677154 in F1\n",
            "To remove Feature 20 there was a loss of -0.0019267644803928619 in F1\n",
            "To remove Feature 23 there was a loss of -0.0019267644803928619 in F1\n",
            "To remove Feature 24 there was a loss of -0.0024843350371813733 in F1\n",
            "To remove Feature 25 there was a loss of -0.00306920945690059 in F1\n",
            "To remove Feature 28 there was a loss of -0.0029740650263736512 in F1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_diffs_add_percent = []\n",
        "maxnum=(min(f1_diff_add))\n",
        "for i in range (0,len(f1_diff_add)):\n",
        "  num=f1_diff_add[i]\n",
        "  val = 100 * (num/maxnum)\n",
        "  f1_diffs_add_percent.append(val)\n",
        "  print(\"The feature \" + str(removed_features[i].name) + \" has a relative importance percentage \" + str(f1_diffs_add_percent[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKd4VsnNobLY",
        "outputId": "9716b21b-a246-4030-bd0d-30aef335b7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature feature10 has a relative importance percentage 48.63731556675939\n",
            "The feature feature11 has a relative importance percentage 84.0731351911296\n",
            "The feature feature12 has a relative importance percentage 74.74470031918592\n",
            "The feature Feature 15 has a relative importance percentage 83.60990654729493\n",
            "The feature Feature 16 has a relative importance percentage 69.8840625054353\n",
            "The feature Feature 17 has a relative importance percentage 48.12447030468545\n",
            "The feature Feature 18 has a relative importance percentage 48.12447030468545\n",
            "The feature Feature 19 has a relative importance percentage 71.64622077596246\n",
            "The feature Feature 20 has a relative importance percentage 62.777223498411395\n",
            "The feature Feature 23 has a relative importance percentage 62.777223498411395\n",
            "The feature Feature 24 has a relative importance percentage 80.9438088884997\n",
            "The feature Feature 25 has a relative importance percentage 100.0\n",
            "The feature Feature 28 has a relative importance percentage 96.90003462249788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try 1 Remove Feature"
      ],
      "metadata": {
        "id": "-5A_vwhaWKCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_remove_feature(x,y,feat,target):\n",
        "  x_1=x\n",
        "  x_1=x_1.drop(columns=feat)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x_1, y, test_size=0.2, random_state=42)\n",
        "  X_train_norm, X_test_norm = mms.fit_transform(X_train), mms.transform(X_test)\n",
        "  feature_number, lr, epochs = X_train.shape[1], .5, 1000000\n",
        "  LogRegSent = LogRegression(feature_number, lr, epochs)\n",
        "  losses = LogRegSent.fit(X_train_norm, y_train)\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss vs Iterations on Twitter Sentiment\")\n",
        "  plt.plot(losses)\n",
        "  plt.show\n",
        "  y_pred = LogRegSent.predict(X_test_norm)\n",
        "  cm = LogRegSent.metrics(y_pred, y_test)\n",
        "  f1=(2*cm[1][1]/(cm[1][1]+cm[0][1]))*(cm[1][1]/(cm[1][1]+cm[1][0]))/((cm[1][1]/(cm[1][1]+cm[1][0]))+(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "  print(\"The F1 with \" + str(feat) + \" is: \" + str(f1) + \" but the target was: \" +str(target))\n",
        "  diff=target-f1\n",
        "  print(\"The difference in F1 score without \" + str(feat) + \" is: \" + str(diff))\n",
        "  return diff\n",
        "\n"
      ],
      "metadata": {
        "id": "b8_3fAeyWJm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features=Xc.columns\n",
        "f1_diff_rem=[]\n",
        "f1_selected = 0.8234750462107209 #this should be F1 score for logreg of all_features\n",
        "for i in range(0,len(all_features)):\n",
        "  new=all_features[i]\n",
        "  difference=try_remove_feature(Xc,yc,new,f1_selected)\n",
        "  f1_diff_rem.append(difference)\n",
        "  print(\"---------------\")\n",
        "for i in range(0,len(all_features)):\n",
        "  print(\"To remove \" + str(all_features[i]) + \" there was a loss of \" + str(f1_diff_rem[i]) + \" in F1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "24OBixYSW3O2",
        "outputId": "ecd29d53-085c-491d-a986-5a8a0afd9114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5195213987717158\n",
            "The iteration is 2000 and the loss is 0.5166309665940962\n",
            "The iteration is 3000 and the loss is 0.5153100848352188\n",
            "The weight is \n",
            "[ 1.02005837  0.32852883  1.43025142 -0.29719017  0.97358146  0.03328336\n",
            "  2.10723821  1.84029904 -0.52350885  0.23170659 -0.83332889  3.41715996\n",
            " -4.57456459  0.53160169 -0.12898674 -0.84950064  0.03416039 -0.84136759\n",
            "  0.50317461 -0.05637017  0.3023505   0.         -0.13368123 -0.44904497\n",
            "  1.16918284  1.31932973 -0.03435339]\n",
            "The intercept is \n",
            "-2.444708083765628\n",
            "The confusion matrix is: \n",
            "[1141, 1044]\n",
            "[512, 3561]\n",
            "The accuracy for the Twitter sentiment is 0.7513582614253755\n",
            "The precision for the Twitter sentiment is 0.7732899022801303\n",
            "The recall for the Twitter sentiment is 0.874294132089369\n",
            "The F1 score for the Twitter sentiment is 0.8206960129061994\n",
            "The F1 with feature1 is: 0.8206960129061994 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature1 is: 0.00277903330452145\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5165487178581781\n",
            "The iteration is 2000 and the loss is 0.5122603904629086\n",
            "The iteration is 3000 and the loss is 0.5100129920597501\n",
            "The iteration is 4000 and the loss is 0.5084616943809923\n",
            "The weight is \n",
            "[ 3.76911226  0.17313584  1.43804774 -0.59722374  0.898866   -0.15906064\n",
            "  2.25927493  1.75836519 -0.76370726  0.36875003 -0.88190562  3.25577487\n",
            " -4.49877835  0.84765532 -0.18933086 -0.87562886  0.04238482 -1.04096292\n",
            "  0.65920838 -0.06603425  0.28428391  0.         -0.08785819 -0.46995984\n",
            "  1.19360727  1.18126645 -0.03412836]\n",
            "The intercept is \n",
            "-3.689293005974128\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[511, 3562]\n",
            "The accuracy for the Twitter sentiment is 0.7556727388942154\n",
            "The precision for the Twitter sentiment is 0.7777292576419214\n",
            "The recall for the Twitter sentiment is 0.874539651362632\n",
            "The F1 score for the Twitter sentiment is 0.8232982780538541\n",
            "The F1 with feature2 is: 0.8232982780538541 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature2 is: 0.00017676815686673564\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5162291185353058\n",
            "The iteration is 2000 and the loss is 0.5119042712846574\n",
            "The iteration is 3000 and the loss is 0.5096168232441695\n",
            "The iteration is 4000 and the loss is 0.5080108479818278\n",
            "The iteration is 5000 and the loss is 0.5068312659924786\n",
            "The weight is \n",
            "[ 3.77524462  0.97695608  1.39925328 -0.63572955  0.88931795 -0.20801044\n",
            "  2.22002616  1.71226622 -0.84442942  0.3776242  -0.88454076  3.21833846\n",
            " -4.4546621   0.90431846 -0.16949163 -0.90514403  0.05272524 -1.0879854\n",
            "  0.67627063 -0.06722797  0.29377992  0.         -0.0695262  -0.46466867\n",
            "  1.20335406  1.16541956 -0.03480756]\n",
            "The intercept is \n",
            "-3.9739327241543063\n",
            "The confusion matrix is: \n",
            "[1168, 1017]\n",
            "[508, 3565]\n",
            "The accuracy for the Twitter sentiment is 0.7563119207414509\n",
            "The precision for the Twitter sentiment is 0.7780445220427761\n",
            "The recall for the Twitter sentiment is 0.8752762091824208\n",
            "The F1 score for the Twitter sentiment is 0.8238012709416522\n",
            "The F1 with feature3 is: 0.8238012709416522 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature3 is: -0.00032622473093135707\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5167307564756243\n",
            "The iteration is 2000 and the loss is 0.5126517798683055\n",
            "The iteration is 3000 and the loss is 0.5105536425743515\n",
            "The iteration is 4000 and the loss is 0.5091192879688591\n",
            "The weight is \n",
            "[ 3.77775747  1.02570607  0.14481131 -0.48330832  0.89704421 -0.10157749\n",
            "  2.22482468  1.75448449 -0.69607343  0.34985948 -0.87548765  3.24086618\n",
            " -4.45245507  0.75549182 -0.20393851 -0.85822625  0.04554551 -1.00940169\n",
            "  0.63407464 -0.06151007  0.31128991  0.         -0.09792459 -0.46009048\n",
            "  1.23160224  1.21352466 -0.0364428 ]\n",
            "The intercept is \n",
            "-3.378002370931309\n",
            "The confusion matrix is: \n",
            "[1152, 1033]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7535953978907\n",
            "The precision for the Twitter sentiment is 0.7752882314552969\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8221453287197231\n",
            "The F1 with feature4 is: 0.8221453287197231 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature4 is: 0.0013297174909977505\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5164008917750614\n",
            "The iteration is 2000 and the loss is 0.5121043913363532\n",
            "The iteration is 3000 and the loss is 0.5097996478924581\n",
            "The iteration is 4000 and the loss is 0.5081716352127175\n",
            "The iteration is 5000 and the loss is 0.5069679984961221\n",
            "The weight is \n",
            "[ 3.76986376  0.9391937   0.05465401  1.3675349   0.83201807 -0.24187063\n",
            "  2.18341574  1.68260447 -0.87531321  0.3773849  -0.88161023  3.22887632\n",
            " -4.44630066  0.92652998 -0.18877138 -0.91686576  0.05332009 -1.11430481\n",
            "  0.6860669  -0.06896016  0.28300022  0.         -0.07095387 -0.47509862\n",
            "  1.15439915  1.15756659 -0.03723842]\n",
            "The intercept is \n",
            "-4.105808317449171\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[507, 3566]\n",
            "The accuracy for the Twitter sentiment is 0.7559923298178332\n",
            "The precision for the Twitter sentiment is 0.7775839511556912\n",
            "The recall for the Twitter sentiment is 0.8755217284556838\n",
            "The F1 score for the Twitter sentiment is 0.8236516918812796\n",
            "The F1 with feature5 is: 0.8236516918812796 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature5 is: -0.00017664567055875047\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5165899374276323\n",
            "The iteration is 2000 and the loss is 0.5122336109968231\n",
            "The iteration is 3000 and the loss is 0.5099343164316346\n",
            "The iteration is 4000 and the loss is 0.5083323630908719\n",
            "The iteration is 5000 and the loss is 0.5071627215178734\n",
            "The weight is \n",
            "[ 3.80563554  0.98626931  0.16931808  1.41160656 -0.56365155 -0.16975201\n",
            "  2.23991907  1.84403851 -0.81854183  0.39067414 -0.89748669  3.25238154\n",
            " -4.47780988  0.88303829 -0.16785205 -0.89552545  0.054169   -1.06847921\n",
            "  0.67835464 -0.06337817  0.31695564  0.         -0.06480023 -0.44548829\n",
            "  1.25127777  1.17351515 -0.0280716 ]\n",
            "The intercept is \n",
            "-3.868005717305011\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7559923298178332\n",
            "The precision for the Twitter sentiment is 0.7778262767350502\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8235701906412478\n",
            "The F1 with feature6 is: 0.8235701906412478 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature6 is: -9.514443052693888e-05\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5162922857419026\n",
            "The iteration is 2000 and the loss is 0.5119874014117304\n",
            "The iteration is 3000 and the loss is 0.5096854485759964\n",
            "The iteration is 4000 and the loss is 0.5080645385561624\n",
            "The iteration is 5000 and the loss is 0.506871039575112\n",
            "The weight is \n",
            "[ 3.78013992  0.94842527  0.07726522  1.39764205 -0.66085366  0.86346018\n",
            "  2.20125158  1.69187872 -0.84986294  0.3808189  -0.88017958  3.21648528\n",
            " -4.44661895  0.91512671 -0.178597   -0.90789692  0.05242305 -1.0949139\n",
            "  0.68053641 -0.06698666  0.29258813  0.         -0.06986406 -0.4671721\n",
            "  1.17091625  1.1573569  -0.03396218]\n",
            "The intercept is \n",
            "-4.01655539505734\n",
            "The confusion matrix is: \n",
            "[1172, 1013]\n",
            "[510, 3563]\n",
            "The accuracy for the Twitter sentiment is 0.7566315116650687\n",
            "The precision for the Twitter sentiment is 0.7786276223776224\n",
            "The recall for the Twitter sentiment is 0.8747851706358949\n",
            "The F1 score for the Twitter sentiment is 0.8239102786449299\n",
            "The F1 with feature7 is: 0.8239102786449299 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature7 is: -0.0004352324342090652\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5186688370629529\n",
            "The iteration is 2000 and the loss is 0.5144703622951858\n",
            "The iteration is 3000 and the loss is 0.5122879699157094\n",
            "The iteration is 4000 and the loss is 0.5107537501649791\n",
            "The weight is \n",
            "[ 3.7841223   1.20698919  0.3466767   1.5035583  -0.46135373  0.99949596\n",
            " -0.08073885  1.76169386 -0.83681884  0.31161416 -0.84130263  3.41022639\n",
            " -4.6861884   0.86961049 -0.0929812  -0.87551054  0.05836383 -0.91100545\n",
            "  0.66300343 -0.05601817  0.2647262   0.         -0.07649265 -0.44682151\n",
            "  1.22009083  1.16717946 -0.0487961 ]\n",
            "The intercept is \n",
            "-3.750878168582745\n",
            "The confusion matrix is: \n",
            "[1141, 1044]\n",
            "[510, 3563]\n",
            "The accuracy for the Twitter sentiment is 0.7516778523489933\n",
            "The precision for the Twitter sentiment is 0.7733883221185153\n",
            "The recall for the Twitter sentiment is 0.8747851706358949\n",
            "The F1 score for the Twitter sentiment is 0.8209677419354839\n",
            "The F1 with feature8 is: 0.8209677419354839 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature8 is: 0.0025073042752369323\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5173502178051473\n",
            "The iteration is 2000 and the loss is 0.5129981042541006\n",
            "The iteration is 3000 and the loss is 0.5106911385577955\n",
            "The iteration is 4000 and the loss is 0.5090781874993889\n",
            "The iteration is 5000 and the loss is 0.5078981542471842\n",
            "The weight is \n",
            "[ 3.98833943  1.1057632   0.20045709  1.50334178 -0.56517742  1.14641711\n",
            " -0.09537777  2.23738806 -0.75751743  0.40125034 -0.94058792  3.31444417\n",
            " -4.50822918  0.85773363 -0.20933182 -0.89322705  0.03756975 -1.08789461\n",
            "  0.69206534 -0.06366295  0.31375778  0.         -0.09159134 -0.49104259\n",
            "  1.30572577  1.21499581 -0.02389291]\n",
            "The intercept is \n",
            "-3.78507348174478\n",
            "The confusion matrix is: \n",
            "[1156, 1029]\n",
            "[503, 3570]\n",
            "The accuracy for the Twitter sentiment is 0.7551933525087887\n",
            "The precision for the Twitter sentiment is 0.776255707762557\n",
            "The recall for the Twitter sentiment is 0.8765038055487355\n",
            "The F1 score for the Twitter sentiment is 0.8233394833948339\n",
            "The F1 with feature9 is: 0.8233394833948339 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature9 is: 0.00013556281588700259\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5165109189903094\n",
            "The iteration is 2000 and the loss is 0.5121643083422734\n",
            "The iteration is 3000 and the loss is 0.5098313865552073\n",
            "The iteration is 4000 and the loss is 0.5081832183732117\n",
            "The iteration is 5000 and the loss is 0.5069631365381184\n",
            "The weight is \n",
            "[ 3.77849962  0.91610973  0.08674332  1.37032883 -0.69728134  0.86398661\n",
            " -0.24349461  2.21856307  1.68104268  0.29414856 -1.10794952  3.05132807\n",
            " -4.6114512   0.63867182 -0.24429202 -0.86312746  0.04692659 -0.9538984\n",
            "  0.68535813 -0.0711213   0.28302728  0.          0.0114025  -0.35647396\n",
            "  1.17160643  1.15863881 -0.02097116]\n",
            "The intercept is \n",
            "-4.246407603916145\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[510, 3563]\n",
            "The accuracy for the Twitter sentiment is 0.7555129434324065\n",
            "The precision for the Twitter sentiment is 0.777438359153393\n",
            "The recall for the Twitter sentiment is 0.8747851706358949\n",
            "The F1 score for the Twitter sentiment is 0.8232439926062847\n",
            "The F1 with feature10 is: 0.8232439926062847 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature10 is: 0.00023105360443620437\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5162226668241097\n",
            "The iteration is 2000 and the loss is 0.5119957873157093\n",
            "The iteration is 3000 and the loss is 0.5097292938661668\n",
            "The iteration is 4000 and the loss is 0.5081259774539734\n",
            "The iteration is 5000 and the loss is 0.5069434649071514\n",
            "The weight is \n",
            "[ 3.78544811  0.9623188   0.09189124  1.41256133 -0.64218766  0.88100851\n",
            " -0.2161511   2.20408915  1.70742369 -0.82030358 -0.84370856  3.19989054\n",
            " -4.45604043  0.90990749 -0.17256946 -0.88391882  0.05277747 -1.09116011\n",
            "  0.67815546 -0.06576117  0.30504742  0.         -0.00495658 -0.35889674\n",
            "  1.185204    1.17095357 -0.0295049 ]\n",
            "The intercept is \n",
            "-3.9592951220087804\n",
            "The confusion matrix is: \n",
            "[1171, 1014]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7566315116650687\n",
            "The precision for the Twitter sentiment is 0.7785058977719528\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8239509883250491\n",
            "The F1 with feature11 is: 0.8239509883250491 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature11 is: -0.00047594211432822053\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.516684013986328\n",
            "The iteration is 2000 and the loss is 0.5122622352185372\n",
            "The iteration is 3000 and the loss is 0.5098924601904079\n",
            "The iteration is 4000 and the loss is 0.5082268135584687\n",
            "The iteration is 5000 and the loss is 0.5070079801442307\n",
            "The weight is \n",
            "[ 3.8061775   0.9749259   0.10451551  1.43323458 -0.64773809  0.90278096\n",
            " -0.20453943  2.19810647  1.75762723 -1.28597776  0.45050944  3.1352479\n",
            " -4.5076201   0.71311188 -0.2583997  -0.88002398  0.06998947 -1.01287645\n",
            "  0.69665985 -0.05947513  0.36010402  0.         -0.31392571 -1.00128857\n",
            "  1.19016004  1.19003606 -0.00559188]\n",
            "The intercept is \n",
            "-4.096294505203684\n",
            "The confusion matrix is: \n",
            "[1169, 1016]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7563119207414509\n",
            "The precision for the Twitter sentiment is 0.7781659388646288\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8237605454755575\n",
            "The F1 with feature12 is: 0.8237605454755575 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without feature12 is: -0.000285499264836675\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5253999487171973\n",
            "The iteration is 2000 and the loss is 0.5173407537207191\n",
            "The iteration is 3000 and the loss is 0.5138592708939221\n",
            "The iteration is 4000 and the loss is 0.5116783263402548\n",
            "The iteration is 5000 and the loss is 0.5101710256487334\n",
            "The weight is \n",
            "[ 4.21906993  1.15944273  0.0479628   1.46024199 -0.86849992  1.08085925\n",
            " -0.14734293  2.57200354  2.07217971  0.71830355  0.2298555  -0.49054624\n",
            " -5.99002316  2.49778572 -0.03933227 -0.21227136  0.10238721 -2.04321644\n",
            "  0.73911104 -0.13439552  0.00695133  0.         -0.54732116 -1.43560725\n",
            "  1.58796776  1.02309541 -0.05546115]\n",
            "The intercept is \n",
            "-5.15983233666992\n",
            "The confusion matrix is: \n",
            "[1157, 1028]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7543943751997443\n",
            "The precision for the Twitter sentiment is 0.7761324041811847\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8226197345643393\n",
            "The F1 with Feature 13 is: 0.8226197345643393 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 13 is: 0.0008553116463815291\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5374232101911014\n",
            "The iteration is 2000 and the loss is 0.5267613655614026\n",
            "The iteration is 3000 and the loss is 0.5228365046707918\n",
            "The iteration is 4000 and the loss is 0.5207429475362578\n",
            "The iteration is 5000 and the loss is 0.5194098095954299\n",
            "The weight is \n",
            "[ 4.18670807  1.61456616  0.68262151  1.40356952 -0.63020293  1.22513211\n",
            " -0.20528632  2.99001772  2.09666931 -3.77497439  0.63674116 -1.51558043\n",
            "  5.89876216 -0.58187877 -0.07188127 -1.86282896 -0.05106997 -0.04713331\n",
            "  0.71570781 -0.05045065  0.7984676   0.          0.56667653  0.54102709\n",
            "  1.02651874  1.77454918 -0.04252105]\n",
            "The intercept is \n",
            "-4.829068201907448\n",
            "The confusion matrix is: \n",
            "[1145, 1040]\n",
            "[520, 3553]\n",
            "The accuracy for the Twitter sentiment is 0.75071907957814\n",
            "The precision for the Twitter sentiment is 0.7735684737644242\n",
            "The recall for the Twitter sentiment is 0.8723299779032654\n",
            "The F1 score for the Twitter sentiment is 0.8199861527809832\n",
            "The F1 with Feature 14 is: 0.8199861527809832 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 14 is: 0.003488893429737683\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5164560195077258\n",
            "The iteration is 2000 and the loss is 0.5122557008864609\n",
            "The iteration is 3000 and the loss is 0.510035777783161\n",
            "The iteration is 4000 and the loss is 0.5084711242995784\n",
            "The iteration is 5000 and the loss is 0.5073089941057035\n",
            "The weight is \n",
            "[ 3.72899557  0.92799558  0.10047839  1.34453595 -0.6714131   0.85968343\n",
            " -0.25836699  2.20357562  1.67912905 -0.50900821  0.41666502 -0.72623163\n",
            "  3.43247304 -4.32681731 -0.18335887 -1.02840618  0.05122942 -0.60870376\n",
            "  0.69050047 -0.06144359  0.31008605  0.         -0.11143833 -0.54892583\n",
            "  1.18666202  1.15815256 -0.03836932]\n",
            "The intercept is \n",
            "-4.061843344885439\n",
            "The confusion matrix is: \n",
            "[1171, 1014]\n",
            "[512, 3561]\n",
            "The accuracy for the Twitter sentiment is 0.756152125279642\n",
            "The precision for the Twitter sentiment is 0.778360655737705\n",
            "The recall for the Twitter sentiment is 0.874294132089369\n",
            "The F1 score for the Twitter sentiment is 0.8235430157261795\n",
            "The F1 with Feature 15 is: 0.8235430157261795 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 15 is: -6.796951545862129e-05\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163135388240562\n",
            "The iteration is 2000 and the loss is 0.5120012727037455\n",
            "The iteration is 3000 and the loss is 0.5096898209784274\n",
            "The iteration is 4000 and the loss is 0.5080597681345819\n",
            "The iteration is 5000 and the loss is 0.5068623722415878\n",
            "The weight is \n",
            "[ 3.79217235  0.9644625   0.07678083  1.41959969 -0.65682463  0.8708165\n",
            " -0.21900315  2.20229383  1.70921405 -0.87717486  0.37796045 -0.90924343\n",
            "  3.20155255 -4.45003372  0.90911104 -0.88064752  0.05500735 -1.0524744\n",
            "  0.68246877 -0.06843193  0.2829048   0.         -0.06971818 -0.46478716\n",
            "  1.18406439  1.16816585 -0.03474408]\n",
            "The intercept is \n",
            "-4.0024499357743855\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[506, 3567]\n",
            "The accuracy for the Twitter sentiment is 0.7564717162032598\n",
            "The precision for the Twitter sentiment is 0.7779716466739367\n",
            "The recall for the Twitter sentiment is 0.8757672477289468\n",
            "The F1 score for the Twitter sentiment is 0.8239778239778239\n",
            "The F1 with Feature 16 is: 0.8239778239778239 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 16 is: -0.0005027777671030575\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5174106917213711\n",
            "The iteration is 2000 and the loss is 0.5125270261322871\n",
            "The iteration is 3000 and the loss is 0.5098666039676442\n",
            "The iteration is 4000 and the loss is 0.5080252130877784\n",
            "The iteration is 5000 and the loss is 0.5067046351733576\n",
            "The weight is \n",
            "[ 3.80758887  0.89939273  0.07423442  1.3986525  -0.73686178  0.87229966\n",
            " -0.27646868  2.21693961  1.73046593 -0.76547619  0.34706429 -0.85918567\n",
            "  2.99219032 -4.63529168  1.26170792 -0.08834317  0.04152879 -1.28665208\n",
            "  0.6926471  -0.07161079  0.34812839  0.         -0.10416735 -0.60765496\n",
            "  1.16784701  1.173496   -0.03245874]\n",
            "The intercept is \n",
            "-4.680064596778289\n",
            "The confusion matrix is: \n",
            "[1165, 1020]\n",
            "[500, 3573]\n",
            "The accuracy for the Twitter sentiment is 0.7571108980504954\n",
            "The precision for the Twitter sentiment is 0.7779229261920314\n",
            "The recall for the Twitter sentiment is 0.8772403633685244\n",
            "The F1 score for the Twitter sentiment is 0.8246018924532655\n",
            "The F1 with Feature 17 is: 0.8246018924532655 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 17 is: -0.0011268462425446657\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163337829793266\n",
            "The iteration is 2000 and the loss is 0.5119828576603734\n",
            "The iteration is 3000 and the loss is 0.5096613042396567\n",
            "The iteration is 4000 and the loss is 0.5080373576379372\n",
            "The iteration is 5000 and the loss is 0.5068481247755345\n",
            "The weight is \n",
            "[ 3.78450815  0.95932462  0.08918869  1.41003952 -0.64961888  0.8740646\n",
            " -0.21823453  2.20868635  1.70429743 -0.84086121  0.38052317 -0.88090191\n",
            "  3.22064947 -4.4481951   0.90410438 -0.17866807 -0.89814241 -1.09446466\n",
            "  0.67948953 -0.06683023  0.29453278  0.         -0.07096595 -0.46612755\n",
            "  1.18796663  1.16654026 -0.03381557]\n",
            "The intercept is \n",
            "-3.9831990579145873\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7776565568404975\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8234750462107209\n",
            "The F1 with Feature 18 is: 0.8234750462107209 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 18 is: 0.0\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5170015322839425\n",
            "The iteration is 2000 and the loss is 0.5128141727407733\n",
            "The iteration is 3000 and the loss is 0.5105242659224636\n",
            "The iteration is 4000 and the loss is 0.5088907985674728\n",
            "The iteration is 5000 and the loss is 0.5076733864044587\n",
            "The weight is \n",
            "[ 3.77869019  0.88222674 -0.01545751  1.36537173 -0.71675965  0.82880717\n",
            " -0.20884098  2.10394969  1.7065216  -0.45070075  0.4372576  -0.75425845\n",
            "  3.47773307 -4.24902868 -0.20952206  0.07421134 -1.04110575  0.06733056\n",
            "  0.6565917  -0.07338013  0.26808104  0.         -0.14780393 -0.63571723\n",
            "  1.22905676  1.14519918 -0.0572732 ]\n",
            "The intercept is \n",
            "-4.310621905191113\n",
            "The confusion matrix is: \n",
            "[1169, 1016]\n",
            "[521, 3552]\n",
            "The accuracy for the Twitter sentiment is 0.7543943751997443\n",
            "The precision for the Twitter sentiment is 0.7775831873905429\n",
            "The recall for the Twitter sentiment is 0.8720844586300025\n",
            "The F1 score for the Twitter sentiment is 0.8221270686263163\n",
            "The F1 with Feature 19 is: 0.8221270686263163 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 19 is: 0.001347977584404525\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5164055061610511\n",
            "The iteration is 2000 and the loss is 0.5120980094635442\n",
            "The iteration is 3000 and the loss is 0.5098063596762872\n",
            "The iteration is 4000 and the loss is 0.5082029966540516\n",
            "The iteration is 5000 and the loss is 0.5070279388389032\n",
            "The weight is \n",
            "[ 3.76969582  0.95489325  0.09015308  1.40258138 -0.64892186  0.87463161\n",
            " -0.21309518  2.20561937  1.70549673 -0.83657347  0.37812766 -0.88415704\n",
            "  3.22437362 -4.45030982  0.90712331 -0.17988834 -0.89981094  0.05447857\n",
            " -1.08334822 -0.06615552  0.29520137  0.         -0.07441153 -0.47038835\n",
            "  1.18294498  1.16437046 -0.03437668]\n",
            "The intercept is \n",
            "-3.965116414636958\n",
            "The confusion matrix is: \n",
            "[1163, 1022]\n",
            "[508, 3565]\n",
            "The accuracy for the Twitter sentiment is 0.7555129434324065\n",
            "The precision for the Twitter sentiment is 0.7771964246784391\n",
            "The recall for the Twitter sentiment is 0.8752762091824208\n",
            "The F1 score for the Twitter sentiment is 0.8233256351039261\n",
            "The F1 with Feature 20 is: 0.8233256351039261 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 20 is: 0.00014941110679478342\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.516334368148961\n",
            "The iteration is 2000 and the loss is 0.5119832453916955\n",
            "The iteration is 3000 and the loss is 0.5096614597626334\n",
            "The iteration is 4000 and the loss is 0.5080372757319845\n",
            "The iteration is 5000 and the loss is 0.5068478007246485\n",
            "The weight is \n",
            "[ 3.78496195  0.95966278  0.08917167  1.41019979 -0.64980365  0.87395061\n",
            " -0.21840575  2.20859202  1.70448053 -0.84127238  0.38032852 -0.88046159\n",
            "  3.22069571 -4.4483443   0.9040367  -0.17865579 -0.89825535  0.05267689\n",
            " -1.09445135  0.67944176  0.29409941  0.         -0.07099057 -0.46594151\n",
            "  1.18822589  1.16650705 -0.03392863]\n",
            "The intercept is \n",
            "-3.9838921986312616\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7776565568404975\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8234750462107209\n",
            "The F1 with Feature 21 is: 0.8234750462107209 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 21 is: 0.0\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163683730000074\n",
            "The iteration is 2000 and the loss is 0.5120294367028562\n",
            "The iteration is 3000 and the loss is 0.5097187724774409\n",
            "The iteration is 4000 and the loss is 0.5081044684433768\n",
            "The iteration is 5000 and the loss is 0.5069237816203785\n",
            "The weight is \n",
            "[ 3.78165185  0.9550098   0.09588072  1.41421252 -0.63720295  0.88490454\n",
            " -0.21380488  2.2036663   1.70834132 -0.83140409  0.393172   -0.90194758\n",
            "  3.20149139 -4.46704154  0.90902733 -0.16104761 -0.90843148  0.05078768\n",
            " -1.08547174  0.67842751 -0.06001552  0.         -0.07303889 -0.47318108\n",
            "  1.18589472  1.16931586 -0.03708229]\n",
            "The intercept is \n",
            "-3.9420777645912994\n",
            "The confusion matrix is: \n",
            "[1170, 1015]\n",
            "[511, 3562]\n",
            "The accuracy for the Twitter sentiment is 0.756152125279642\n",
            "The precision for the Twitter sentiment is 0.7782390211929211\n",
            "The recall for the Twitter sentiment is 0.874539651362632\n",
            "The F1 score for the Twitter sentiment is 0.8235838150289018\n",
            "The F1 with Feature 22 is: 0.8235838150289018 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 22 is: -0.00010876881818089323\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163337648981696\n",
            "The iteration is 2000 and the loss is 0.5119824758821128\n",
            "The iteration is 3000 and the loss is 0.5096605563872266\n",
            "The iteration is 4000 and the loss is 0.5080362587179873\n",
            "The iteration is 5000 and the loss is 0.5068466849292902\n",
            "The weight is \n",
            "[ 3.78482296  0.95961696  0.08913285  1.41022504 -0.64968299  0.87404907\n",
            " -0.21844328  2.20870057  1.70453716 -0.84113012  0.38050787 -0.88064503\n",
            "  3.22044406 -4.44841141  0.90426279 -0.17841712 -0.89822205  0.05269887\n",
            " -1.09436821  0.67946859 -0.06685071  0.29464851 -0.07085495 -0.46595887\n",
            "  1.18808346  1.16645053 -0.0338025 ]\n",
            "The intercept is \n",
            "-3.983767986065102\n",
            "The confusion matrix is: \n",
            "[1166, 1019]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7776565568404975\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8234750462107209\n",
            "The F1 with Feature 23 is: 0.8234750462107209 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 23 is: 0.0\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5162950343465595\n",
            "The iteration is 2000 and the loss is 0.5119692432807816\n",
            "The iteration is 3000 and the loss is 0.5096571191573145\n",
            "The iteration is 4000 and the loss is 0.5080359666300651\n",
            "The iteration is 5000 and the loss is 0.5068475385388082\n",
            "The weight is \n",
            "[ 3.78480773  0.96093271  0.08878585  1.41129583 -0.64916824  0.87362442\n",
            " -0.21829935  2.20872708  1.70436098 -0.83143786  0.36701403 -0.8872876\n",
            "  3.21894071 -4.44853588  0.90538044 -0.17850132 -0.89681755  0.05280491\n",
            " -1.09443525  0.67962676 -0.06737118  0.29473733  0.         -0.50733746\n",
            "  1.18709301  1.16667708 -0.03531442]\n",
            "The intercept is \n",
            "-3.979752069393171\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[510, 3563]\n",
            "The accuracy for the Twitter sentiment is 0.7558325343560243\n",
            "The precision for the Twitter sentiment is 0.7777777777777778\n",
            "The recall for the Twitter sentiment is 0.8747851706358949\n",
            "The F1 score for the Twitter sentiment is 0.8234342500577768\n",
            "The F1 with Feature 24 is: 0.8234342500577768 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 24 is: 4.079615294405592e-05\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163022017535969\n",
            "The iteration is 2000 and the loss is 0.5119688364501297\n",
            "The iteration is 3000 and the loss is 0.5096639823240071\n",
            "The iteration is 4000 and the loss is 0.5080437892689443\n",
            "The iteration is 5000 and the loss is 0.506854351482768\n",
            "The weight is \n",
            "[ 3.78434623  0.96499663  0.0862449   1.41379228 -0.65373207  0.86639325\n",
            " -0.22118725  2.20777486  1.71038885 -0.77054858  0.21001086 -1.03309065\n",
            "  3.26284638 -4.41975375  0.94707839 -0.17544266 -0.91335307  0.05531217\n",
            " -1.12392406  0.68330652 -0.06642522  0.30320002  0.         -0.29489478\n",
            "  1.19077556  1.16642496 -0.04175809]\n",
            "The intercept is \n",
            "-4.009967430596498\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[514, 3559]\n",
            "The accuracy for the Twitter sentiment is 0.7551933525087887\n",
            "The precision for the Twitter sentiment is 0.7775835700240332\n",
            "The recall for the Twitter sentiment is 0.8738030935428431\n",
            "The F1 score for the Twitter sentiment is 0.8228901734104046\n",
            "The F1 with Feature 25 is: 0.8228901734104046 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 25 is: 0.0005848728003162718\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.517362598157925\n",
            "The iteration is 2000 and the loss is 0.5130398587075309\n",
            "The iteration is 3000 and the loss is 0.5107820035133137\n",
            "The iteration is 4000 and the loss is 0.509198501547346\n",
            "The iteration is 5000 and the loss is 0.5080341300780242\n",
            "The weight is \n",
            "[ 3.74010805e+00  9.85818353e-01  3.61560771e-01  1.49222466e+00\n",
            " -4.72555488e-01  1.05946310e+00 -7.88718452e-04  2.23248895e+00\n",
            "  1.87738141e+00 -7.44062076e-01  3.71546352e-01 -8.75486024e-01\n",
            "  3.40783058e+00 -4.41662746e+00  8.92402588e-01 -1.56456365e-01\n",
            " -8.57112792e-01  4.17924204e-02 -1.13323050e+00  6.51902766e-01\n",
            " -7.69884377e-02  2.82763670e-01  0.00000000e+00 -1.16743415e-01\n",
            " -5.18059182e-01  1.16554857e+00 -3.09431823e-02]\n",
            "The intercept is \n",
            "-3.890301512902841\n",
            "The confusion matrix is: \n",
            "[1154, 1031]\n",
            "[505, 3568]\n",
            "The accuracy for the Twitter sentiment is 0.7545541706615532\n",
            "The precision for the Twitter sentiment is 0.7758208306153511\n",
            "The recall for the Twitter sentiment is 0.8760127670022096\n",
            "The F1 score for the Twitter sentiment is 0.8228782287822878\n",
            "The F1 with Feature 26 is: 0.8228782287822878 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 26 is: 0.000596817428433094\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5178484422158528\n",
            "The iteration is 2000 and the loss is 0.5134253128699\n",
            "The iteration is 3000 and the loss is 0.5111100235295732\n",
            "The iteration is 4000 and the loss is 0.5095005520164334\n",
            "The iteration is 5000 and the loss is 0.5083260163947392\n",
            "The weight is \n",
            "[ 3.94155793  1.02496666  0.15683745  1.50651338 -0.59121998  0.91118527\n",
            " -0.08652423  2.20988226  1.8065302  -0.80391738  0.39931037 -0.95214701\n",
            "  3.13899575 -4.65866705  0.88039272 -0.19291468 -0.89078219  0.0643987\n",
            " -1.0540626   0.66246727 -0.07247669  0.31372292  0.         -0.0468264\n",
            " -0.43277531  1.18714253 -0.00989523]\n",
            "The intercept is \n",
            "-3.762767522501097\n",
            "The confusion matrix is: \n",
            "[1157, 1028]\n",
            "[514, 3559]\n",
            "The accuracy for the Twitter sentiment is 0.7535953978907\n",
            "The precision for the Twitter sentiment is 0.775888380204927\n",
            "The recall for the Twitter sentiment is 0.8738030935428431\n",
            "The F1 score for the Twitter sentiment is 0.8219399538106236\n",
            "The F1 with Feature 27 is: 0.8219399538106236 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 27 is: 0.0015350924000973043\n",
            "---------------\n",
            "The iteration is 0 and the loss is 0.6931471805599453\n",
            "The iteration is 1000 and the loss is 0.5163340101158802\n",
            "The iteration is 2000 and the loss is 0.5119826742128999\n",
            "The iteration is 3000 and the loss is 0.5096607024933104\n",
            "The iteration is 4000 and the loss is 0.5080363389529559\n",
            "The iteration is 5000 and the loss is 0.5068466938846996\n",
            "The weight is \n",
            "[ 3.78526948  0.95972919  0.08911563  1.41047171 -0.64989921  0.87396593\n",
            " -0.21848957  2.20887995  1.70449108 -0.84083245  0.38015263 -0.88024835\n",
            "  3.22045152 -4.44841924  0.90448278 -0.17856745 -0.89812695  0.05272546\n",
            " -1.09467171  0.67958241 -0.06693897  0.29484725  0.         -0.07116529\n",
            " -0.46631567  1.18808411  1.16632075]\n",
            "The intercept is \n",
            "-3.9843846104322744\n",
            "The confusion matrix is: \n",
            "[1167, 1018]\n",
            "[509, 3564]\n",
            "The accuracy for the Twitter sentiment is 0.7559923298178332\n",
            "The precision for the Twitter sentiment is 0.7778262767350502\n",
            "The recall for the Twitter sentiment is 0.8750306899091579\n",
            "The F1 score for the Twitter sentiment is 0.8235701906412478\n",
            "The F1 with Feature 28 is: 0.8235701906412478 but the target was: 0.8234750462107209\n",
            "The difference in F1 score without Feature 28 is: -9.514443052693888e-05\n",
            "---------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-7908cde1aeaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To remove \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" there was a loss of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_diff_rem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" in F1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(all_features)):\n",
        "  print(\"To remove \" + str(all_features[i]) + \" there was a loss of \" + str(f1_diff_rem[i]) + \" in F1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvV0U87jSz1h",
        "outputId": "c82a37a2-d9ca-4a8d-de2a-def87d139ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To remove feature1 there was a loss of 0.00277903330452145 in F1\n",
            "To remove feature2 there was a loss of 0.00017676815686673564 in F1\n",
            "To remove feature3 there was a loss of -0.00032622473093135707 in F1\n",
            "To remove feature4 there was a loss of 0.0013297174909977505 in F1\n",
            "To remove feature5 there was a loss of -0.00017664567055875047 in F1\n",
            "To remove feature6 there was a loss of -9.514443052693888e-05 in F1\n",
            "To remove feature7 there was a loss of -0.0004352324342090652 in F1\n",
            "To remove feature8 there was a loss of 0.0025073042752369323 in F1\n",
            "To remove feature9 there was a loss of 0.00013556281588700259 in F1\n",
            "To remove feature10 there was a loss of 0.00023105360443620437 in F1\n",
            "To remove feature11 there was a loss of -0.00047594211432822053 in F1\n",
            "To remove feature12 there was a loss of -0.000285499264836675 in F1\n",
            "To remove Feature 13 there was a loss of 0.0008553116463815291 in F1\n",
            "To remove Feature 14 there was a loss of 0.003488893429737683 in F1\n",
            "To remove Feature 15 there was a loss of -6.796951545862129e-05 in F1\n",
            "To remove Feature 16 there was a loss of -0.0005027777671030575 in F1\n",
            "To remove Feature 17 there was a loss of -0.0011268462425446657 in F1\n",
            "To remove Feature 18 there was a loss of 0.0 in F1\n",
            "To remove Feature 19 there was a loss of 0.001347977584404525 in F1\n",
            "To remove Feature 20 there was a loss of 0.00014941110679478342 in F1\n",
            "To remove Feature 21 there was a loss of 0.0 in F1\n",
            "To remove Feature 22 there was a loss of -0.00010876881818089323 in F1\n",
            "To remove Feature 23 there was a loss of 0.0 in F1\n",
            "To remove Feature 24 there was a loss of 4.079615294405592e-05 in F1\n",
            "To remove Feature 25 there was a loss of 0.0005848728003162718 in F1\n",
            "To remove Feature 26 there was a loss of 0.000596817428433094 in F1\n",
            "To remove Feature 27 there was a loss of 0.0015350924000973043 in F1\n",
            "To remove Feature 28 there was a loss of -9.514443052693888e-05 in F1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_diffs_rem_percent = []\n",
        "maxnum=(max(f1_diff_rem))\n",
        "for i in range (0,len(f1_diff_rem)):\n",
        "  num=f1_diff_rem[i]\n",
        "  val = 100 * (num/maxnum)\n",
        "  f1_diffs_rem_percent.append(val)\n",
        "  print(\"The \" + str(all_features[i]) + \" has a relative importance percentage \" + str(f1_diffs_rem_percent[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exMp_DZMum0K",
        "outputId": "14a15fac-03b9-4b54-9fdb-dfc898abb713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature1 has a relative importance percentage 79.65371715955209\n",
            "The feature2 has a relative importance percentage 5.066596628032465\n",
            "The feature3 has a relative importance percentage -9.350378207335634\n",
            "The feature4 has a relative importance percentage 38.11287211193857\n",
            "The feature5 has a relative importance percentage -5.063085878551235\n",
            "The feature6 has a relative importance percentage -2.727066115461499\n",
            "The feature7 has a relative importance percentage -12.474798757088685\n",
            "The feature8 has a relative importance percentage 71.86531562889978\n",
            "The feature9 has a relative importance percentage 3.8855533600289727\n",
            "The feature10 has a relative importance percentage 6.622546921806564\n",
            "The feature11 has a relative importance percentage -13.641635203629734\n",
            "The feature12 has a relative importance percentage -8.183089297116783\n",
            "The Feature 13 has a relative importance percentage 24.515270059304644\n",
            "The Feature 14 has a relative importance percentage 100.0\n",
            "The Feature 15 has a relative importance percentage -1.9481682896726273\n",
            "The Feature 16 has a relative importance percentage -14.410808963599086\n",
            "The Feature 17 has a relative importance percentage -32.29809867334896\n",
            "The Feature 18 has a relative importance percentage 0.0\n",
            "The Feature 19 has a relative importance percentage 38.63624990419597\n",
            "The Feature 20 has a relative importance percentage 4.282478378997581\n",
            "The Feature 21 has a relative importance percentage 0.0\n",
            "The Feature 22 has a relative importance percentage -3.117573533596616\n",
            "The Feature 23 has a relative importance percentage 0.0\n",
            "The Feature 24 has a relative importance percentage 1.1693149637741511\n",
            "The Feature 25 has a relative importance percentage 16.763848254323037\n",
            "The Feature 26 has a relative importance percentage 17.106209761126657\n",
            "The Feature 27 has a relative importance percentage 43.999406431073545\n",
            "The Feature 28 has a relative importance percentage -2.727066115461499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizations"
      ],
      "metadata": {
        "id": "4abZieyLZrX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "some visualization of how much the F1 difference is for each feature\n",
        "order the features from best to worst with a label of each feature\n",
        "that way we can try to describe why the best measured better\n",
        "and why the worst measured worse\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qZ_zO2MWZuYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "try remove one\n",
        "f1_diffs_rem_percent\n",
        "The feature1 has a relative importance percentage 79.65371715955209\n",
        "The feature2 has a relative importance percentage 5.066596628032465\n",
        "The feature3 has a relative importance percentage -9.350378207335634\n",
        "The feature4 has a relative importance percentage 38.11287211193857\n",
        "The feature5 has a relative importance percentage -5.063085878551235\n",
        "The feature6 has a relative importance percentage -2.727066115461499\n",
        "The feature7 has a relative importance percentage -12.474798757088685\n",
        "The feature8 has a relative importance percentage 71.86531562889978\n",
        "The feature9 has a relative importance percentage 3.8855533600289727\n",
        "The feature10 has a relative importance percentage 6.622546921806564\n",
        "The feature11 has a relative importance percentage -13.641635203629734\n",
        "The feature12 has a relative importance percentage -8.183089297116783\n",
        "The Feature 13 has a relative importance percentage 24.515270059304644\n",
        "The Feature 14 has a relative importance percentage 100.0\n",
        "The Feature 15 has a relative importance percentage -1.9481682896726273\n",
        "The Feature 16 has a relative importance percentage -14.410808963599086\n",
        "The Feature 17 has a relative importance percentage -32.29809867334896\n",
        "The Feature 18 has a relative importance percentage 0.0\n",
        "The Feature 19 has a relative importance percentage 38.63624990419597\n",
        "The Feature 20 has a relative importance percentage 4.282478378997581\n",
        "The Feature 21 has a relative importance percentage 0.0\n",
        "The Feature 22 has a relative importance percentage -3.117573533596616\n",
        "The Feature 23 has a relative importance percentage 0.0\n",
        "The Feature 24 has a relative importance percentage 1.1693149637741511\n",
        "The Feature 25 has a relative importance percentage 16.763848254323037\n",
        "The Feature 26 has a relative importance percentage 17.106209761126657\n",
        "The Feature 27 has a relative importance percentage 43.999406431073545\n",
        "The Feature 28 has a relative importance percentage -2.727066115461499\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ub0mg5yBediE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "try add one\n",
        "f1_diffs_add_percent\n",
        "The feature feature10 has a relative importance percentage 48.63731556675939\n",
        "The feature feature11 has a relative importance percentage 84.0731351911296\n",
        "The feature feature12 has a relative importance percentage 74.74470031918592\n",
        "The feature Feature 15 has a relative importance percentage 83.60990654729493\n",
        "The feature Feature 16 has a relative importance percentage 69.8840625054353\n",
        "The feature Feature 17 has a relative importance percentage 48.12447030468545\n",
        "The feature Feature 18 has a relative importance percentage 48.12447030468545\n",
        "The feature Feature 19 has a relative importance percentage 71.64622077596246\n",
        "The feature Feature 20 has a relative importance percentage 62.777223498411395\n",
        "The feature Feature 23 has a relative importance percentage 62.777223498411395\n",
        "The feature Feature 24 has a relative importance percentage 80.9438088884997\n",
        "The feature Feature 25 has a relative importance percentage 100.0\n",
        "The feature Feature 28 has a relative importance percentage 96.90003462249788\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GgDVS-uYei_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_diffs_add_percent_padded=['0','0','0','0','0','0','0','0','0','48.63731556675939','84.0731351911296','74.74470031918592','0','0','83.60990654729493','69.8840625054353','48.12447030468545','48.12447030468545','71.64622077596246','62.777223498411395', '0', '0', '62.777223498411395','80.9438088884997','100.0','0','0','96.90003462249788']"
      ],
      "metadata": {
        "id": "IjByfJ7H3b4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "sklearn importance weights\n",
        "The feature feature1 has a relative importance percentage 86.40163468408473\n",
        "The feature feature2 has a relative importance percentage 58.47034172861291\n",
        "The feature feature3 has a relative importance percentage 52.35136295591531\n",
        "The feature feature4 has a relative importance percentage 54.667298886312345\n",
        "The feature feature5 has a relative importance percentage 43.16589301930024\n",
        "The feature feature6 has a relative importance percentage 51.793820864920214\n",
        "The feature feature7 has a relative importance percentage 45.87124158175938\n",
        "The feature feature8 has a relative importance percentage 69.95017570784626\n",
        "The feature feature9 has a relative importance percentage 66.18688252818464\n",
        "The feature feature10 has a relative importance percentage 27.100568860890473\n",
        "The feature feature11 has a relative importance percentage 23.76248645309518\n",
        "The feature feature12 has a relative importance percentage 26.34323571407327\n",
        "The feature Feature 13 has a relative importance percentage 63.77158217368765\n",
        "The feature Feature 14 has a relative importance percentage 100.0\n",
        "The feature Feature 15 has a relative importance percentage 19.93415218412927\n",
        "The feature Feature 16 has a relative importance percentage 18.48951650067179\n",
        "The feature Feature 17 has a relative importance percentage 12.124680833676008\n",
        "The feature Feature 18 has a relative importance percentage 0.29558592654752436\n",
        "The feature Feature 19 has a relative importance percentage 33.31950900754798\n",
        "The feature Feature 20 has a relative importance percentage 1.7483491926022832\n",
        "The feature Feature 21 has a relative importance percentage 60.640364548123436\n",
        "The feature Feature 22 has a relative importance percentage 43.51677324033304\n",
        "The feature Feature 23 has a relative importance percentage 0.0\n",
        "The feature Feature 24 has a relative importance percentage 37.105133477101845\n",
        "The feature Feature 25 has a relative importance percentage 38.83102787782608\n",
        "The feature Feature 26 has a relative importance percentage 56.08875958164439\n",
        "The feature Feature 27 has a relative importance percentage 55.08022606346591\n",
        "The feature Feature 28 has a relative importance percentage 1.0450935757526747\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2tLNpOWrg0SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_imp=['86.40163468408473','58.47034172861291','52.35136295591531','54.667298886312345','43.16589301930024','51.793820864920214','45.87124158175938','69.95017570784626','66.18688252818464','27.100568860890473','23.76248645309518','26.34323571407327','63.77158217368765','100.0','19.93415218412927','18.48951650067179','12.124680833676008','0.29558592654752436','33.31950900754798','1.7483491926022832','60.640364548123436','43.51677324033304','0.0','37.105133477101845','38.83102787782608','56.08875958164439','55.08022606346591','1.0450935757526747']"
      ],
      "metadata": {
        "id": "Ked3yQ_I5FGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label=list(all_features)\n",
        "\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Remove One from All List', x=label, y=f1_diffs_rem_percent),\n",
        "    go.Bar(name='SKLearn', x=label, y=sklearn_imp),\n",
        "    go.Bar(name='Add One to Best List', x=label, y=f1_diffs_add_percent_padded)\n",
        "])\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', xaxis={'categoryorder':'category ascending'})\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "TaLft4bR6rgz",
        "outputId": "bf23e862-b1e5-41c0-f72f-803f60eb3d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e6284cda-2c12-43fa-8fa8-fc9ba2c94dd0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e6284cda-2c12-43fa-8fa8-fc9ba2c94dd0\")) {                    Plotly.newPlot(                        \"e6284cda-2c12-43fa-8fa8-fc9ba2c94dd0\",                        [{\"name\":\"Remove One from All List\",\"x\":[\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\",\"feature8\",\"feature9\",\"feature10\",\"feature11\",\"feature12\",\"Feature 13\",\"Feature 14\",\"Feature 15\",\"Feature 16\",\"Feature 17\",\"Feature 18\",\"Feature 19\",\"Feature 20\",\"Feature 21\",\"Feature 22\",\"Feature 23\",\"Feature 24\",\"Feature 25\",\"Feature 26\",\"Feature 27\",\"Feature 28\"],\"y\":[79.65371715955209,5.066596628032465,-9.350378207335634,38.11287211193857,-5.063085878551235,-2.727066115461499,-12.474798757088685,71.86531562889978,3.8855533600289727,6.622546921806564,-13.641635203629734,-8.183089297116783,24.515270059304644,100.0,-1.9481682896726273,-14.410808963599086,-32.29809867334896,0.0,38.63624990419597,4.282478378997581,0.0,-3.117573533596616,0.0,1.1693149637741511,16.763848254323037,17.106209761126657,43.999406431073545,-2.727066115461499],\"type\":\"bar\"},{\"name\":\"SKLearn\",\"x\":[\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\",\"feature8\",\"feature9\",\"feature10\",\"feature11\",\"feature12\",\"Feature 13\",\"Feature 14\",\"Feature 15\",\"Feature 16\",\"Feature 17\",\"Feature 18\",\"Feature 19\",\"Feature 20\",\"Feature 21\",\"Feature 22\",\"Feature 23\",\"Feature 24\",\"Feature 25\",\"Feature 26\",\"Feature 27\",\"Feature 28\"],\"y\":[\"86.40163468408473\",\"58.47034172861291\",\"52.35136295591531\",\"54.667298886312345\",\"43.16589301930024\",\"51.793820864920214\",\"45.87124158175938\",\"69.95017570784626\",\"66.18688252818464\",\"27.100568860890473\",\"23.76248645309518\",\"26.34323571407327\",\"63.77158217368765\",\"100.0\",\"19.93415218412927\",\"18.48951650067179\",\"12.124680833676008\",\"0.29558592654752436\",\"33.31950900754798\",\"1.7483491926022832\",\"60.640364548123436\",\"43.51677324033304\",\"0.0\",\"37.105133477101845\",\"38.83102787782608\",\"56.08875958164439\",\"55.08022606346591\",\"1.0450935757526747\"],\"type\":\"bar\"},{\"name\":\"Add One to Best List\",\"x\":[\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\",\"feature8\",\"feature9\",\"feature10\",\"feature11\",\"feature12\",\"Feature 13\",\"Feature 14\",\"Feature 15\",\"Feature 16\",\"Feature 17\",\"Feature 18\",\"Feature 19\",\"Feature 20\",\"Feature 21\",\"Feature 22\",\"Feature 23\",\"Feature 24\",\"Feature 25\",\"Feature 26\",\"Feature 27\",\"Feature 28\"],\"y\":[\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"48.63731556675939\",\"84.0731351911296\",\"74.74470031918592\",\"0\",\"0\",\"83.60990654729493\",\"69.8840625054353\",\"48.12447030468545\",\"48.12447030468545\",\"71.64622077596246\",\"62.777223498411395\",\"0\",\"0\",\"62.777223498411395\",\"80.9438088884997\",\"100.0\",\"0\",\"0\",\"96.90003462249788\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"categoryorder\":\"category ascending\"},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e6284cda-2c12-43fa-8fa8-fc9ba2c94dd0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify our LogReg against sklearn"
      ],
      "metadata": {
        "id": "KjL4vj0yvd5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calling sklearn to compare. checks out my math above is correct!\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "confusion_matrix_twitter = confusion_matrix(y_test, y_pred)\n",
        "print(\"The confusion matrix for Twitter sentinment:\")\n",
        "print(confusion_matrix_twitter)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_twitter)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNWDZ8A8Sbyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "af979f44-4fdc-41fc-9400-f7120b2e5901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for Twitter sentinment:\n",
            "[[1166 1019]\n",
            " [ 509 3564]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "print(\"The confusion matrix for Twitter sentiment:\")\n",
        "print(confusion_matrix_twitter)\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dy9yad9Bs3Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48390c7-292f-4828-b097-1cd768bd618a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for Twitter sentiment:\n",
            "[[1166 1019]\n",
            " [ 509 3564]]\n",
            "Accuracy: 0.7558325343560243\n",
            "Precision: 0.7776565568404975\n",
            "Recall: 0.8750306899091579\n",
            "F1 Score: 0.8234750462107209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "E_I7rz3jSeDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1fe231-bd06-450e-8e2c-391f6b048be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 0., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "POPn5VzdWvnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2cbd4f-47fd-4b81-ddc3-81ced4289228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25651    1\n",
              "5405     1\n",
              "4034     1\n",
              "21857    0\n",
              "27040    0\n",
              "        ..\n",
              "6528     1\n",
              "18615    1\n",
              "1397     1\n",
              "5312     1\n",
              "30506    1\n",
              "Name: Label, Length: 6258, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I implemented it from scratch above, just using this as a benchmark to test my code. \n",
        "#My code's metrics are really really close so I consider that a win\n",
        "from sklearn import metrics  \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#X=np.concatenate((X_train_norm, X_test_norm))\n",
        "#y=np.concatenate((y_train, y_test))\n",
        "#y.loc[y.Label == 2, 'Label'] = 1\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
        "Xc_selected, yc, test_size=0.33, random_state=55)\n",
        "X_train2, X_test2, y_train2, y_test2 = X_train_norm, X_test_norm, y_train, y_test\n",
        "goodmodel = LogisticRegression(max_iter=100000)\n",
        "goodmodel.fit(X_train, y_train)\n",
        "y_pred2 = pd.Series(goodmodel.predict(X_test2))\n",
        "confusion_matrix_twitter2 = confusion_matrix(y_test2, y_pred2)\n",
        "print(\"The confusion matrix for Twitter sentiment:\")\n",
        "print(confusion_matrix_twitter2)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_twitter2)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test2, y_pred2))\n",
        "print(\"Precision:\", metrics.precision_score(y_test2, y_pred2))\n",
        "print(\"Recall:\", metrics.recall_score(y_test2, y_pred2))\n",
        "print(\"F1:\"), metrics.f1_score(y_test2, y_pred2)"
      ],
      "metadata": {
        "id": "glUnTXt8om5M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "42e966f8-aa3a-4896-d676-345fca2f3f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The confusion matrix for Twitter sentiment:\n",
            "[[   7 2178]\n",
            " [   4 4069]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6513263023330137\n",
            "Precision: 0.6513526492716504\n",
            "Recall: 0.9990179229069482\n",
            "F1:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 0.7885658914728682)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test2"
      ],
      "metadata": {
        "id": "YMFkOfozo6in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc83005-aa9b-4046-8678-196af0866aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25651    1\n",
              "5405     1\n",
              "4034     1\n",
              "21857    0\n",
              "27040    0\n",
              "        ..\n",
              "6528     1\n",
              "18615    1\n",
              "1397     1\n",
              "5312     1\n",
              "30506    1\n",
              "Name: Label, Length: 6258, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2"
      ],
      "metadata": {
        "id": "QOZLX2oio7Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfe5e1a-6998-4d0a-d8d3-faf55ea1c0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "6253    1\n",
              "6254    1\n",
              "6255    1\n",
              "6256    1\n",
              "6257    1\n",
              "Length: 6258, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Complete\")"
      ],
      "metadata": {
        "id": "xR1--HPQpTwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow about 16min for runtime\n",
        "#Extract all features and put them in on data frame\n",
        "\n",
        "def feature_extraction(data_location, label_location):\n",
        "  df = pd.read_csv(data_location, header=None)\n",
        "  df.columns = ['TWEET']\n",
        "\n",
        "  df[\"Tweet Tokens\"] = np.nan\n",
        "  df[\"Count: Words in + Lexicon\"] = np.nan\n",
        "  df[\"Count: Words in - Lexicon\"] = np.nan\n",
        "  df[\"Contain The word NO? \"] = np.nan\n",
        "  df[\"Count: Nouns\"] = np.nan\n",
        "  df[\"Ratio: Unique Words-Total Words\"] = np.nan\n",
        "  df[\"Ratio: Stop Words-Total Words\"] = np.nan\n",
        "  df[\"Count: Adjectives in Tweet\"] = np.nan\n",
        "  df[\"Log: Tweet word count\"] = np.nan\n",
        "  df[\"Log: Length of Longest Word in Tweet\"] = np.nan\n",
        "  df[\"Log: Count of Words with 5+ Characters\"] = np.nan\n",
        "\n",
        "  # ADD LABELS COLUMN TO DF \n",
        "  labels = pd.read_csv(label_location, sep=\"\\n\", header=None)\n",
        "  df = pd.concat([df,labels], axis = 1)\n",
        "  df.rename(columns = {0:'Labels'}, inplace = True)\n",
        "\n",
        "  # DROP NEUTRAL LABELS FROM DF\n",
        "  df.drop(df.loc[df['Labels']==1].index, inplace=True)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  # CHANGE ALL 2 LABEL VALUES TO 1 \n",
        "  for i in range(0, len(df.index)):\n",
        "    if df['Labels'].values[i] == 2:\n",
        "      df.at[i,'Labels'] = 1\n",
        "\n",
        "  # CLEAN TWEETS\n",
        "  pattern_a = r'[^A-Za-z0-9]+'\n",
        "  pattern_b = r'\\b\\w{1,1}\\b'\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].lower()\n",
        "    df['TWEET'].values[i] = df['TWEET'].values[i].replace('@user', '')\n",
        "    df['TWEET'].values[i] = re.sub(pattern_a, ' ', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(pattern_b, '', df['TWEET'].values[i])\n",
        "    df['TWEET'].values[i] = re.sub(emoji_pattern, '', df['TWEET'].values[i])\n",
        "\n",
        "  #TOKENIZE TWEETS\n",
        "  df['Tweet Tokens'] = df['Tweet Tokens'].astype('object')\n",
        "  for i in range(0, len(df.index)):\n",
        "    \n",
        "    tokens = df['TWEET'].values[i].split()\n",
        "    df.at[i, 'Tweet Tokens'] = tokens\n",
        "\n",
        "  #Create Positive and Negative Lexicons\n",
        "  pos_lexicon = []\n",
        "  neg_lexicon = []\n",
        "\n",
        "  for i in range(0, len(subreddit_dataframes)):               \n",
        "    for j in range(0, len(subreddit_dataframes[i].index)):    \n",
        "\n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] >= 0:         \n",
        "        pos_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "      \n",
        "      if subreddit_dataframes[i]['Sentiment Score'].values[j] < 0:         \n",
        "        neg_lexicon.append(subreddit_dataframes[i]['Word'].values[j])        \n",
        "\n",
        "\n",
        "  pos_lexicon = [*set(pos_lexicon)]   # Remove duplicate values from + lexicon\n",
        "  neg_lexicon = [*set(neg_lexicon)]   # Remove duplicate values from - lexicon\n",
        "\n",
        "\n",
        "  #Handle duplicate words in postitive and negative lexicon\n",
        "  same_wrds = set(pos_lexicon).intersection(neg_lexicon)      #get set of all words that appear in both psoitive and Negative Lexicon\n",
        "                                                              #https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches\n",
        "\n",
        "  word_vals_dict = dict.fromkeys(same_wrds, 0)                # Create a dictionary to hold of all words found in positive and negative lexicons     \n",
        "  sentiment_vals2sum = []\n",
        "\n",
        "  for k in range(0, len(same_wrds)):    # In the set of words identified in positive and negative lexicon\n",
        "  \n",
        "    i = same_wrds.pop()                 # i will return one word from the set, then the following with each iteration\n",
        "    same_wrds.add(i)                    # https://stackoverflow.com/questions/59825/how-to-retrieve-an-element-from-a-set-without-removing-it\n",
        "\n",
        "    sentiment_vals2sum = []             # Will store the Sentiment Scores collected across data frames \n",
        "\n",
        "    for j in range(0, len(subreddit_dataframes)):                    # in range of dataframes(44)\n",
        "      is_wrd_there = i in subreddit_dataframes[j]['Word'].unique()   # Return true or false. True if desired word 'i' is in the data frame being checked false if not (ls_df_names[0], ls_df_names[1],...)\n",
        "      if is_wrd_there is True:                              # If true... \n",
        "\n",
        "        mask1 = subreddit_dataframes[j]['Word'].values == i                  # Get the sentiment value of the word from its dataframe \n",
        "                                                                    # https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
        "                                                      \n",
        "        sentiment_vals2sum.append(subreddit_dataframes[j][mask1].iat[0,1])   # append sentiment value to list where they are stored eg. sentiment_vals2sum \n",
        "        num_avg = mean(sentiment_vals2sum)                          # Take the mean of the sentiment scores collected in the list above(these are all sentiment scores for one word collected across dataframes where the word was found 'True')\n",
        "        word_vals_dict[i] = num_avg  \n",
        "\n",
        "  # Remove words that now have a clear positive or negative classification\n",
        "  for w in word_vals_dict.items():        # .items() returns a tuple of (word, score). See Cell above for all words: scores in dict\n",
        "    if w[1] >= 0:                         # if w[1] (the score) is greater than 0...\n",
        "      neg_lexicon.remove(w[0])            # remove it from the negative lexicon\n",
        "    if w[1] < 0:                          # If w[1] (the score) is less than 0...\n",
        "      pos_lexicon.remove(w[0])            # remove the word from the positive lexicon\n",
        "\n",
        "  # COUNT POSITIVE AND NEGATIVE WORDS\n",
        "  neg_lex_set = set(neg_lexicon)\n",
        "  pos_lex_set = set(pos_lexicon)\n",
        "\n",
        "  for i in range(0, len(df.index)):\n",
        "    x = set(df['Tweet Tokens'][i])\n",
        "    df['Count: Words in + Lexicon'].values[i] = len(x.intersection(pos_lex_set))\n",
        "    df['Count: Words in - Lexicon'].values[i] = len(x.intersection(neg_lex_set))\n",
        "\n",
        "  # DOES TWEET CONTAIN NO\n",
        "  for i in range(0, len(df.index)):                       # In the range 0 to length of the tweets dataframe         # Tokenize and lowercase tweets \n",
        "    if 'no' in df['Tweet Tokens'][i]:                                    # If no is in tweet dataframe value is 1 if not value is zero\n",
        "      df['Contain The word NO? '].values[i] = 1\n",
        "    else: \n",
        "      df['Contain The word NO? '].values[i] = 0\n",
        "\n",
        "  # COUNT NOUNS IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    noun_definitions = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in noun_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Nouns'].values[i] = count    \n",
        "\n",
        "  # RATIO: UNIQUE TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    ratio = len(np.unique(x)) / len(tokens)\n",
        "    df['Ratio: Unique Words-Total Words'].values[i] = ratio    \n",
        "\n",
        "  # STOP WORDS TO TOTAL WORDS\n",
        "  for i in range(0, len(df.index)):                       \n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    x = np.array(tokens)\n",
        "    stop_wrds_count = [w for w in tokens if w in stop_words]\n",
        "    ratio = len(stop_wrds_count) / len(tokens)\n",
        "    df['Ratio: Stop Words-Total Words'].values[i] = ratio\n",
        "\n",
        "  #ADJECTIVES IN TWEET\n",
        "  for i in range(0, len(df.index)):\n",
        "    tokens = df['Tweet Tokens'][i]\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    adj_definitions = ['JJ', 'JJR', 'JJS ']\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0, len(tagged)):\n",
        "      if tagged[j][1] in adj_definitions:\n",
        "        count += 1\n",
        "    \n",
        "    df['Count: Adjectives in Tweet'].values[i] = count\n",
        "\n",
        "  # LOG OF TWEET WORD COUNT \n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]       #tokenize tweets \n",
        "    log_val = math.log(len(tokens))\n",
        "    df['Log: Tweet word count'].values[i] = log_val\n",
        "\n",
        "\n",
        "  # LOG LENGTH OF LONGEST WORD IN TWEET\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]   #tokenize tweets \n",
        "    longest_wrd = max(tokens, key=len)\n",
        "    log_val =  math.log(len(longest_wrd))\n",
        "    df['Log: Length of Longest Word in Tweet'].values[i] = log_val\n",
        "\n",
        "  #LOG OF COUNT OF WORD WITH 5+ CHARACTERS\n",
        "  for i in range(0, len(df.index)):           #In range: length of dataframe of tweets\n",
        "    tokens = df['Tweet Tokens'][i]    #tokenize tweets\n",
        "    count = 0\n",
        "      \n",
        "    if any(len(i) >= 5 for i in tokens) is True:\n",
        "\n",
        "      for j in range(0, len(tokens)):\n",
        "        if len(tokens[j]) >= 5:\n",
        "          count = count +1\n",
        "\n",
        "      log_val = math.log(count)\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = log_val\n",
        "      \n",
        "    else:\n",
        "      df['Log: Count of Words with 5+ Characters'].values[i] = 0\n",
        "\n",
        "\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "92GOZSc0Nmps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How to run: \n",
        "# dataframe = feature_extraction(data_location, label_location)"
      ],
      "metadata": {
        "id": "p45NGKHsMeWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}